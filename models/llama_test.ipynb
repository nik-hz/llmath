{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q -U bitsandbytes\n",
    "# !pip install -q -U git+https://github.com/huggingface/transformers.git\n",
    "# !pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "# !pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
    "# !pip install -q -U datasets scipy ipywidgets matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set CUDA_VISIBLE_DEVICES to 1\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "# Set CUDA_VISIBLE_DEVICES to 1\n",
    "%env CUDA_VISIBLE_DEVICES=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(os.environ['CUDA_VISIBLE_DEVICES'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth: Fast Llama patching release 2024.3\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3090. Max memory: 23.483 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.2.1+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. Xformers = 0.0.25. FA = True.\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
    "fourbit_models = [\n",
    "    \"unsloth/mistral-7b-bnb-4bit\",\n",
    "    \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\",\n",
    "    \"unsloth/llama-2-7b-bnb-4bit\",\n",
    "    \"unsloth/llama-2-13b-bnb-4bit\",\n",
    "    \"unsloth/codellama-34b-bnb-4bit\",\n",
    "    \"unsloth/tinyllama-bnb-4bit\",\n",
    "    \"unsloth/gemma-7b-bnb-4bit\", # New Google 6 trillion tokens model 2.5x faster!\n",
    "    \"unsloth/gemma-2b-bnb-4bit\",\n",
    "] # More models at https://huggingface.co/unsloth\n",
    "\n",
    "# unsloth/codellama-7b-bnb-4bit\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/llama-2-7b-bnb-4bit\", # Choose ANY! eg mistralai/Mistral-7B-Instruct-v0.2\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    use_gradient_checkpointing = True,\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title GSM8K Prompts\n",
    "\n",
    "PREAMBLE = \"\"\"As an expert problem solver solve step by step the following mathematical questions.\"\"\"\n",
    "\n",
    "# The default gsm8k prompt from the CoT paper\n",
    "# https://arxiv.org/pdf/2201.11903.pdf page 35.\n",
    "\n",
    "PROMPT = \"\"\"Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\n",
    "A: We start with 15 trees. Later we have 21 trees. The difference must be the number of trees they planted. So, they must have planted 21 - 15 = 6 trees. The answer is 6.\n",
    "\n",
    "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
    "A: There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 + 2 = 5 cars. The answer is 5.\n",
    "\n",
    "Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\n",
    "A: Leah had 32 chocolates and Leah's sister had 42. That means there were originally 32 + 42 = 74 chocolates. 35 have been eaten. So in total they still have 74 - 35 = 39 chocolates. The answer is 39.\n",
    "\n",
    "Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?\n",
    "A: Jason had 20 lollipops. Since he only has 12 now, he must have given the rest to Denny. The number of lollipops he has given to Denny must have been 20 - 12 = 8 lollipops. The answer is 8.\n",
    "\n",
    "Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?\n",
    "A: He has 5 toys. He got 2 from mom, so after that he has 5 + 2 = 7 toys. Then he got 2 more from dad, so in total he has 7 + 2 = 9 toys. The answer is 9.\n",
    "\n",
    "Q: There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room?\n",
    "A: There are 4 days from monday to thursday. 5 computers were added each day. That means in total 4 * 5 = 20 computers were added. There were 9 computers in the beginning, so now there are 9 + 20 = 29 computers. The answer is 29.\n",
    "\n",
    "Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls did he have at the end of wednesday?\n",
    "A: Michael initially had 58 balls. He lost 23 on Tuesday, so after that he has 58 - 23 = 35 balls. On Wednesday he lost 2 more so now he has 35 - 2 = 33 balls. The answer is 33.\n",
    "\n",
    "Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\n",
    "A: She bought 5 bagels for $3 each. This means she spent 5 * $3 = $15 on the bagels. She had $23 in beginning, so now she has $23 - $15 = $8. The answer is 8.\"\"\"\n",
    "\n",
    "\n",
    "# Extension of the default 8-shot prompt, page 35 in\n",
    "# https://arxiv.org/pdf/2201.11903.pdf\n",
    "# The extension is intended to improve performance on\n",
    "# more complicated gsm8k examples.\n",
    "\n",
    "EXTRA_3_SHOTS = \"\"\"As an expert problem solver solve step by step the following mathematical questions.\n",
    "\n",
    "Q: Tina makes $18.00 an hour.  If she works more than 8 hours per shift, she is eligible for overtime, which is paid by your hourly wage + 1/2 your hourly wage.  If she works 10 hours every day for 5 days, how much money does she make?\n",
    "A: Here's how to calculate Tina's earnings:\n",
    "\n",
    "**Regular Time:**\n",
    "- Hours per shift: 8 hours\n",
    "- Wage per hour: $18.00\n",
    "- Regular pay per shift: 8 hours * $18.00/hour = $144.00\n",
    "\n",
    "**Overtime:**\n",
    "- Overtime hours per shift: 10 hours - 8 hours = 2 hours\n",
    "- Overtime pay per hour: $18.00 + ($18.00 / 2) = $27.00\n",
    "- Overtime pay per shift: 2 hours * $27.00/hour = $54.00\n",
    "\n",
    "**Total per day:**\n",
    "- Regular pay + overtime pay: $144.00/shift + $54.00/shift = $198.00/day\n",
    "\n",
    "**Total for 5 days:**\n",
    "- 5 days * $198.00/day = $990.00\n",
    "\n",
    "**Therefore, Tina will make $990.00 in 5 days.** The answer is 990.\n",
    "\n",
    "Q: Abigail is trying a new recipe for a cold drink. It uses 1/4 of a cup of iced tea and 1 and 1/4 of a cup of lemonade to make one drink. If she fills a pitcher with 18 total cups of this drink, how many cups of lemonade are in the pitcher?\n",
    "A: ## Ambiguity in the Problem Statement:\n",
    "\n",
    "There is one main ambiguity in the problem statement:\n",
    "\n",
    "**Total volume vs. Number of servings:** The statement \"18 total cups of this drink\" could be interpreted in two ways:\n",
    "  * **18 cups of the combined volume:** This would mean Abigail used a total of 18 cups of liquid, including both iced tea and lemonade.\n",
    "  * **18 individual servings:** This would mean Abigail made 18 individual drinks, each containing 1/4 cup of iced tea and 1 1/4 cup of lemonade.\n",
    "\n",
    "Let us assume the interpretation \"18 cups of the combined volume\".\n",
    "\n",
    "## Solution assuming 18 cups of combined volume:\n",
    "\n",
    "**Step 1: Find the proportion of lemonade in one drink:**\n",
    "\n",
    "* Lemonade: 1 1/4 cups\n",
    "* Iced tea: 1/4 cup\n",
    "* Total: 1 1/4 + 1/4 = 1 1/2 cups\n",
    "* Lemonade proportion: (1 1/4) / (1 1/2) = 5/6\n",
    "\n",
    "**Step 2: Calculate the amount of lemonade in the pitcher:**\n",
    "\n",
    "* Total volume: 18 cups\n",
    "* Lemonade proportion: 5/6\n",
    "* Volume of lemonade: 18 * (5/6) = 15 cups\n",
    "\n",
    "Therefore, there are 15 cups of lemonade in the pitcher. The answer is 15.\n",
    "\n",
    "Q: A deep-sea monster rises from the waters once every hundred years to feast on a ship and sate its hunger. Over three hundred years, it has consumed 847 people. Ships have been built larger over time, so each new ship has twice as many people as the last ship. How many people were on the ship the monster ate in the first hundred years?\n",
    "A: Let us solve it using algebra. Let x be the number of people on the ship the monster ate in the first hundred years.\n",
    "\n",
    "The number of people on the ship eaten in the second hundred years is 2x, and in the third hundred years is 4x.\n",
    "\n",
    "Therefore, the total number of people eaten over three hundred years is x + 2x + 4x = 847.\n",
    "\n",
    "Combining like terms, we get 7x = 847.\n",
    "\n",
    "Dividing both sides by 7, we find x = 121.\n",
    "\n",
    "Therefore, there were 121 people on the ship the monster ate in the first hundred years. The answer is 121.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_number_from_text(text, prefix=\"The answer is\"):\n",
    "    \"\"\"\n",
    "    Extracts the last number from a text string that follows a given prefix.\n",
    "    Args:\n",
    "        text (str): The text from which to extract the number.\n",
    "        prefix (str): The prefix to search for before extracting the number.\n",
    "    Returns:\n",
    "        float or None: The extracted number, or None if no valid number is found.\n",
    "    \"\"\"\n",
    "    # Find the part of the text that starts with the prefix\n",
    "    match = re.search(re.escape(prefix) + r\".*\", text)\n",
    "    if match:\n",
    "        # Extract all numbers from the matched text\n",
    "        numbers = re.findall(r\"[-+]?[0-9]*\\.?[0-9]+\", match.group(0))\n",
    "        if numbers:\n",
    "            # Return the last number found as a float\n",
    "            last_number = numbers[-1]\n",
    "            try:\n",
    "                return float(last_number)\n",
    "            except ValueError:\n",
    "                print(f\"Could not convert '{last_number}' to float.\")\n",
    "                return None\n",
    "    return None\n",
    "\n",
    "def extract_response_after_question(full_output, question):\n",
    "    \"\"\"\n",
    "    Extracts the line immediately following the question in the model's output.\n",
    "\n",
    "    Args:\n",
    "    - full_output (str): The complete output from the model.\n",
    "    - question (str): The question text used to locate the response line.\n",
    "\n",
    "    Returns:\n",
    "    - str: The line following the question line or None if not found.\n",
    "    \"\"\"\n",
    "    # Normalize line breaks\n",
    "    full_output = full_output.replace('\\r\\n', '\\n').replace('\\r', '\\n')\n",
    "    lines = full_output.split('\\n')\n",
    "\n",
    "    # Attempt to find the line containing the question\n",
    "    for i, line in enumerate(lines):\n",
    "        if question in line:\n",
    "            # Return the next line if it exists\n",
    "            if i + 1 < len(lines):\n",
    "                return lines[i + 1].strip()\n",
    "            break\n",
    "\n",
    "    return None\n",
    "\n",
    "# # Example Usage:\n",
    "# full_output = \"\"\"\n",
    "# Q: How many eggs do Janet's ducks lay?\n",
    "# A: Janet's ducks lay 16 eggs per day. She eats 3 for breakfast.\n",
    "# She bakes muffins with 4. She sells the rest for $2 per fresh duck egg.\n",
    "# So, she gets 16 * 3 - 4 * 2 = $48. The answer is $48.\n",
    "# \"\"\"\n",
    "# question = \"How many eggs do Janet's ducks lay?\"\n",
    "\n",
    "# next_line = extract_response_after_question(full_output, question)\n",
    "# print(f\"Response after the question: '{next_line}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_id 0\n",
      "Model answer: None\n",
      "Ground truth answer: 18.0\n",
      "Correct: 0 out of 1319\n",
      "========================================\n",
      "task_id 1\n",
      "Model answer: 2.5\n",
      "Ground truth answer: 3.0\n",
      "Correct: 0 out of 1319\n",
      "========================================\n",
      "task_id 2\n",
      "Model answer: 0.0\n",
      "Ground truth answer: 70000.0\n",
      "Correct: 0 out of 1319\n",
      "========================================\n",
      "task_id 3\n",
      "Model answer: 180.0\n",
      "Ground truth answer: 540.0\n",
      "Correct: 0 out of 1319\n",
      "========================================\n",
      "task_id 4\n",
      "Model answer: 40.0\n",
      "Ground truth answer: 20.0\n",
      "Correct: 0 out of 1319\n",
      "========================================\n",
      "task_id 5\n",
      "Model answer: None\n",
      "Ground truth answer: 64.0\n",
      "Correct: 0 out of 1319\n",
      "========================================\n",
      "task_id 6\n",
      "Model answer: 160.0\n",
      "Ground truth answer: 260.0\n",
      "Correct: 0 out of 1319\n",
      "========================================\n",
      "task_id 7\n",
      "Model answer: None\n",
      "Ground truth answer: 160.0\n",
      "Correct: 0 out of 1319\n",
      "========================================\n",
      "task_id 8\n",
      "Model answer: None\n",
      "Ground truth answer: 45.0\n",
      "Correct: 0 out of 1319\n",
      "========================================\n",
      "task_id 9\n",
      "Model answer: 450.0\n",
      "Ground truth answer: 460.0\n",
      "Correct: 0 out of 1319\n",
      "========================================\n",
      "task_id 10\n",
      "Model answer: None\n",
      "Ground truth answer: 366.0\n",
      "Correct: 0 out of 1319\n",
      "========================================\n",
      "task_id 11\n",
      "Model answer: 405.0\n",
      "Ground truth answer: 694.0\n",
      "Correct: 0 out of 1319\n",
      "========================================\n",
      "task_id 12\n",
      "Model answer: None\n",
      "Ground truth answer: 13.0\n",
      "Correct: 0 out of 1319\n",
      "========================================\n",
      "task_id 13\n",
      "Model answer: 2.0\n",
      "Ground truth answer: 18.0\n",
      "Correct: 0 out of 1319\n",
      "========================================\n",
      "task_id 14\n",
      "Model answer: None\n",
      "Ground truth answer: 60.0\n",
      "Correct: 0 out of 1319\n",
      "========================================\n",
      "task_id 15\n",
      "Model answer: None\n",
      "Ground truth answer: 125.0\n",
      "Correct: 0 out of 1319\n",
      "========================================\n",
      "task_id 16\n",
      "Model answer: 230.0\n",
      "Ground truth answer: 230.0\n",
      "Correct: 1 out of 1319\n",
      "========================================\n",
      "task_id 17\n",
      "Model answer: None\n",
      "Ground truth answer: 57500.0\n",
      "Correct: 1 out of 1319\n",
      "========================================\n",
      "task_id 18\n",
      "Model answer: 48.0\n",
      "Ground truth answer: 7.0\n",
      "Correct: 1 out of 1319\n",
      "========================================\n",
      "task_id 19\n",
      "Model answer: 3.0\n",
      "Ground truth answer: 6.0\n",
      "Correct: 1 out of 1319\n",
      "========================================\n",
      "task_id 20\n",
      "Model answer: 16.0\n",
      "Ground truth answer: 15.0\n",
      "Correct: 1 out of 1319\n",
      "========================================\n",
      "task_id 21\n",
      "Model answer: 29.0\n",
      "Ground truth answer: 14.0\n",
      "Correct: 1 out of 1319\n",
      "========================================\n",
      "task_id 22\n",
      "Model answer: 7.0\n",
      "Ground truth answer: 7.0\n",
      "Correct: 2 out of 1319\n",
      "========================================\n",
      "task_id 23\n",
      "Model answer: 8.0\n",
      "Ground truth answer: 8.0\n",
      "Correct: 3 out of 1319\n",
      "========================================\n",
      "task_id 24\n",
      "Model answer: 19.125\n",
      "Ground truth answer: 26.0\n",
      "Correct: 3 out of 1319\n",
      "========================================\n",
      "task_id 25\n",
      "Model answer: 1.0\n",
      "Ground truth answer: 2.0\n",
      "Correct: 3 out of 1319\n",
      "========================================\n",
      "task_id 26\n",
      "Model answer: None\n",
      "Ground truth answer: 243.0\n",
      "Correct: 3 out of 1319\n",
      "========================================\n",
      "task_id 27\n",
      "Model answer: 3600.0\n",
      "Ground truth answer: 16.0\n",
      "Correct: 3 out of 1319\n",
      "========================================\n",
      "task_id 28\n",
      "Model answer: 35.0\n",
      "Ground truth answer: 25.0\n",
      "Correct: 3 out of 1319\n",
      "========================================\n",
      "task_id 29\n",
      "Model answer: 10.0\n",
      "Ground truth answer: 104.0\n",
      "Correct: 3 out of 1319\n",
      "========================================\n",
      "task_id 30\n",
      "Model answer: 11.0\n",
      "Ground truth answer: 109.0\n",
      "Correct: 3 out of 1319\n",
      "========================================\n",
      "task_id 31\n",
      "Model answer: 100.0\n",
      "Ground truth answer: 80.0\n",
      "Correct: 3 out of 1319\n",
      "========================================\n",
      "task_id 32\n",
      "Model answer: 35.0\n",
      "Ground truth answer: 35.0\n",
      "Correct: 4 out of 1319\n",
      "========================================\n",
      "task_id 33\n",
      "Model answer: 80.0\n",
      "Ground truth answer: 70.0\n",
      "Correct: 4 out of 1319\n",
      "========================================\n",
      "task_id 34\n",
      "Model answer: 36.0\n",
      "Ground truth answer: 23.0\n",
      "Correct: 4 out of 1319\n",
      "========================================\n",
      "task_id 35\n",
      "Model answer: 9.0\n",
      "Ground truth answer: 9.0\n",
      "Correct: 5 out of 1319\n",
      "========================================\n",
      "task_id 36\n",
      "Model answer: 300.0\n",
      "Ground truth answer: 75.0\n",
      "Correct: 5 out of 1319\n",
      "========================================\n",
      "task_id 37\n",
      "Model answer: 2.0\n",
      "Ground truth answer: 2.0\n",
      "Correct: 6 out of 1319\n",
      "========================================\n",
      "task_id 38\n",
      "Model answer: None\n",
      "Ground truth answer: 10.0\n",
      "Correct: 6 out of 1319\n",
      "========================================\n",
      "task_id 39\n",
      "Model answer: None\n",
      "Ground truth answer: 18.0\n",
      "Correct: 6 out of 1319\n",
      "========================================\n",
      "task_id 40\n",
      "Model answer: 8.0\n",
      "Ground truth answer: 8.0\n",
      "Correct: 7 out of 1319\n",
      "========================================\n",
      "task_id 41\n",
      "Model answer: None\n",
      "Ground truth answer: 200.0\n",
      "Correct: 7 out of 1319\n",
      "========================================\n",
      "task_id 42\n",
      "Model answer: None\n",
      "Ground truth answer: 26.0\n",
      "Correct: 7 out of 1319\n",
      "========================================\n",
      "task_id 43\n",
      "Model answer: None\n",
      "Ground truth answer: 48.0\n",
      "Correct: 7 out of 1319\n",
      "========================================\n",
      "task_id 44\n",
      "Model answer: None\n",
      "Ground truth answer: 20.0\n",
      "Correct: 7 out of 1319\n",
      "========================================\n",
      "task_id 45\n",
      "Model answer: 17.0\n",
      "Ground truth answer: 104.0\n",
      "Correct: 7 out of 1319\n",
      "========================================\n",
      "task_id 46\n",
      "Model answer: 103.0\n",
      "Ground truth answer: 163.0\n",
      "Correct: 7 out of 1319\n",
      "========================================\n",
      "task_id 47\n",
      "Model answer: 120.0\n",
      "Ground truth answer: 800.0\n",
      "Correct: 7 out of 1319\n",
      "========================================\n",
      "task_id 48\n",
      "Model answer: 24.0\n",
      "Ground truth answer: 8.0\n",
      "Correct: 7 out of 1319\n",
      "========================================\n",
      "task_id 49\n",
      "Model answer: 3.75\n",
      "Ground truth answer: 30.0\n",
      "Correct: 7 out of 1319\n",
      "========================================\n",
      "task_id 50\n",
      "Model answer: None\n",
      "Ground truth answer: 294.0\n",
      "Correct: 7 out of 1319\n",
      "========================================\n",
      "task_id 51\n",
      "Model answer: 10.0\n",
      "Ground truth answer: 5.0\n",
      "Correct: 7 out of 1319\n",
      "========================================\n",
      "task_id 52\n",
      "Model answer: None\n",
      "Ground truth answer: 15.0\n",
      "Correct: 7 out of 1319\n",
      "========================================\n",
      "task_id 53\n",
      "Model answer: None\n",
      "Ground truth answer: 40.0\n",
      "Correct: 7 out of 1319\n",
      "========================================\n",
      "task_id 54\n",
      "Model answer: 28.0\n",
      "Ground truth answer: 40.0\n",
      "Correct: 7 out of 1319\n",
      "========================================\n",
      "task_id 55\n",
      "Model answer: 14.0\n",
      "Ground truth answer: 14.0\n",
      "Correct: 8 out of 1319\n",
      "========================================\n",
      "task_id 56\n",
      "Model answer: 42.0\n",
      "Ground truth answer: 3.0\n",
      "Correct: 8 out of 1319\n",
      "========================================\n",
      "task_id 57\n",
      "Model answer: 11245.0\n",
      "Ground truth answer: 83.0\n",
      "Correct: 8 out of 1319\n",
      "========================================\n",
      "task_id 58\n",
      "Model answer: None\n",
      "Ground truth answer: 57.0\n",
      "Correct: 8 out of 1319\n",
      "========================================\n",
      "task_id 59\n",
      "Model answer: 1267.0\n",
      "Ground truth answer: 187.0\n",
      "Correct: 8 out of 1319\n",
      "========================================\n",
      "task_id 60\n",
      "Model answer: 22.0\n",
      "Ground truth answer: 17.0\n",
      "Correct: 8 out of 1319\n",
      "========================================\n",
      "task_id 61\n",
      "Model answer: 1380.0\n",
      "Ground truth answer: 1430.0\n",
      "Correct: 8 out of 1319\n",
      "========================================\n",
      "task_id 62\n",
      "Model answer: 5000.0\n",
      "Ground truth answer: 25000.0\n",
      "Correct: 8 out of 1319\n",
      "========================================\n",
      "task_id 63\n",
      "Model answer: None\n",
      "Ground truth answer: 1596.0\n",
      "Correct: 8 out of 1319\n",
      "========================================\n",
      "task_id 64\n",
      "Model answer: 8.0\n",
      "Ground truth answer: 300.0\n",
      "Correct: 8 out of 1319\n",
      "========================================\n",
      "task_id 65\n",
      "Model answer: 5.0\n",
      "Ground truth answer: 36.0\n",
      "Correct: 8 out of 1319\n",
      "========================================\n",
      "task_id 66\n",
      "Model answer: 40.0\n",
      "Ground truth answer: 48.0\n",
      "Correct: 8 out of 1319\n",
      "========================================\n",
      "task_id 67\n",
      "Model answer: 200.0\n",
      "Ground truth answer: 595.0\n",
      "Correct: 8 out of 1319\n",
      "========================================\n",
      "task_id 68\n",
      "Model answer: 72.0\n",
      "Ground truth answer: 36.0\n",
      "Correct: 8 out of 1319\n",
      "========================================\n",
      "task_id 69\n",
      "Model answer: 60.0\n",
      "Ground truth answer: 60.0\n",
      "Correct: 9 out of 1319\n",
      "========================================\n",
      "task_id 70\n",
      "Model answer: 2925.0\n",
      "Ground truth answer: 7425.0\n",
      "Correct: 9 out of 1319\n",
      "========================================\n",
      "task_id 71\n",
      "Model answer: 60.0\n",
      "Ground truth answer: 60.0\n",
      "Correct: 10 out of 1319\n",
      "========================================\n",
      "task_id 72\n",
      "Model answer: 218.0\n",
      "Ground truth answer: 221.0\n",
      "Correct: 10 out of 1319\n",
      "========================================\n",
      "task_id 73\n",
      "Model answer: 750.0\n",
      "Ground truth answer: 255.0\n",
      "Correct: 10 out of 1319\n",
      "========================================\n",
      "task_id 74\n",
      "Model answer: None\n",
      "Ground truth answer: 88.0\n",
      "Correct: 10 out of 1319\n",
      "========================================\n",
      "task_id 75\n",
      "Model answer: 0.25\n",
      "Ground truth answer: 60.0\n",
      "Correct: 10 out of 1319\n",
      "========================================\n",
      "task_id 76\n",
      "Model answer: 185.0\n",
      "Ground truth answer: 5.0\n",
      "Correct: 10 out of 1319\n",
      "========================================\n",
      "task_id 77\n",
      "Model answer: None\n",
      "Ground truth answer: 100.0\n",
      "Correct: 10 out of 1319\n",
      "========================================\n",
      "task_id 78\n",
      "Model answer: 2.0\n",
      "Ground truth answer: 6.0\n",
      "Correct: 10 out of 1319\n",
      "========================================\n",
      "task_id 79\n",
      "Model answer: 70.0\n",
      "Ground truth answer: 70.0\n",
      "Correct: 11 out of 1319\n",
      "========================================\n",
      "task_id 80\n",
      "Model answer: 2.0\n",
      "Ground truth answer: 10.0\n",
      "Correct: 11 out of 1319\n",
      "========================================\n",
      "task_id 81\n",
      "Model answer: -34.0\n",
      "Ground truth answer: 17.0\n",
      "Correct: 11 out of 1319\n",
      "========================================\n",
      "task_id 82\n",
      "Model answer: 248.0\n",
      "Ground truth answer: 623.0\n",
      "Correct: 11 out of 1319\n",
      "========================================\n",
      "task_id 83\n",
      "Model answer: 600.0\n",
      "Ground truth answer: 600.0\n",
      "Correct: 12 out of 1319\n",
      "========================================\n",
      "task_id 84\n",
      "Model answer: 22.0\n",
      "Ground truth answer: 15.0\n",
      "Correct: 12 out of 1319\n",
      "========================================\n",
      "task_id 85\n",
      "Model answer: 48.0\n",
      "Ground truth answer: 44.0\n",
      "Correct: 12 out of 1319\n",
      "========================================\n",
      "task_id 86\n",
      "Model answer: None\n",
      "Ground truth answer: 22.0\n",
      "Correct: 12 out of 1319\n",
      "========================================\n",
      "task_id 87\n",
      "Model answer: 738.0\n",
      "Ground truth answer: 9360.0\n",
      "Correct: 12 out of 1319\n",
      "========================================\n",
      "task_id 88\n",
      "Model answer: 200.0\n",
      "Ground truth answer: 8000.0\n",
      "Correct: 12 out of 1319\n",
      "========================================\n",
      "task_id 89\n",
      "Model answer: 8.0\n",
      "Ground truth answer: 24.0\n",
      "Correct: 12 out of 1319\n",
      "========================================\n",
      "task_id 90\n",
      "Model answer: 200.0\n",
      "Ground truth answer: 225.0\n",
      "Correct: 12 out of 1319\n",
      "========================================\n",
      "task_id 91\n",
      "Model answer: 15.0\n",
      "Ground truth answer: 28.0\n",
      "Correct: 12 out of 1319\n",
      "========================================\n",
      "task_id 92\n",
      "Model answer: None\n",
      "Ground truth answer: 4.0\n",
      "Correct: 12 out of 1319\n",
      "========================================\n",
      "task_id 93\n",
      "Model answer: 36.0\n",
      "Ground truth answer: 36.0\n",
      "Correct: 13 out of 1319\n",
      "========================================\n",
      "task_id 94\n",
      "Model answer: 120.0\n",
      "Ground truth answer: 348.0\n",
      "Correct: 13 out of 1319\n",
      "========================================\n",
      "task_id 95\n",
      "Model answer: 140.0\n",
      "Ground truth answer: 40.0\n",
      "Correct: 13 out of 1319\n",
      "========================================\n",
      "task_id 96\n",
      "Model answer: 3.0\n",
      "Ground truth answer: 3.0\n",
      "Correct: 14 out of 1319\n",
      "========================================\n",
      "task_id 97\n",
      "Model answer: 48.0\n",
      "Ground truth answer: 12.0\n",
      "Correct: 14 out of 1319\n",
      "========================================\n",
      "task_id 98\n",
      "Model answer: 30.0\n",
      "Ground truth answer: 5.0\n",
      "Correct: 14 out of 1319\n",
      "========================================\n",
      "task_id 99\n",
      "Model answer: 0.0\n",
      "Ground truth answer: 58.0\n",
      "Correct: 14 out of 1319\n",
      "========================================\n",
      "task_id 100\n",
      "Model answer: None\n",
      "Ground truth answer: 175.0\n",
      "Correct: 14 out of 1319\n",
      "========================================\n",
      "task_id 101\n",
      "Model answer: 2.75\n",
      "Ground truth answer: 6.0\n",
      "Correct: 14 out of 1319\n",
      "========================================\n",
      "task_id 102\n",
      "Model answer: None\n",
      "Ground truth answer: 26.0\n",
      "Correct: 14 out of 1319\n",
      "========================================\n",
      "task_id 103\n",
      "Model answer: 420.0\n",
      "Ground truth answer: 140.0\n",
      "Correct: 14 out of 1319\n",
      "========================================\n",
      "task_id 104\n",
      "Model answer: None\n",
      "Ground truth answer: 500.0\n",
      "Correct: 14 out of 1319\n",
      "========================================\n",
      "task_id 105\n",
      "Model answer: 15.0\n",
      "Ground truth answer: 20.0\n",
      "Correct: 14 out of 1319\n",
      "========================================\n",
      "task_id 106\n",
      "Model answer: 14400.0\n",
      "Ground truth answer: 72.0\n",
      "Correct: 14 out of 1319\n",
      "========================================\n",
      "task_id 107\n",
      "Model answer: 4.0\n",
      "Ground truth answer: 3.0\n",
      "Correct: 14 out of 1319\n",
      "========================================\n",
      "task_id 108\n",
      "Model answer: 125.0\n",
      "Ground truth answer: 50.0\n",
      "Correct: 14 out of 1319\n",
      "========================================\n",
      "task_id 109\n",
      "Model answer: 2.0\n",
      "Ground truth answer: 28.0\n",
      "Correct: 14 out of 1319\n",
      "========================================\n",
      "task_id 110\n",
      "Model answer: 38.0\n",
      "Ground truth answer: 45.0\n",
      "Correct: 14 out of 1319\n",
      "========================================\n",
      "task_id 111\n",
      "Model answer: 2.0\n",
      "Ground truth answer: 16.0\n",
      "Correct: 14 out of 1319\n",
      "========================================\n",
      "task_id 112\n",
      "Model answer: 24.0\n",
      "Ground truth answer: 24.0\n",
      "Correct: 15 out of 1319\n",
      "========================================\n",
      "task_id 113\n",
      "Model answer: 25.0\n",
      "Ground truth answer: 25.0\n",
      "Correct: 16 out of 1319\n",
      "========================================\n",
      "task_id 114\n",
      "Model answer: None\n",
      "Ground truth answer: 6.0\n",
      "Correct: 16 out of 1319\n",
      "========================================\n",
      "task_id 115\n",
      "Model answer: 100.0\n",
      "Ground truth answer: 90.0\n",
      "Correct: 16 out of 1319\n",
      "========================================\n",
      "task_id 116\n",
      "Model answer: 13.0\n",
      "Ground truth answer: 42.0\n",
      "Correct: 16 out of 1319\n",
      "========================================\n",
      "task_id 117\n",
      "Model answer: 360.0\n",
      "Ground truth answer: 360.0\n",
      "Correct: 17 out of 1319\n",
      "========================================\n",
      "task_id 118\n",
      "Model answer: None\n",
      "Ground truth answer: 4.0\n",
      "Correct: 17 out of 1319\n",
      "========================================\n",
      "task_id 119\n",
      "Model answer: None\n",
      "Ground truth answer: 95200.0\n",
      "Correct: 17 out of 1319\n",
      "========================================\n",
      "task_id 120\n",
      "Model answer: 60.0\n",
      "Ground truth answer: 240.0\n",
      "Correct: 17 out of 1319\n",
      "========================================\n",
      "task_id 121\n",
      "Model answer: None\n",
      "Ground truth answer: 27.0\n",
      "Correct: 17 out of 1319\n",
      "========================================\n",
      "task_id 122\n",
      "Model answer: 7.0\n",
      "Ground truth answer: 48.0\n",
      "Correct: 17 out of 1319\n",
      "========================================\n",
      "task_id 123\n",
      "Model answer: 15.0\n",
      "Ground truth answer: 50.0\n",
      "Correct: 17 out of 1319\n",
      "========================================\n",
      "task_id 124\n",
      "Model answer: 50.0\n",
      "Ground truth answer: 10.0\n",
      "Correct: 17 out of 1319\n",
      "========================================\n",
      "task_id 125\n",
      "Model answer: 9.0\n",
      "Ground truth answer: 10.0\n",
      "Correct: 17 out of 1319\n",
      "========================================\n",
      "task_id 126\n",
      "Model answer: 45.0\n",
      "Ground truth answer: 82.0\n",
      "Correct: 17 out of 1319\n",
      "========================================\n",
      "task_id 127\n",
      "Model answer: 70.0\n",
      "Ground truth answer: 120.0\n",
      "Correct: 17 out of 1319\n",
      "========================================\n",
      "task_id 128\n",
      "Model answer: None\n",
      "Ground truth answer: 880.0\n",
      "Correct: 17 out of 1319\n",
      "========================================\n",
      "task_id 129\n",
      "Model answer: 25.0\n",
      "Ground truth answer: 10000.0\n",
      "Correct: 17 out of 1319\n",
      "========================================\n",
      "task_id 130\n",
      "Model answer: 30.0\n",
      "Ground truth answer: 30.0\n",
      "Correct: 18 out of 1319\n",
      "========================================\n",
      "task_id 131\n",
      "Model answer: 940.0\n",
      "Ground truth answer: 940.0\n",
      "Correct: 19 out of 1319\n",
      "========================================\n",
      "task_id 132\n",
      "Model answer: 0.0\n",
      "Ground truth answer: 60.0\n",
      "Correct: 19 out of 1319\n",
      "========================================\n",
      "task_id 133\n",
      "Model answer: 17.0\n",
      "Ground truth answer: 13.0\n",
      "Correct: 19 out of 1319\n",
      "========================================\n",
      "task_id 134\n",
      "Model answer: 60.0\n",
      "Ground truth answer: 720.0\n",
      "Correct: 19 out of 1319\n",
      "========================================\n",
      "task_id 135\n",
      "Model answer: 55.0\n",
      "Ground truth answer: 40.0\n",
      "Correct: 19 out of 1319\n",
      "========================================\n",
      "task_id 136\n",
      "Model answer: None\n",
      "Ground truth answer: 6.0\n",
      "Correct: 19 out of 1319\n",
      "========================================\n",
      "task_id 137\n",
      "Model answer: None\n",
      "Ground truth answer: 29.0\n",
      "Correct: 19 out of 1319\n",
      "========================================\n",
      "task_id 138\n",
      "Model answer: None\n",
      "Ground truth answer: 105.0\n",
      "Correct: 19 out of 1319\n",
      "========================================\n",
      "task_id 139\n",
      "Model answer: 34.0\n",
      "Ground truth answer: 70.0\n",
      "Correct: 19 out of 1319\n",
      "========================================\n",
      "task_id 140\n",
      "Model answer: 20.0\n",
      "Ground truth answer: 20.0\n",
      "Correct: 20 out of 1319\n",
      "========================================\n",
      "task_id 141\n",
      "Model answer: None\n",
      "Ground truth answer: 400.0\n",
      "Correct: 20 out of 1319\n",
      "========================================\n",
      "task_id 142\n",
      "Model answer: 110.0\n",
      "Ground truth answer: 140.0\n",
      "Correct: 20 out of 1319\n",
      "========================================\n",
      "task_id 143\n",
      "Model answer: None\n",
      "Ground truth answer: 16.0\n",
      "Correct: 20 out of 1319\n",
      "========================================\n",
      "task_id 144\n",
      "Model answer: None\n",
      "Ground truth answer: 20.0\n",
      "Correct: 20 out of 1319\n",
      "========================================\n",
      "task_id 145\n",
      "Model answer: 1332.0\n",
      "Ground truth answer: 4000.0\n",
      "Correct: 20 out of 1319\n",
      "========================================\n",
      "task_id 146\n",
      "Model answer: 3000.0\n",
      "Ground truth answer: 125.0\n",
      "Correct: 20 out of 1319\n",
      "========================================\n",
      "task_id 147\n",
      "Model answer: None\n",
      "Ground truth answer: 75.0\n",
      "Correct: 20 out of 1319\n",
      "========================================\n",
      "task_id 148\n",
      "Model answer: 2.0\n",
      "Ground truth answer: 30.0\n",
      "Correct: 20 out of 1319\n",
      "========================================\n",
      "task_id 149\n",
      "Model answer: 3.0\n",
      "Ground truth answer: 16.0\n",
      "Correct: 20 out of 1319\n",
      "========================================\n",
      "task_id 150\n",
      "Model answer: None\n",
      "Ground truth answer: 4.0\n",
      "Correct: 20 out of 1319\n",
      "========================================\n",
      "task_id 151\n",
      "Model answer: 2.25\n",
      "Ground truth answer: 5.0\n",
      "Correct: 20 out of 1319\n",
      "========================================\n",
      "task_id 152\n",
      "Model answer: 4.0\n",
      "Ground truth answer: 4.0\n",
      "Correct: 21 out of 1319\n",
      "========================================\n",
      "task_id 153\n",
      "Model answer: None\n",
      "Ground truth answer: 48.0\n",
      "Correct: 21 out of 1319\n",
      "========================================\n",
      "task_id 154\n",
      "Model answer: 16.0\n",
      "Ground truth answer: 272.0\n",
      "Correct: 21 out of 1319\n",
      "========================================\n",
      "task_id 155\n",
      "Model answer: None\n",
      "Ground truth answer: 280.0\n",
      "Correct: 21 out of 1319\n",
      "========================================\n",
      "task_id 156\n",
      "Model answer: 700.0\n",
      "Ground truth answer: 1400.0\n",
      "Correct: 21 out of 1319\n",
      "========================================\n",
      "task_id 157\n",
      "Model answer: 1900.0\n",
      "Ground truth answer: 80.0\n",
      "Correct: 21 out of 1319\n",
      "========================================\n",
      "task_id 158\n",
      "Model answer: 34.0\n",
      "Ground truth answer: 34.0\n",
      "Correct: 22 out of 1319\n",
      "========================================\n",
      "task_id 159\n",
      "Model answer: 3.0\n",
      "Ground truth answer: 15.0\n",
      "Correct: 22 out of 1319\n",
      "========================================\n",
      "task_id 160\n",
      "Model answer: 8.0\n",
      "Ground truth answer: 16.0\n",
      "Correct: 22 out of 1319\n",
      "========================================\n",
      "task_id 161\n",
      "Model answer: None\n",
      "Ground truth answer: 32.0\n",
      "Correct: 22 out of 1319\n",
      "========================================\n",
      "task_id 162\n",
      "Model answer: None\n",
      "Ground truth answer: 92.0\n",
      "Correct: 22 out of 1319\n",
      "========================================\n",
      "task_id 163\n",
      "Model answer: 42.0\n",
      "Ground truth answer: 50.0\n",
      "Correct: 22 out of 1319\n",
      "========================================\n",
      "task_id 164\n",
      "Model answer: 55.0\n",
      "Ground truth answer: 15.0\n",
      "Correct: 22 out of 1319\n",
      "========================================\n",
      "task_id 165\n",
      "Model answer: 55.0\n",
      "Ground truth answer: 77.0\n",
      "Correct: 22 out of 1319\n",
      "========================================\n",
      "task_id 166\n",
      "Model answer: 5.0\n",
      "Ground truth answer: 5.0\n",
      "Correct: 23 out of 1319\n",
      "========================================\n",
      "task_id 167\n",
      "Model answer: 24.0\n",
      "Ground truth answer: 16.0\n",
      "Correct: 23 out of 1319\n",
      "========================================\n",
      "task_id 168\n",
      "Model answer: 8.0\n",
      "Ground truth answer: 18.0\n",
      "Correct: 23 out of 1319\n",
      "========================================\n",
      "task_id 169\n",
      "Model answer: 30.0\n",
      "Ground truth answer: 120.0\n",
      "Correct: 23 out of 1319\n",
      "========================================\n",
      "task_id 170\n",
      "Model answer: None\n",
      "Ground truth answer: 150.0\n",
      "Correct: 23 out of 1319\n",
      "========================================\n",
      "task_id 171\n",
      "Model answer: 600.0\n",
      "Ground truth answer: 1210.0\n",
      "Correct: 23 out of 1319\n",
      "========================================\n",
      "task_id 172\n",
      "Model answer: None\n",
      "Ground truth answer: 51.0\n",
      "Correct: 23 out of 1319\n",
      "========================================\n",
      "task_id 173\n",
      "Model answer: None\n",
      "Ground truth answer: 18000.0\n",
      "Correct: 23 out of 1319\n",
      "========================================\n",
      "task_id 174\n",
      "Model answer: 39.0\n",
      "Ground truth answer: 95.0\n",
      "Correct: 23 out of 1319\n",
      "========================================\n",
      "task_id 175\n",
      "Model answer: 24.5\n",
      "Ground truth answer: 15.0\n",
      "Correct: 23 out of 1319\n",
      "========================================\n",
      "task_id 176\n",
      "Model answer: 100.0\n",
      "Ground truth answer: 100.0\n",
      "Correct: 24 out of 1319\n",
      "========================================\n",
      "task_id 177\n",
      "Model answer: None\n",
      "Ground truth answer: 350.0\n",
      "Correct: 24 out of 1319\n",
      "========================================\n",
      "task_id 178\n",
      "Model answer: None\n",
      "Ground truth answer: 122.0\n",
      "Correct: 24 out of 1319\n",
      "========================================\n",
      "task_id 179\n",
      "Model answer: 130.0\n",
      "Ground truth answer: 130.0\n",
      "Correct: 25 out of 1319\n",
      "========================================\n",
      "task_id 180\n",
      "Model answer: 60.0\n",
      "Ground truth answer: 20.0\n",
      "Correct: 25 out of 1319\n",
      "========================================\n",
      "task_id 181\n",
      "Model answer: None\n",
      "Ground truth answer: 160.0\n",
      "Correct: 25 out of 1319\n",
      "========================================\n",
      "task_id 182\n",
      "Model answer: None\n",
      "Ground truth answer: 23.0\n",
      "Correct: 25 out of 1319\n",
      "========================================\n",
      "task_id 183\n",
      "Model answer: 5.0\n",
      "Ground truth answer: 2.0\n",
      "Correct: 25 out of 1319\n",
      "========================================\n",
      "task_id 184\n",
      "Model answer: None\n",
      "Ground truth answer: 25.0\n",
      "Correct: 25 out of 1319\n",
      "========================================\n",
      "task_id 185\n",
      "Model answer: 10.0\n",
      "Ground truth answer: 30.0\n",
      "Correct: 25 out of 1319\n",
      "========================================\n",
      "task_id 186\n",
      "Model answer: None\n",
      "Ground truth answer: 5.0\n",
      "Correct: 25 out of 1319\n",
      "========================================\n",
      "task_id 187\n",
      "Model answer: 6.0\n",
      "Ground truth answer: 106.0\n",
      "Correct: 25 out of 1319\n",
      "========================================\n",
      "task_id 188\n",
      "Model answer: -40.0\n",
      "Ground truth answer: 50.0\n",
      "Correct: 25 out of 1319\n",
      "========================================\n",
      "task_id 189\n",
      "Model answer: 68.25\n",
      "Ground truth answer: 34.0\n",
      "Correct: 25 out of 1319\n",
      "========================================\n",
      "task_id 190\n",
      "Model answer: 120.0\n",
      "Ground truth answer: 360.0\n",
      "Correct: 25 out of 1319\n",
      "========================================\n",
      "task_id 191\n",
      "Model answer: 24.5\n",
      "Ground truth answer: 5.0\n",
      "Correct: 25 out of 1319\n",
      "========================================\n",
      "task_id 192\n",
      "Model answer: 30.0\n",
      "Ground truth answer: 91.0\n",
      "Correct: 25 out of 1319\n",
      "========================================\n",
      "task_id 193\n",
      "Model answer: None\n",
      "Ground truth answer: 24.0\n",
      "Correct: 25 out of 1319\n",
      "========================================\n",
      "task_id 194\n",
      "Model answer: 10.0\n",
      "Ground truth answer: 10.0\n",
      "Correct: 26 out of 1319\n",
      "========================================\n",
      "task_id 195\n",
      "Model answer: 12.0\n",
      "Ground truth answer: 12.0\n",
      "Correct: 27 out of 1319\n",
      "========================================\n",
      "task_id 196\n",
      "Model answer: 5.0\n",
      "Ground truth answer: 120.0\n",
      "Correct: 27 out of 1319\n",
      "========================================\n",
      "task_id 197\n",
      "Model answer: 12277.0\n",
      "Ground truth answer: 6277.0\n",
      "Correct: 27 out of 1319\n",
      "========================================\n",
      "task_id 198\n",
      "Model answer: 220.0\n",
      "Ground truth answer: 320.0\n",
      "Correct: 27 out of 1319\n",
      "========================================\n",
      "task_id 199\n",
      "Model answer: 5000.0\n",
      "Ground truth answer: 7500.0\n",
      "Correct: 27 out of 1319\n",
      "========================================\n",
      "task_id 200\n",
      "Model answer: 61.0\n",
      "Ground truth answer: 55.0\n",
      "Correct: 27 out of 1319\n",
      "========================================\n",
      "task_id 201\n",
      "Model answer: 2000.0\n",
      "Ground truth answer: 200.0\n",
      "Correct: 27 out of 1319\n",
      "========================================\n",
      "task_id 202\n",
      "Model answer: 100.0\n",
      "Ground truth answer: 100.0\n",
      "Correct: 28 out of 1319\n",
      "========================================\n",
      "task_id 203\n",
      "Model answer: None\n",
      "Ground truth answer: 31.0\n",
      "Correct: 28 out of 1319\n",
      "========================================\n",
      "task_id 204\n",
      "Model answer: None\n",
      "Ground truth answer: 98.0\n",
      "Correct: 28 out of 1319\n",
      "========================================\n",
      "task_id 205\n",
      "Model answer: 93.0\n",
      "Ground truth answer: 98.0\n",
      "Correct: 28 out of 1319\n",
      "========================================\n",
      "task_id 206\n",
      "Model answer: 180.0\n",
      "Ground truth answer: 860.0\n",
      "Correct: 28 out of 1319\n",
      "========================================\n",
      "task_id 207\n",
      "Model answer: 1000.0\n",
      "Ground truth answer: 2600.0\n",
      "Correct: 28 out of 1319\n",
      "========================================\n",
      "task_id 208\n",
      "Model answer: 20.0\n",
      "Ground truth answer: 76.0\n",
      "Correct: 28 out of 1319\n",
      "========================================\n",
      "task_id 209\n",
      "Model answer: 7200.0\n",
      "Ground truth answer: 145.0\n",
      "Correct: 28 out of 1319\n",
      "========================================\n",
      "task_id 210\n",
      "Model answer: None\n",
      "Ground truth answer: 10.0\n",
      "Correct: 28 out of 1319\n",
      "========================================\n",
      "task_id 211\n",
      "Model answer: 44.0\n",
      "Ground truth answer: 4.0\n",
      "Correct: 28 out of 1319\n",
      "========================================\n",
      "task_id 212\n",
      "Model answer: 1.5\n",
      "Ground truth answer: 5.0\n",
      "Correct: 28 out of 1319\n",
      "========================================\n",
      "task_id 213\n",
      "Model answer: 200.0\n",
      "Ground truth answer: 250.0\n",
      "Correct: 28 out of 1319\n",
      "========================================\n",
      "task_id 214\n",
      "Model answer: None\n",
      "Ground truth answer: 8.0\n",
      "Correct: 28 out of 1319\n",
      "========================================\n",
      "task_id 215\n",
      "Model answer: 44.0\n",
      "Ground truth answer: 44.0\n",
      "Correct: 29 out of 1319\n",
      "========================================\n",
      "task_id 216\n",
      "Model answer: 22.0\n",
      "Ground truth answer: 220.0\n",
      "Correct: 29 out of 1319\n",
      "========================================\n",
      "task_id 217\n",
      "Model answer: 15.0\n",
      "Ground truth answer: 15.0\n",
      "Correct: 30 out of 1319\n",
      "========================================\n",
      "task_id 218\n",
      "Model answer: None\n",
      "Ground truth answer: 45.0\n",
      "Correct: 30 out of 1319\n",
      "========================================\n",
      "task_id 219\n",
      "Model answer: 100.0\n",
      "Ground truth answer: 54.0\n",
      "Correct: 30 out of 1319\n",
      "========================================\n",
      "task_id 220\n",
      "Model answer: 130.0\n",
      "Ground truth answer: 70.0\n",
      "Correct: 30 out of 1319\n",
      "========================================\n",
      "task_id 221\n",
      "Model answer: 90.0\n",
      "Ground truth answer: 90.0\n",
      "Correct: 31 out of 1319\n",
      "========================================\n",
      "task_id 222\n",
      "Model answer: 140.0\n",
      "Ground truth answer: 140.0\n",
      "Correct: 32 out of 1319\n",
      "========================================\n",
      "task_id 223\n",
      "Model answer: 20000.0\n",
      "Ground truth answer: 20000.0\n",
      "Correct: 33 out of 1319\n",
      "========================================\n",
      "task_id 224\n",
      "Model answer: 90.0\n",
      "Ground truth answer: 180.0\n",
      "Correct: 33 out of 1319\n",
      "========================================\n",
      "task_id 225\n",
      "Model answer: 9.0\n",
      "Ground truth answer: 9.0\n",
      "Correct: 34 out of 1319\n",
      "========================================\n",
      "task_id 226\n",
      "Model answer: 64.0\n",
      "Ground truth answer: 33.0\n",
      "Correct: 34 out of 1319\n",
      "========================================\n",
      "task_id 227\n",
      "Model answer: None\n",
      "Ground truth answer: 9.0\n",
      "Correct: 34 out of 1319\n",
      "========================================\n",
      "task_id 228\n",
      "Model answer: 2.0\n",
      "Ground truth answer: 1.0\n",
      "Correct: 34 out of 1319\n",
      "========================================\n",
      "task_id 229\n",
      "Model answer: 16.0\n",
      "Ground truth answer: 21.0\n",
      "Correct: 34 out of 1319\n",
      "========================================\n",
      "task_id 230\n",
      "Model answer: 3000.0\n",
      "Ground truth answer: 0.0\n",
      "Correct: 34 out of 1319\n",
      "========================================\n",
      "task_id 231\n",
      "Model answer: 50.0\n",
      "Ground truth answer: 50.0\n",
      "Correct: 35 out of 1319\n",
      "========================================\n",
      "task_id 232\n",
      "Model answer: 25.0\n",
      "Ground truth answer: 75.0\n",
      "Correct: 35 out of 1319\n",
      "========================================\n",
      "task_id 233\n",
      "Model answer: 9.0\n",
      "Ground truth answer: 12.0\n",
      "Correct: 35 out of 1319\n",
      "========================================\n",
      "task_id 234\n",
      "Model answer: 63.0\n",
      "Ground truth answer: 21.0\n",
      "Correct: 35 out of 1319\n",
      "========================================\n",
      "task_id 235\n",
      "Model answer: 10.0\n",
      "Ground truth answer: 10.0\n",
      "Correct: 36 out of 1319\n",
      "========================================\n",
      "task_id 236\n",
      "Model answer: 25.0\n",
      "Ground truth answer: 31.0\n",
      "Correct: 36 out of 1319\n",
      "========================================\n",
      "task_id 237\n",
      "Model answer: 90.0\n",
      "Ground truth answer: 90.0\n",
      "Correct: 37 out of 1319\n",
      "========================================\n",
      "task_id 238\n",
      "Model answer: 37.0\n",
      "Ground truth answer: 68.0\n",
      "Correct: 37 out of 1319\n",
      "========================================\n",
      "task_id 239\n",
      "Model answer: None\n",
      "Ground truth answer: 280.0\n",
      "Correct: 37 out of 1319\n",
      "========================================\n",
      "task_id 240\n",
      "Model answer: 18.0\n",
      "Ground truth answer: 21.0\n",
      "Correct: 37 out of 1319\n",
      "========================================\n",
      "task_id 241\n",
      "Model answer: None\n",
      "Ground truth answer: 6.0\n",
      "Correct: 37 out of 1319\n",
      "========================================\n",
      "task_id 242\n",
      "Model answer: 120.0\n",
      "Ground truth answer: 3.0\n",
      "Correct: 37 out of 1319\n",
      "========================================\n",
      "task_id 243\n",
      "Model answer: 300.0\n",
      "Ground truth answer: 250.0\n",
      "Correct: 37 out of 1319\n",
      "========================================\n",
      "task_id 244\n",
      "Model answer: 3.0\n",
      "Ground truth answer: 20.0\n",
      "Correct: 37 out of 1319\n",
      "========================================\n",
      "task_id 245\n",
      "Model answer: 28.0\n",
      "Ground truth answer: 7.0\n",
      "Correct: 37 out of 1319\n",
      "========================================\n",
      "task_id 246\n",
      "Model answer: 500.0\n",
      "Ground truth answer: 27000.0\n",
      "Correct: 37 out of 1319\n",
      "========================================\n",
      "task_id 247\n",
      "Model answer: None\n",
      "Ground truth answer: 32.0\n",
      "Correct: 37 out of 1319\n",
      "========================================\n",
      "task_id 248\n",
      "Model answer: 180.0\n",
      "Ground truth answer: 300.0\n",
      "Correct: 37 out of 1319\n",
      "========================================\n",
      "task_id 249\n",
      "Model answer: None\n",
      "Ground truth answer: 600.0\n",
      "Correct: 37 out of 1319\n",
      "========================================\n",
      "task_id 250\n",
      "Model answer: 13.0\n",
      "Ground truth answer: 17.0\n",
      "Correct: 37 out of 1319\n",
      "========================================\n",
      "task_id 251\n",
      "Model answer: 70.0\n",
      "Ground truth answer: 70.0\n",
      "Correct: 38 out of 1319\n",
      "========================================\n",
      "task_id 252\n",
      "Model answer: 72.0\n",
      "Ground truth answer: 73.0\n",
      "Correct: 38 out of 1319\n",
      "========================================\n",
      "task_id 253\n",
      "Model answer: 24.0\n",
      "Ground truth answer: 18.0\n",
      "Correct: 38 out of 1319\n",
      "========================================\n",
      "task_id 254\n",
      "Model answer: 8.0\n",
      "Ground truth answer: 84.0\n",
      "Correct: 38 out of 1319\n",
      "========================================\n",
      "task_id 255\n",
      "Model answer: 16.0\n",
      "Ground truth answer: 192.0\n",
      "Correct: 38 out of 1319\n",
      "========================================\n",
      "task_id 256\n",
      "Model answer: None\n",
      "Ground truth answer: 45.0\n",
      "Correct: 38 out of 1319\n",
      "========================================\n",
      "task_id 257\n",
      "Model answer: 1200.0\n",
      "Ground truth answer: 5600.0\n",
      "Correct: 38 out of 1319\n",
      "========================================\n",
      "task_id 258\n",
      "Model answer: None\n",
      "Ground truth answer: 6.0\n",
      "Correct: 38 out of 1319\n",
      "========================================\n",
      "task_id 259\n",
      "Model answer: 44.0\n",
      "Ground truth answer: 168.0\n",
      "Correct: 38 out of 1319\n",
      "========================================\n",
      "task_id 260\n",
      "Model answer: 132.0\n",
      "Ground truth answer: 11.0\n",
      "Correct: 38 out of 1319\n",
      "========================================\n",
      "task_id 261\n",
      "Model answer: 0.0666\n",
      "Ground truth answer: 62.0\n",
      "Correct: 38 out of 1319\n",
      "========================================\n",
      "task_id 262\n",
      "Model answer: 30.0\n",
      "Ground truth answer: 270.0\n",
      "Correct: 38 out of 1319\n",
      "========================================\n",
      "task_id 263\n",
      "Model answer: 10.0\n",
      "Ground truth answer: 8.0\n",
      "Correct: 38 out of 1319\n",
      "========================================\n",
      "task_id 264\n",
      "Model answer: 300.0\n",
      "Ground truth answer: 400.0\n",
      "Correct: 38 out of 1319\n",
      "========================================\n",
      "task_id 265\n",
      "Model answer: 500.0\n",
      "Ground truth answer: 9500.0\n",
      "Correct: 38 out of 1319\n",
      "========================================\n",
      "task_id 266\n",
      "Model answer: None\n",
      "Ground truth answer: 118000.0\n",
      "Correct: 38 out of 1319\n",
      "========================================\n",
      "task_id 267\n",
      "Model answer: 28.5\n",
      "Ground truth answer: 91.0\n",
      "Correct: 38 out of 1319\n",
      "========================================\n",
      "task_id 268\n",
      "Model answer: 1625.0\n",
      "Ground truth answer: 1375.0\n",
      "Correct: 38 out of 1319\n",
      "========================================\n",
      "task_id 269\n",
      "Model answer: 4.0\n",
      "Ground truth answer: 4.0\n",
      "Correct: 39 out of 1319\n",
      "========================================\n",
      "task_id 270\n",
      "Model answer: None\n",
      "Ground truth answer: 762.0\n",
      "Correct: 39 out of 1319\n",
      "========================================\n",
      "task_id 271\n",
      "Model answer: 48.0\n",
      "Ground truth answer: 20.0\n",
      "Correct: 39 out of 1319\n",
      "========================================\n",
      "task_id 272\n",
      "Model answer: 2.0\n",
      "Ground truth answer: 5.0\n",
      "Correct: 39 out of 1319\n",
      "========================================\n",
      "task_id 273\n",
      "Model answer: None\n",
      "Ground truth answer: 315.0\n",
      "Correct: 39 out of 1319\n",
      "========================================\n",
      "task_id 274\n",
      "Model answer: 2400.0\n",
      "Ground truth answer: 3200.0\n",
      "Correct: 39 out of 1319\n",
      "========================================\n",
      "task_id 275\n",
      "Model answer: 54.0\n",
      "Ground truth answer: 138.0\n",
      "Correct: 39 out of 1319\n",
      "========================================\n",
      "task_id 276\n",
      "Model answer: None\n",
      "Ground truth answer: 9.0\n",
      "Correct: 39 out of 1319\n",
      "========================================\n",
      "task_id 277\n",
      "Model answer: 4.0\n",
      "Ground truth answer: 4.0\n",
      "Correct: 40 out of 1319\n",
      "========================================\n",
      "task_id 278\n",
      "Model answer: 50.0\n",
      "Ground truth answer: 40.0\n",
      "Correct: 40 out of 1319\n",
      "========================================\n",
      "task_id 279\n",
      "Model answer: 162.0\n",
      "Ground truth answer: 6.0\n",
      "Correct: 40 out of 1319\n",
      "========================================\n",
      "task_id 280\n",
      "Model answer: 7.0\n",
      "Ground truth answer: 7.0\n",
      "Correct: 41 out of 1319\n",
      "========================================\n",
      "task_id 281\n",
      "Model answer: 3500.0\n",
      "Ground truth answer: 2450.0\n",
      "Correct: 41 out of 1319\n",
      "========================================\n",
      "task_id 282\n",
      "Model answer: None\n",
      "Ground truth answer: 195.0\n",
      "Correct: 41 out of 1319\n",
      "========================================\n",
      "task_id 283\n",
      "Model answer: 7.0\n",
      "Ground truth answer: 68.0\n",
      "Correct: 41 out of 1319\n",
      "========================================\n",
      "task_id 284\n",
      "Model answer: None\n",
      "Ground truth answer: 360.0\n",
      "Correct: 41 out of 1319\n",
      "========================================\n",
      "task_id 285\n",
      "Model answer: 21.0\n",
      "Ground truth answer: 21.0\n",
      "Correct: 42 out of 1319\n",
      "========================================\n",
      "task_id 286\n",
      "Model answer: 50.0\n",
      "Ground truth answer: 90.0\n",
      "Correct: 42 out of 1319\n",
      "========================================\n",
      "task_id 287\n",
      "Model answer: 1.0\n",
      "Ground truth answer: 8.0\n",
      "Correct: 42 out of 1319\n",
      "========================================\n",
      "task_id 288\n",
      "Model answer: 2.95\n",
      "Ground truth answer: 3.0\n",
      "Correct: 42 out of 1319\n",
      "========================================\n",
      "task_id 289\n",
      "Model answer: 240.0\n",
      "Ground truth answer: 16.0\n",
      "Correct: 42 out of 1319\n",
      "========================================\n",
      "task_id 290\n",
      "Model answer: 390.0\n",
      "Ground truth answer: 390.0\n",
      "Correct: 43 out of 1319\n",
      "========================================\n",
      "task_id 291\n",
      "Model answer: 2.0\n",
      "Ground truth answer: 2.0\n",
      "Correct: 44 out of 1319\n",
      "========================================\n",
      "task_id 292\n",
      "Model answer: None\n",
      "Ground truth answer: 75.0\n",
      "Correct: 44 out of 1319\n",
      "========================================\n",
      "task_id 293\n",
      "Model answer: None\n",
      "Ground truth answer: 83.0\n",
      "Correct: 44 out of 1319\n",
      "========================================\n",
      "task_id 294\n",
      "Model answer: None\n",
      "Ground truth answer: 3.0\n",
      "Correct: 44 out of 1319\n",
      "========================================\n",
      "task_id 295\n",
      "Model answer: None\n",
      "Ground truth answer: 370.0\n",
      "Correct: 44 out of 1319\n",
      "========================================\n",
      "task_id 296\n",
      "Model answer: 42.0\n",
      "Ground truth answer: 3.0\n",
      "Correct: 44 out of 1319\n",
      "========================================\n",
      "task_id 297\n",
      "Model answer: None\n",
      "Ground truth answer: 55.0\n",
      "Correct: 44 out of 1319\n",
      "========================================\n",
      "task_id 298\n",
      "Model answer: 400.0\n",
      "Ground truth answer: 500.0\n",
      "Correct: 44 out of 1319\n",
      "========================================\n",
      "task_id 299\n",
      "Model answer: None\n",
      "Ground truth answer: 31800.0\n",
      "Correct: 44 out of 1319\n",
      "========================================\n",
      "task_id 300\n",
      "Model answer: 49.0\n",
      "Ground truth answer: 78.0\n",
      "Correct: 44 out of 1319\n",
      "========================================\n",
      "task_id 301\n",
      "Model answer: None\n",
      "Ground truth answer: 8.0\n",
      "Correct: 44 out of 1319\n",
      "========================================\n",
      "task_id 302\n",
      "Model answer: 15.0\n",
      "Ground truth answer: 15.0\n",
      "Correct: 45 out of 1319\n",
      "========================================\n",
      "task_id 303\n",
      "Model answer: None\n",
      "Ground truth answer: 1300.0\n",
      "Correct: 45 out of 1319\n",
      "========================================\n",
      "task_id 304\n",
      "Model answer: 300.0\n",
      "Ground truth answer: 3200.0\n",
      "Correct: 45 out of 1319\n",
      "========================================\n",
      "task_id 305\n",
      "Model answer: 4.0\n",
      "Ground truth answer: 4.0\n",
      "Correct: 46 out of 1319\n",
      "========================================\n",
      "task_id 306\n",
      "Model answer: 20.0\n",
      "Ground truth answer: 10.0\n",
      "Correct: 46 out of 1319\n",
      "========================================\n",
      "task_id 307\n",
      "Model answer: 2.0\n",
      "Ground truth answer: 16.0\n",
      "Correct: 46 out of 1319\n",
      "========================================\n",
      "task_id 308\n",
      "Model answer: 0.5\n",
      "Ground truth answer: 6.0\n",
      "Correct: 46 out of 1319\n",
      "========================================\n",
      "task_id 309\n",
      "Model answer: 120.0\n",
      "Ground truth answer: 8.0\n",
      "Correct: 46 out of 1319\n",
      "========================================\n",
      "task_id 310\n",
      "Model answer: None\n",
      "Ground truth answer: 2050.0\n",
      "Correct: 46 out of 1319\n",
      "========================================\n",
      "task_id 311\n",
      "Model answer: 133.0\n",
      "Ground truth answer: 91.0\n",
      "Correct: 46 out of 1319\n",
      "========================================\n",
      "task_id 312\n",
      "Model answer: 22.0\n",
      "Ground truth answer: 32.0\n",
      "Correct: 46 out of 1319\n",
      "========================================\n",
      "task_id 313\n",
      "Model answer: None\n",
      "Ground truth answer: 120000.0\n",
      "Correct: 46 out of 1319\n",
      "========================================\n",
      "task_id 314\n",
      "Model answer: None\n",
      "Ground truth answer: 30.0\n",
      "Correct: 46 out of 1319\n",
      "========================================\n",
      "task_id 315\n",
      "Model answer: 35.0\n",
      "Ground truth answer: 14.0\n",
      "Correct: 46 out of 1319\n",
      "========================================\n",
      "task_id 316\n",
      "Model answer: 60.0\n",
      "Ground truth answer: 156.0\n",
      "Correct: 46 out of 1319\n",
      "========================================\n",
      "task_id 317\n",
      "Model answer: 2.4\n",
      "Ground truth answer: 12.0\n",
      "Correct: 46 out of 1319\n",
      "========================================\n",
      "task_id 318\n",
      "Model answer: 93.0\n",
      "Ground truth answer: 123.0\n",
      "Correct: 46 out of 1319\n",
      "========================================\n",
      "task_id 319\n",
      "Model answer: 135.0\n",
      "Ground truth answer: 15.0\n",
      "Correct: 46 out of 1319\n",
      "========================================\n",
      "task_id 320\n",
      "Model answer: 16.0\n",
      "Ground truth answer: 8.0\n",
      "Correct: 46 out of 1319\n",
      "========================================\n",
      "task_id 321\n",
      "Model answer: 3.0\n",
      "Ground truth answer: 1.0\n",
      "Correct: 46 out of 1319\n",
      "========================================\n",
      "task_id 322\n",
      "Model answer: 2.0\n",
      "Ground truth answer: 9.0\n",
      "Correct: 46 out of 1319\n",
      "========================================\n",
      "task_id 323\n",
      "Model answer: None\n",
      "Ground truth answer: 75.0\n",
      "Correct: 46 out of 1319\n",
      "========================================\n",
      "task_id 324\n",
      "Model answer: 7.0\n",
      "Ground truth answer: 14.0\n",
      "Correct: 46 out of 1319\n",
      "========================================\n",
      "task_id 325\n",
      "Model answer: None\n",
      "Ground truth answer: 224000.0\n",
      "Correct: 46 out of 1319\n",
      "========================================\n",
      "task_id 326\n",
      "Model answer: 19.0\n",
      "Ground truth answer: 14.0\n",
      "Correct: 46 out of 1319\n",
      "========================================\n",
      "task_id 327\n",
      "Model answer: 14.0\n",
      "Ground truth answer: 31.0\n",
      "Correct: 46 out of 1319\n",
      "========================================\n",
      "task_id 328\n",
      "Model answer: None\n",
      "Ground truth answer: 2.0\n",
      "Correct: 46 out of 1319\n",
      "========================================\n",
      "task_id 329\n",
      "Model answer: 14.0\n",
      "Ground truth answer: 14.0\n",
      "Correct: 47 out of 1319\n",
      "========================================\n",
      "task_id 330\n",
      "Model answer: 46.0\n",
      "Ground truth answer: 31.0\n",
      "Correct: 47 out of 1319\n",
      "========================================\n",
      "task_id 331\n",
      "Model answer: 0.0\n",
      "Ground truth answer: 8400.0\n",
      "Correct: 47 out of 1319\n",
      "========================================\n",
      "task_id 332\n",
      "Model answer: 44.0\n",
      "Ground truth answer: 44.0\n",
      "Correct: 48 out of 1319\n",
      "========================================\n",
      "task_id 333\n",
      "Model answer: 3.0\n",
      "Ground truth answer: 100.0\n",
      "Correct: 48 out of 1319\n",
      "========================================\n",
      "task_id 334\n",
      "Model answer: None\n",
      "Ground truth answer: 6.0\n",
      "Correct: 48 out of 1319\n",
      "========================================\n",
      "task_id 335\n",
      "Model answer: None\n",
      "Ground truth answer: 310.0\n",
      "Correct: 48 out of 1319\n",
      "========================================\n",
      "task_id 336\n",
      "Model answer: 72.0\n",
      "Ground truth answer: 72.0\n",
      "Correct: 49 out of 1319\n",
      "========================================\n",
      "task_id 337\n",
      "Model answer: 6.0\n",
      "Ground truth answer: 1.0\n",
      "Correct: 49 out of 1319\n",
      "========================================\n",
      "task_id 338\n",
      "Model answer: 180.0\n",
      "Ground truth answer: 60.0\n",
      "Correct: 49 out of 1319\n",
      "========================================\n",
      "task_id 339\n",
      "Model answer: 90.0\n",
      "Ground truth answer: 160.0\n",
      "Correct: 49 out of 1319\n",
      "========================================\n",
      "task_id 340\n",
      "Model answer: None\n",
      "Ground truth answer: 4.0\n",
      "Correct: 49 out of 1319\n",
      "========================================\n",
      "task_id 341\n",
      "Model answer: 90.0\n",
      "Ground truth answer: 260.0\n",
      "Correct: 49 out of 1319\n",
      "========================================\n",
      "task_id 342\n",
      "Model answer: 63.0\n",
      "Ground truth answer: 87.0\n",
      "Correct: 49 out of 1319\n",
      "========================================\n",
      "task_id 343\n",
      "Model answer: 25000.0\n",
      "Ground truth answer: 180000.0\n",
      "Correct: 49 out of 1319\n",
      "========================================\n",
      "task_id 344\n",
      "Model answer: 12.0\n",
      "Ground truth answer: 2.0\n",
      "Correct: 49 out of 1319\n",
      "========================================\n",
      "task_id 345\n",
      "Model answer: 240.0\n",
      "Ground truth answer: 310.0\n",
      "Correct: 49 out of 1319\n",
      "========================================\n",
      "task_id 346\n",
      "Model answer: None\n",
      "Ground truth answer: 9.0\n",
      "Correct: 49 out of 1319\n",
      "========================================\n",
      "task_id 347\n",
      "Model answer: 18.0\n",
      "Ground truth answer: 36.0\n",
      "Correct: 49 out of 1319\n",
      "========================================\n",
      "task_id 348\n",
      "Model answer: 140.0\n",
      "Ground truth answer: 10.0\n",
      "Correct: 49 out of 1319\n",
      "========================================\n",
      "task_id 349\n",
      "Model answer: None\n",
      "Ground truth answer: 2640.0\n",
      "Correct: 49 out of 1319\n",
      "========================================\n",
      "task_id 350\n",
      "Model answer: None\n",
      "Ground truth answer: 8.0\n",
      "Correct: 49 out of 1319\n",
      "========================================\n",
      "task_id 351\n",
      "Model answer: None\n",
      "Ground truth answer: 10.0\n",
      "Correct: 49 out of 1319\n",
      "========================================\n",
      "task_id 352\n",
      "Model answer: 19.0\n",
      "Ground truth answer: 21.0\n",
      "Correct: 49 out of 1319\n",
      "========================================\n",
      "task_id 353\n",
      "Model answer: 34.0\n",
      "Ground truth answer: 20.0\n",
      "Correct: 49 out of 1319\n",
      "========================================\n",
      "task_id 354\n",
      "Model answer: None\n",
      "Ground truth answer: 45.0\n",
      "Correct: 49 out of 1319\n",
      "========================================\n",
      "task_id 355\n",
      "Model answer: None\n",
      "Ground truth answer: 34.0\n",
      "Correct: 49 out of 1319\n",
      "========================================\n",
      "task_id 356\n",
      "Model answer: 38.0\n",
      "Ground truth answer: 21.0\n",
      "Correct: 49 out of 1319\n",
      "========================================\n",
      "task_id 357\n",
      "Model answer: None\n",
      "Ground truth answer: 2.0\n",
      "Correct: 49 out of 1319\n",
      "========================================\n",
      "task_id 358\n",
      "Model answer: 500.0\n",
      "Ground truth answer: 20.0\n",
      "Correct: 49 out of 1319\n",
      "========================================\n",
      "task_id 359\n",
      "Model answer: 35.0\n",
      "Ground truth answer: 4.0\n",
      "Correct: 49 out of 1319\n",
      "========================================\n",
      "task_id 360\n",
      "Model answer: 40.0\n",
      "Ground truth answer: 25.0\n",
      "Correct: 49 out of 1319\n",
      "========================================\n",
      "task_id 361\n",
      "Model answer: None\n",
      "Ground truth answer: 20.0\n",
      "Correct: 49 out of 1319\n",
      "========================================\n",
      "task_id 362\n",
      "Model answer: 24.0\n",
      "Ground truth answer: 23.0\n",
      "Correct: 49 out of 1319\n",
      "========================================\n",
      "task_id 363\n",
      "Model answer: 5.0\n",
      "Ground truth answer: 6.0\n",
      "Correct: 49 out of 1319\n",
      "========================================\n",
      "task_id 364\n",
      "Model answer: 85.0\n",
      "Ground truth answer: 49.0\n",
      "Correct: 49 out of 1319\n",
      "========================================\n",
      "task_id 365\n",
      "Model answer: 18.0\n",
      "Ground truth answer: 18.0\n",
      "Correct: 50 out of 1319\n",
      "========================================\n",
      "task_id 366\n",
      "Model answer: 33.0\n",
      "Ground truth answer: 9.0\n",
      "Correct: 50 out of 1319\n",
      "========================================\n",
      "task_id 367\n",
      "Model answer: 12.0\n",
      "Ground truth answer: 19.0\n",
      "Correct: 50 out of 1319\n",
      "========================================\n",
      "task_id 368\n",
      "Model answer: 6.0\n",
      "Ground truth answer: 18.0\n",
      "Correct: 50 out of 1319\n",
      "========================================\n",
      "task_id 369\n",
      "Model answer: None\n",
      "Ground truth answer: 1198.0\n",
      "Correct: 50 out of 1319\n",
      "========================================\n",
      "task_id 370\n",
      "Model answer: 480.0\n",
      "Ground truth answer: 320.0\n",
      "Correct: 50 out of 1319\n",
      "========================================\n",
      "task_id 371\n",
      "Model answer: 14.0\n",
      "Ground truth answer: 50.0\n",
      "Correct: 50 out of 1319\n",
      "========================================\n",
      "task_id 372\n",
      "Model answer: 5.0\n",
      "Ground truth answer: 5.0\n",
      "Correct: 51 out of 1319\n",
      "========================================\n",
      "task_id 373\n",
      "Model answer: 240000.0\n",
      "Ground truth answer: 240000.0\n",
      "Correct: 52 out of 1319\n",
      "========================================\n",
      "task_id 374\n",
      "Model answer: 45.0\n",
      "Ground truth answer: 45.0\n",
      "Correct: 53 out of 1319\n",
      "========================================\n",
      "task_id 375\n",
      "Model answer: 48.0\n",
      "Ground truth answer: 48.0\n",
      "Correct: 54 out of 1319\n",
      "========================================\n",
      "task_id 376\n",
      "Model answer: 15.0\n",
      "Ground truth answer: 15.0\n",
      "Correct: 55 out of 1319\n",
      "========================================\n",
      "task_id 377\n",
      "Model answer: None\n",
      "Ground truth answer: 50.0\n",
      "Correct: 55 out of 1319\n",
      "========================================\n",
      "task_id 378\n",
      "Model answer: -10.0\n",
      "Ground truth answer: 15.0\n",
      "Correct: 55 out of 1319\n",
      "========================================\n",
      "task_id 379\n",
      "Model answer: 11.0\n",
      "Ground truth answer: 21.0\n",
      "Correct: 55 out of 1319\n",
      "========================================\n",
      "task_id 380\n",
      "Model answer: 730.0\n",
      "Ground truth answer: 803.0\n",
      "Correct: 55 out of 1319\n",
      "========================================\n",
      "task_id 381\n",
      "Model answer: 67.0\n",
      "Ground truth answer: 67.0\n",
      "Correct: 56 out of 1319\n",
      "========================================\n",
      "task_id 382\n",
      "Model answer: 270.0\n",
      "Ground truth answer: 350.0\n",
      "Correct: 56 out of 1319\n",
      "========================================\n",
      "task_id 383\n",
      "Model answer: None\n",
      "Ground truth answer: 2.0\n",
      "Correct: 56 out of 1319\n",
      "========================================\n",
      "task_id 384\n",
      "Model answer: 12.8\n",
      "Ground truth answer: 32.0\n",
      "Correct: 56 out of 1319\n",
      "========================================\n",
      "task_id 385\n",
      "Model answer: None\n",
      "Ground truth answer: 16.0\n",
      "Correct: 56 out of 1319\n",
      "========================================\n",
      "task_id 386\n",
      "Model answer: None\n",
      "Ground truth answer: 80.0\n",
      "Correct: 56 out of 1319\n",
      "========================================\n",
      "task_id 387\n",
      "Model answer: 84.0\n",
      "Ground truth answer: 36.0\n",
      "Correct: 56 out of 1319\n",
      "========================================\n",
      "task_id 388\n",
      "Model answer: 88.0\n",
      "Ground truth answer: 88.0\n",
      "Correct: 57 out of 1319\n",
      "========================================\n",
      "task_id 389\n",
      "Model answer: 21.0\n",
      "Ground truth answer: 6.0\n",
      "Correct: 57 out of 1319\n",
      "========================================\n",
      "task_id 390\n",
      "Model answer: 144.0\n",
      "Ground truth answer: 12.0\n",
      "Correct: 57 out of 1319\n",
      "========================================\n",
      "task_id 391\n",
      "Model answer: 165.0\n",
      "Ground truth answer: 15.0\n",
      "Correct: 57 out of 1319\n",
      "========================================\n",
      "task_id 392\n",
      "Model answer: 54.0\n",
      "Ground truth answer: 34.0\n",
      "Correct: 57 out of 1319\n",
      "========================================\n",
      "task_id 393\n",
      "Model answer: 15.0\n",
      "Ground truth answer: 20.0\n",
      "Correct: 57 out of 1319\n",
      "========================================\n",
      "task_id 394\n",
      "Model answer: 40.0\n",
      "Ground truth answer: 92.0\n",
      "Correct: 57 out of 1319\n",
      "========================================\n",
      "task_id 395\n",
      "Model answer: 13.0\n",
      "Ground truth answer: 38.0\n",
      "Correct: 57 out of 1319\n",
      "========================================\n",
      "task_id 396\n",
      "Model answer: 7.0\n",
      "Ground truth answer: 3.0\n",
      "Correct: 57 out of 1319\n",
      "========================================\n",
      "task_id 397\n",
      "Model answer: 30.0\n",
      "Ground truth answer: 25.0\n",
      "Correct: 57 out of 1319\n",
      "========================================\n",
      "task_id 398\n",
      "Model answer: 132.0\n",
      "Ground truth answer: 168.0\n",
      "Correct: 57 out of 1319\n",
      "========================================\n",
      "task_id 399\n",
      "Model answer: 18.0\n",
      "Ground truth answer: 12.0\n",
      "Correct: 57 out of 1319\n",
      "========================================\n",
      "task_id 400\n",
      "Model answer: 48.0\n",
      "Ground truth answer: 48.0\n",
      "Correct: 58 out of 1319\n",
      "========================================\n",
      "task_id 401\n",
      "Model answer: 144000.0\n",
      "Ground truth answer: 14400.0\n",
      "Correct: 58 out of 1319\n",
      "========================================\n",
      "task_id 402\n",
      "Model answer: 2.0\n",
      "Ground truth answer: 4.0\n",
      "Correct: 58 out of 1319\n",
      "========================================\n",
      "task_id 403\n",
      "Model answer: None\n",
      "Ground truth answer: 81.0\n",
      "Correct: 58 out of 1319\n",
      "========================================\n",
      "task_id 404\n",
      "Model answer: 60.0\n",
      "Ground truth answer: 22.0\n",
      "Correct: 58 out of 1319\n",
      "========================================\n",
      "task_id 405\n",
      "Model answer: None\n",
      "Ground truth answer: 50.0\n",
      "Correct: 58 out of 1319\n",
      "========================================\n",
      "task_id 406\n",
      "Model answer: 150.0\n",
      "Ground truth answer: 200.0\n",
      "Correct: 58 out of 1319\n",
      "========================================\n",
      "task_id 407\n",
      "Model answer: None\n",
      "Ground truth answer: 2000.0\n",
      "Correct: 58 out of 1319\n",
      "========================================\n",
      "task_id 408\n",
      "Model answer: 7.5\n",
      "Ground truth answer: 20.0\n",
      "Correct: 58 out of 1319\n",
      "========================================\n",
      "task_id 409\n",
      "Model answer: None\n",
      "Ground truth answer: 168000.0\n",
      "Correct: 58 out of 1319\n",
      "========================================\n",
      "task_id 410\n",
      "Model answer: None\n",
      "Ground truth answer: 3.0\n",
      "Correct: 58 out of 1319\n",
      "========================================\n",
      "task_id 411\n",
      "Model answer: 1050.0\n",
      "Ground truth answer: 1110.0\n",
      "Correct: 58 out of 1319\n",
      "========================================\n",
      "task_id 412\n",
      "Model answer: 720.0\n",
      "Ground truth answer: 5.0\n",
      "Correct: 58 out of 1319\n",
      "========================================\n",
      "task_id 413\n",
      "Model answer: 250.0\n",
      "Ground truth answer: 25.0\n",
      "Correct: 58 out of 1319\n",
      "========================================\n",
      "task_id 414\n",
      "Model answer: 80.0\n",
      "Ground truth answer: 56.0\n",
      "Correct: 58 out of 1319\n",
      "========================================\n",
      "task_id 415\n",
      "Model answer: None\n",
      "Ground truth answer: 350.0\n",
      "Correct: 58 out of 1319\n",
      "========================================\n",
      "task_id 416\n",
      "Model answer: 161.0\n",
      "Ground truth answer: 56.0\n",
      "Correct: 58 out of 1319\n",
      "========================================\n",
      "task_id 417\n",
      "Model answer: None\n",
      "Ground truth answer: 3140.0\n",
      "Correct: 58 out of 1319\n",
      "========================================\n",
      "task_id 418\n",
      "Model answer: None\n",
      "Ground truth answer: 40.0\n",
      "Correct: 58 out of 1319\n",
      "========================================\n",
      "task_id 419\n",
      "Model answer: 0.0\n",
      "Ground truth answer: 3000.0\n",
      "Correct: 58 out of 1319\n",
      "========================================\n",
      "task_id 420\n",
      "Model answer: 13000.0\n",
      "Ground truth answer: 17000.0\n",
      "Correct: 58 out of 1319\n",
      "========================================\n",
      "task_id 421\n",
      "Model answer: 12.0\n",
      "Ground truth answer: 12.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 422\n",
      "Model answer: 96.0\n",
      "Ground truth answer: 284.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 423\n",
      "Model answer: 18.0\n",
      "Ground truth answer: 8.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 424\n",
      "Model answer: 360.0\n",
      "Ground truth answer: 570.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 425\n",
      "Model answer: None\n",
      "Ground truth answer: 150.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 426\n",
      "Model answer: None\n",
      "Ground truth answer: 11.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 427\n",
      "Model answer: 7.0\n",
      "Ground truth answer: 150.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 428\n",
      "Model answer: 27.0\n",
      "Ground truth answer: 26.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 429\n",
      "Model answer: 16.0\n",
      "Ground truth answer: 13.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 430\n",
      "Model answer: None\n",
      "Ground truth answer: 132.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 431\n",
      "Model answer: 18.0\n",
      "Ground truth answer: 1.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 432\n",
      "Model answer: None\n",
      "Ground truth answer: 30.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 433\n",
      "Model answer: 3.75\n",
      "Ground truth answer: 6.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 434\n",
      "Model answer: 2.0\n",
      "Ground truth answer: 5.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 435\n",
      "Model answer: 20.0\n",
      "Ground truth answer: 5.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 436\n",
      "Model answer: 140.0\n",
      "Ground truth answer: 15.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 437\n",
      "Model answer: 28.0\n",
      "Ground truth answer: 7.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 438\n",
      "Model answer: None\n",
      "Ground truth answer: 2.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 439\n",
      "Model answer: 1.0\n",
      "Ground truth answer: 17.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 440\n",
      "Model answer: 12.0\n",
      "Ground truth answer: 98.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 441\n",
      "Model answer: None\n",
      "Ground truth answer: 80.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 442\n",
      "Model answer: None\n",
      "Ground truth answer: 49.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 443\n",
      "Model answer: None\n",
      "Ground truth answer: 59.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 444\n",
      "Model answer: None\n",
      "Ground truth answer: 20.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 445\n",
      "Model answer: None\n",
      "Ground truth answer: 6.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 446\n",
      "Model answer: 4.4\n",
      "Ground truth answer: 2.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 447\n",
      "Model answer: 25.0\n",
      "Ground truth answer: 5.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 448\n",
      "Model answer: 1.0\n",
      "Ground truth answer: 539.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 449\n",
      "Model answer: 48.0\n",
      "Ground truth answer: 112.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 450\n",
      "Model answer: None\n",
      "Ground truth answer: 4.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 451\n",
      "Model answer: None\n",
      "Ground truth answer: 11050.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 452\n",
      "Model answer: 150.0\n",
      "Ground truth answer: 50.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 453\n",
      "Model answer: None\n",
      "Ground truth answer: 6400.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 454\n",
      "Model answer: 120.0\n",
      "Ground truth answer: 150.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 455\n",
      "Model answer: 3044.0\n",
      "Ground truth answer: 1920.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 456\n",
      "Model answer: 39.0\n",
      "Ground truth answer: 78.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 457\n",
      "Model answer: 5.0\n",
      "Ground truth answer: 45.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 458\n",
      "Model answer: 0.333\n",
      "Ground truth answer: 35.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 459\n",
      "Model answer: None\n",
      "Ground truth answer: 2.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 460\n",
      "Model answer: 0.5\n",
      "Ground truth answer: 84.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 461\n",
      "Model answer: 1.0\n",
      "Ground truth answer: 9.0\n",
      "Correct: 59 out of 1319\n",
      "========================================\n",
      "task_id 462\n",
      "Model answer: 71.0\n",
      "Ground truth answer: 71.0\n",
      "Correct: 60 out of 1319\n",
      "========================================\n",
      "task_id 463\n",
      "Model answer: 18.0\n",
      "Ground truth answer: 18.0\n",
      "Correct: 61 out of 1319\n",
      "========================================\n",
      "task_id 464\n",
      "Model answer: 1.0\n",
      "Ground truth answer: 6.0\n",
      "Correct: 61 out of 1319\n",
      "========================================\n",
      "task_id 465\n",
      "Model answer: 1350.0\n",
      "Ground truth answer: 30.0\n",
      "Correct: 61 out of 1319\n",
      "========================================\n",
      "task_id 466\n",
      "Model answer: None\n",
      "Ground truth answer: 1.0\n",
      "Correct: 61 out of 1319\n",
      "========================================\n",
      "task_id 467\n",
      "Model answer: 2560.0\n",
      "Ground truth answer: 1200.0\n",
      "Correct: 61 out of 1319\n",
      "========================================\n",
      "task_id 468\n",
      "Model answer: 60.0\n",
      "Ground truth answer: 120.0\n",
      "Correct: 61 out of 1319\n",
      "========================================\n",
      "task_id 469\n",
      "Model answer: 4.0\n",
      "Ground truth answer: 4.0\n",
      "Correct: 62 out of 1319\n",
      "========================================\n",
      "task_id 470\n",
      "Model answer: 0.0\n",
      "Ground truth answer: 3.0\n",
      "Correct: 62 out of 1319\n",
      "========================================\n",
      "task_id 471\n",
      "Model answer: None\n",
      "Ground truth answer: 80.0\n",
      "Correct: 62 out of 1319\n",
      "========================================\n",
      "task_id 472\n",
      "Model answer: 5.0\n",
      "Ground truth answer: 6.0\n",
      "Correct: 62 out of 1319\n",
      "========================================\n",
      "task_id 473\n",
      "Model answer: 20.0\n",
      "Ground truth answer: 10.0\n",
      "Correct: 62 out of 1319\n",
      "========================================\n",
      "task_id 474\n",
      "Model answer: 15.0\n",
      "Ground truth answer: 80.0\n",
      "Correct: 62 out of 1319\n",
      "========================================\n",
      "task_id 475\n",
      "Model answer: 60.0\n",
      "Ground truth answer: 20.0\n",
      "Correct: 62 out of 1319\n",
      "========================================\n",
      "task_id 476\n",
      "Model answer: 3.75\n",
      "Ground truth answer: 5.0\n",
      "Correct: 62 out of 1319\n",
      "========================================\n",
      "task_id 477\n",
      "Model answer: 14.0\n",
      "Ground truth answer: 20.0\n",
      "Correct: 62 out of 1319\n",
      "========================================\n",
      "task_id 478\n",
      "Model answer: 221.0\n",
      "Ground truth answer: 621.0\n",
      "Correct: 62 out of 1319\n",
      "========================================\n",
      "task_id 479\n",
      "Model answer: None\n",
      "Ground truth answer: 15400.0\n",
      "Correct: 62 out of 1319\n",
      "========================================\n",
      "task_id 480\n",
      "Model answer: 9.0\n",
      "Ground truth answer: 11.0\n",
      "Correct: 62 out of 1319\n",
      "========================================\n",
      "task_id 481\n",
      "Model answer: None\n",
      "Ground truth answer: 84.0\n",
      "Correct: 62 out of 1319\n",
      "========================================\n",
      "task_id 482\n",
      "Model answer: 27.0\n",
      "Ground truth answer: 26.0\n",
      "Correct: 62 out of 1319\n",
      "========================================\n",
      "task_id 483\n",
      "Model answer: 60.0\n",
      "Ground truth answer: 40.0\n",
      "Correct: 62 out of 1319\n",
      "========================================\n",
      "task_id 484\n",
      "Model answer: 120.0\n",
      "Ground truth answer: 240.0\n",
      "Correct: 62 out of 1319\n",
      "========================================\n",
      "task_id 485\n",
      "Model answer: 60.0\n",
      "Ground truth answer: 220.0\n",
      "Correct: 62 out of 1319\n",
      "========================================\n",
      "task_id 486\n",
      "Model answer: 12.0\n",
      "Ground truth answer: 6.0\n",
      "Correct: 62 out of 1319\n",
      "========================================\n",
      "task_id 487\n",
      "Model answer: 100.0\n",
      "Ground truth answer: 4.0\n",
      "Correct: 62 out of 1319\n",
      "========================================\n",
      "task_id 488\n",
      "Model answer: 2.0\n",
      "Ground truth answer: 6.0\n",
      "Correct: 62 out of 1319\n",
      "========================================\n",
      "task_id 489\n",
      "Model answer: None\n",
      "Ground truth answer: -10.0\n",
      "Correct: 62 out of 1319\n",
      "========================================\n",
      "task_id 490\n",
      "Model answer: 4.0\n",
      "Ground truth answer: 4.0\n",
      "Correct: 63 out of 1319\n",
      "========================================\n",
      "task_id 491\n",
      "Model answer: 40.0\n",
      "Ground truth answer: 16.0\n",
      "Correct: 63 out of 1319\n",
      "========================================\n",
      "task_id 492\n",
      "Model answer: 32.0\n",
      "Ground truth answer: 32.0\n",
      "Correct: 64 out of 1319\n",
      "========================================\n",
      "task_id 493\n",
      "Model answer: 0.4\n",
      "Ground truth answer: 25.0\n",
      "Correct: 64 out of 1319\n",
      "========================================\n",
      "task_id 494\n",
      "Model answer: 600.0\n",
      "Ground truth answer: 21.0\n",
      "Correct: 64 out of 1319\n",
      "========================================\n",
      "task_id 495\n",
      "Model answer: 25.0\n",
      "Ground truth answer: 200.0\n",
      "Correct: 64 out of 1319\n",
      "========================================\n",
      "task_id 496\n",
      "Model answer: 12.0\n",
      "Ground truth answer: 38.0\n",
      "Correct: 64 out of 1319\n",
      "========================================\n",
      "task_id 497\n",
      "Model answer: 124.0\n",
      "Ground truth answer: 112.0\n",
      "Correct: 64 out of 1319\n",
      "========================================\n",
      "task_id 498\n",
      "Model answer: 5.0\n",
      "Ground truth answer: 40.0\n",
      "Correct: 64 out of 1319\n",
      "========================================\n",
      "task_id 499\n",
      "Model answer: None\n",
      "Ground truth answer: 10.0\n",
      "Correct: 64 out of 1319\n",
      "========================================\n",
      "task_id 500\n",
      "Model answer: None\n",
      "Ground truth answer: 16.0\n",
      "Correct: 64 out of 1319\n",
      "========================================\n",
      "task_id 501\n",
      "Model answer: 273.0\n",
      "Ground truth answer: 273.0\n",
      "Correct: 65 out of 1319\n",
      "========================================\n",
      "task_id 502\n",
      "Model answer: 35.0\n",
      "Ground truth answer: 26.0\n",
      "Correct: 65 out of 1319\n",
      "========================================\n",
      "task_id 503\n",
      "Model answer: 6.0\n",
      "Ground truth answer: 18.0\n",
      "Correct: 65 out of 1319\n",
      "========================================\n",
      "task_id 504\n",
      "Model answer: 3.0\n",
      "Ground truth answer: 2.0\n",
      "Correct: 65 out of 1319\n",
      "========================================\n",
      "task_id 505\n",
      "Model answer: 2400.0\n",
      "Ground truth answer: 600.0\n",
      "Correct: 65 out of 1319\n",
      "========================================\n",
      "task_id 506\n",
      "Model answer: 288.0\n",
      "Ground truth answer: 144.0\n",
      "Correct: 65 out of 1319\n",
      "========================================\n",
      "task_id 507\n",
      "Model answer: 2.0\n",
      "Ground truth answer: 2.0\n",
      "Correct: 66 out of 1319\n",
      "========================================\n",
      "task_id 508\n",
      "Model answer: 80.0\n",
      "Ground truth answer: 120.0\n",
      "Correct: 66 out of 1319\n",
      "========================================\n",
      "task_id 509\n",
      "Model answer: 48.0\n",
      "Ground truth answer: 4.0\n",
      "Correct: 66 out of 1319\n",
      "========================================\n",
      "task_id 510\n",
      "Model answer: 116.67\n",
      "Ground truth answer: 525.0\n",
      "Correct: 66 out of 1319\n",
      "========================================\n",
      "task_id 511\n",
      "Model answer: 180.0\n",
      "Ground truth answer: 110.0\n",
      "Correct: 66 out of 1319\n",
      "========================================\n",
      "task_id 512\n",
      "Model answer: 120.0\n",
      "Ground truth answer: 120.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 513\n",
      "Model answer: None\n",
      "Ground truth answer: 300.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 514\n",
      "Model answer: 0.0\n",
      "Ground truth answer: 90000.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 515\n",
      "Model answer: 0.0\n",
      "Ground truth answer: 160.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 516\n",
      "Model answer: 1500.0\n",
      "Ground truth answer: 375.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 517\n",
      "Model answer: 72.0\n",
      "Ground truth answer: 18.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 518\n",
      "Model answer: 80.0\n",
      "Ground truth answer: 32.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 519\n",
      "Model answer: 82.0\n",
      "Ground truth answer: 280.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 520\n",
      "Model answer: 6.0\n",
      "Ground truth answer: 63.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 521\n",
      "Model answer: 25.0\n",
      "Ground truth answer: 39.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 522\n",
      "Model answer: None\n",
      "Ground truth answer: 29.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 523\n",
      "Model answer: 72.0\n",
      "Ground truth answer: 74.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 524\n",
      "Model answer: 60.0\n",
      "Ground truth answer: 9.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 525\n",
      "Model answer: None\n",
      "Ground truth answer: 12.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 526\n",
      "Model answer: None\n",
      "Ground truth answer: 21.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 527\n",
      "Model answer: 5.0\n",
      "Ground truth answer: 48.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 528\n",
      "Model answer: 20.0\n",
      "Ground truth answer: 172.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 529\n",
      "Model answer: 4.0\n",
      "Ground truth answer: 11.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 530\n",
      "Model answer: 15.0\n",
      "Ground truth answer: 36.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 531\n",
      "Model answer: 16.0\n",
      "Ground truth answer: 66.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 532\n",
      "Model answer: 11.0\n",
      "Ground truth answer: 25.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 533\n",
      "Model answer: 500.0\n",
      "Ground truth answer: 300.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 534\n",
      "Model answer: None\n",
      "Ground truth answer: 300.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 535\n",
      "Model answer: 3.0\n",
      "Ground truth answer: 16.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 536\n",
      "Model answer: 14.0\n",
      "Ground truth answer: 8.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 537\n",
      "Model answer: 117.0\n",
      "Ground truth answer: 188.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 538\n",
      "Model answer: None\n",
      "Ground truth answer: 18.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 539\n",
      "Model answer: 50.0\n",
      "Ground truth answer: 35.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 540\n",
      "Model answer: 34.0\n",
      "Ground truth answer: 39.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 541\n",
      "Model answer: 562.5\n",
      "Ground truth answer: 50.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 542\n",
      "Model answer: 7.5\n",
      "Ground truth answer: 7.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 543\n",
      "Model answer: 16.0\n",
      "Ground truth answer: 6.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 544\n",
      "Model answer: 400.0\n",
      "Ground truth answer: 80.0\n",
      "Correct: 67 out of 1319\n",
      "========================================\n",
      "task_id 545\n",
      "Model answer: 30.0\n",
      "Ground truth answer: 30.0\n",
      "Correct: 68 out of 1319\n",
      "========================================\n",
      "task_id 546\n",
      "Model answer: 39.0\n",
      "Ground truth answer: 130.0\n",
      "Correct: 68 out of 1319\n",
      "========================================\n",
      "task_id 547\n",
      "Model answer: 12.0\n",
      "Ground truth answer: 81.0\n",
      "Correct: 68 out of 1319\n",
      "========================================\n",
      "task_id 548\n",
      "Model answer: 40.0\n",
      "Ground truth answer: 100.0\n",
      "Correct: 68 out of 1319\n",
      "========================================\n",
      "task_id 549\n",
      "Model answer: 82.0\n",
      "Ground truth answer: 398.0\n",
      "Correct: 68 out of 1319\n",
      "========================================\n",
      "task_id 550\n",
      "Model answer: 9.45\n",
      "Ground truth answer: 27.0\n",
      "Correct: 68 out of 1319\n",
      "========================================\n",
      "task_id 551\n",
      "Model answer: 25.0\n",
      "Ground truth answer: 17.0\n",
      "Correct: 68 out of 1319\n",
      "========================================\n",
      "task_id 552\n",
      "Model answer: None\n",
      "Ground truth answer: 450.0\n",
      "Correct: 68 out of 1319\n",
      "========================================\n",
      "task_id 553\n",
      "Model answer: 140.0\n",
      "Ground truth answer: 92.0\n",
      "Correct: 68 out of 1319\n",
      "========================================\n",
      "task_id 554\n",
      "Model answer: None\n",
      "Ground truth answer: 54.0\n",
      "Correct: 68 out of 1319\n",
      "========================================\n",
      "task_id 555\n",
      "Model answer: 40.0\n",
      "Ground truth answer: 2.0\n",
      "Correct: 68 out of 1319\n",
      "========================================\n",
      "task_id 556\n",
      "Model answer: 120.0\n",
      "Ground truth answer: 160.0\n",
      "Correct: 68 out of 1319\n",
      "========================================\n",
      "task_id 557\n",
      "Model answer: 14.0\n",
      "Ground truth answer: 70.0\n",
      "Correct: 68 out of 1319\n",
      "========================================\n",
      "task_id 558\n",
      "Model answer: 3.0\n",
      "Ground truth answer: 3.0\n",
      "Correct: 69 out of 1319\n",
      "========================================\n",
      "task_id 559\n",
      "Model answer: -16.0\n",
      "Ground truth answer: 16.0\n",
      "Correct: 69 out of 1319\n",
      "========================================\n",
      "task_id 560\n",
      "Model answer: 35.0\n",
      "Ground truth answer: 45.0\n",
      "Correct: 69 out of 1319\n",
      "========================================\n",
      "task_id 561\n",
      "Model answer: 173.33\n",
      "Ground truth answer: 180.0\n",
      "Correct: 69 out of 1319\n",
      "========================================\n",
      "task_id 562\n",
      "Model answer: None\n",
      "Ground truth answer: 82.0\n",
      "Correct: 69 out of 1319\n",
      "========================================\n",
      "task_id 563\n",
      "Model answer: None\n",
      "Ground truth answer: 12.0\n",
      "Correct: 69 out of 1319\n",
      "========================================\n",
      "task_id 564\n",
      "Model answer: 27.0\n",
      "Ground truth answer: 240.0\n",
      "Correct: 69 out of 1319\n",
      "========================================\n",
      "task_id 565\n",
      "Model answer: 9.0\n",
      "Ground truth answer: 5.0\n",
      "Correct: 69 out of 1319\n",
      "========================================\n",
      "task_id 566\n",
      "Model answer: 51.0\n",
      "Ground truth answer: 10.0\n",
      "Correct: 69 out of 1319\n",
      "========================================\n",
      "task_id 567\n",
      "Model answer: None\n",
      "Ground truth answer: 9.0\n",
      "Correct: 69 out of 1319\n",
      "========================================\n",
      "task_id 568\n",
      "Model answer: 105.0\n",
      "Ground truth answer: 175.0\n",
      "Correct: 69 out of 1319\n",
      "========================================\n",
      "task_id 569\n",
      "Model answer: 84.0\n",
      "Ground truth answer: 21.0\n",
      "Correct: 69 out of 1319\n",
      "========================================\n",
      "task_id 570\n",
      "Model answer: None\n",
      "Ground truth answer: 23.0\n",
      "Correct: 69 out of 1319\n",
      "========================================\n",
      "task_id 571\n",
      "Model answer: 276.0\n",
      "Ground truth answer: 308.0\n",
      "Correct: 69 out of 1319\n",
      "========================================\n",
      "task_id 572\n",
      "Model answer: 25.0\n",
      "Ground truth answer: 100.0\n",
      "Correct: 69 out of 1319\n",
      "========================================\n",
      "task_id 573\n",
      "Model answer: 72000.0\n",
      "Ground truth answer: 600.0\n",
      "Correct: 69 out of 1319\n",
      "========================================\n",
      "task_id 574\n",
      "Model answer: None\n",
      "Ground truth answer: 37.0\n",
      "Correct: 69 out of 1319\n",
      "========================================\n",
      "task_id 575\n",
      "Model answer: None\n",
      "Ground truth answer: 36.0\n",
      "Correct: 69 out of 1319\n",
      "========================================\n",
      "task_id 576\n",
      "Model answer: None\n",
      "Ground truth answer: 11232.0\n",
      "Correct: 69 out of 1319\n",
      "========================================\n",
      "task_id 577\n",
      "Model answer: 40.0\n",
      "Ground truth answer: 40.0\n",
      "Correct: 70 out of 1319\n",
      "========================================\n",
      "task_id 578\n",
      "Model answer: 120.0\n",
      "Ground truth answer: 48.0\n",
      "Correct: 70 out of 1319\n",
      "========================================\n",
      "task_id 579\n",
      "Model answer: 8.0\n",
      "Ground truth answer: 7.0\n",
      "Correct: 70 out of 1319\n",
      "========================================\n",
      "task_id 580\n",
      "Model answer: 510.0\n",
      "Ground truth answer: 500.0\n",
      "Correct: 70 out of 1319\n",
      "========================================\n",
      "task_id 581\n",
      "Model answer: 15.0\n",
      "Ground truth answer: 215.0\n",
      "Correct: 70 out of 1319\n",
      "========================================\n",
      "task_id 582\n",
      "Model answer: 130.0\n",
      "Ground truth answer: 129200.0\n",
      "Correct: 70 out of 1319\n",
      "========================================\n",
      "task_id 583\n",
      "Model answer: None\n",
      "Ground truth answer: 120.0\n",
      "Correct: 70 out of 1319\n",
      "========================================\n",
      "task_id 584\n",
      "Model answer: 180.0\n",
      "Ground truth answer: 2.0\n",
      "Correct: 70 out of 1319\n",
      "========================================\n",
      "task_id 585\n",
      "Model answer: 30.0\n",
      "Ground truth answer: 40.0\n",
      "Correct: 70 out of 1319\n",
      "========================================\n",
      "task_id 586\n",
      "Model answer: 0.0\n",
      "Ground truth answer: 800.0\n",
      "Correct: 70 out of 1319\n",
      "========================================\n",
      "task_id 587\n",
      "Model answer: 11.0\n",
      "Ground truth answer: 30.0\n",
      "Correct: 70 out of 1319\n",
      "========================================\n",
      "task_id 588\n",
      "Model answer: 57.0\n",
      "Ground truth answer: 52.0\n",
      "Correct: 70 out of 1319\n",
      "========================================\n",
      "task_id 589\n",
      "Model answer: 8.7\n",
      "Ground truth answer: 15.0\n",
      "Correct: 70 out of 1319\n",
      "========================================\n",
      "task_id 590\n",
      "Model answer: 182.0\n",
      "Ground truth answer: 319.0\n",
      "Correct: 70 out of 1319\n",
      "========================================\n",
      "task_id 591\n",
      "Model answer: 220.0\n",
      "Ground truth answer: 220.0\n",
      "Correct: 71 out of 1319\n",
      "========================================\n",
      "task_id 592\n",
      "Model answer: None\n",
      "Ground truth answer: 1.0\n",
      "Correct: 71 out of 1319\n",
      "========================================\n",
      "task_id 593\n",
      "Model answer: None\n",
      "Ground truth answer: 3.0\n",
      "Correct: 71 out of 1319\n",
      "========================================\n",
      "task_id 594\n",
      "Model answer: None\n",
      "Ground truth answer: 42.0\n",
      "Correct: 71 out of 1319\n",
      "========================================\n",
      "task_id 595\n",
      "Model answer: 13.0\n",
      "Ground truth answer: 13.0\n",
      "Correct: 72 out of 1319\n",
      "========================================\n",
      "task_id 596\n",
      "Model answer: 40.0\n",
      "Ground truth answer: 260.0\n",
      "Correct: 72 out of 1319\n",
      "========================================\n",
      "task_id 597\n",
      "Model answer: 720.0\n",
      "Ground truth answer: 90.0\n",
      "Correct: 72 out of 1319\n",
      "========================================\n",
      "task_id 598\n",
      "Model answer: None\n",
      "Ground truth answer: 69.0\n",
      "Correct: 72 out of 1319\n",
      "========================================\n",
      "task_id 599\n",
      "Model answer: 40.0\n",
      "Ground truth answer: 48.0\n",
      "Correct: 72 out of 1319\n",
      "========================================\n",
      "task_id 600\n",
      "Model answer: 10.0\n",
      "Ground truth answer: 10.0\n",
      "Correct: 73 out of 1319\n",
      "========================================\n",
      "task_id 601\n",
      "Model answer: None\n",
      "Ground truth answer: 104.0\n",
      "Correct: 73 out of 1319\n",
      "========================================\n",
      "task_id 602\n",
      "Model answer: 5.0\n",
      "Ground truth answer: 5.0\n",
      "Correct: 74 out of 1319\n",
      "========================================\n",
      "task_id 603\n",
      "Model answer: None\n",
      "Ground truth answer: 1800.0\n",
      "Correct: 74 out of 1319\n",
      "========================================\n",
      "task_id 604\n",
      "Model answer: 36.0\n",
      "Ground truth answer: 12.0\n",
      "Correct: 74 out of 1319\n",
      "========================================\n",
      "task_id 605\n",
      "Model answer: 80.0\n",
      "Ground truth answer: 42.0\n",
      "Correct: 74 out of 1319\n",
      "========================================\n",
      "task_id 606\n",
      "Model answer: None\n",
      "Ground truth answer: 6.0\n",
      "Correct: 74 out of 1319\n",
      "========================================\n",
      "task_id 607\n",
      "Model answer: 0.2\n",
      "Ground truth answer: 10.0\n",
      "Correct: 74 out of 1319\n",
      "========================================\n",
      "task_id 608\n",
      "Model answer: 35.0\n",
      "Ground truth answer: 8.0\n",
      "Correct: 74 out of 1319\n",
      "========================================\n",
      "task_id 609\n",
      "Model answer: None\n",
      "Ground truth answer: 7.0\n",
      "Correct: 74 out of 1319\n",
      "========================================\n",
      "task_id 610\n",
      "Model answer: 944.0\n",
      "Ground truth answer: 960.0\n",
      "Correct: 74 out of 1319\n",
      "========================================\n",
      "task_id 611\n",
      "Model answer: None\n",
      "Ground truth answer: 0.0\n",
      "Correct: 74 out of 1319\n",
      "========================================\n",
      "task_id 612\n",
      "Model answer: None\n",
      "Ground truth answer: 30.0\n",
      "Correct: 74 out of 1319\n",
      "========================================\n",
      "task_id 613\n",
      "Model answer: 3000.0\n",
      "Ground truth answer: 93000.0\n",
      "Correct: 74 out of 1319\n",
      "========================================\n",
      "task_id 614\n",
      "Model answer: None\n",
      "Ground truth answer: 312.0\n",
      "Correct: 74 out of 1319\n",
      "========================================\n",
      "task_id 615\n",
      "Model answer: None\n",
      "Ground truth answer: 33.0\n",
      "Correct: 74 out of 1319\n",
      "========================================\n",
      "task_id 616\n",
      "Model answer: 10.0\n",
      "Ground truth answer: 10.0\n",
      "Correct: 75 out of 1319\n",
      "========================================\n",
      "task_id 617\n",
      "Model answer: 5.0\n",
      "Ground truth answer: 5.0\n",
      "Correct: 76 out of 1319\n",
      "========================================\n",
      "task_id 618\n",
      "Model answer: None\n",
      "Ground truth answer: 36.0\n",
      "Correct: 76 out of 1319\n",
      "========================================\n",
      "task_id 619\n",
      "Model answer: 4.0\n",
      "Ground truth answer: 76.0\n",
      "Correct: 76 out of 1319\n",
      "========================================\n",
      "task_id 620\n",
      "Model answer: 491.0\n",
      "Ground truth answer: 1509.0\n",
      "Correct: 76 out of 1319\n",
      "========================================\n",
      "task_id 621\n",
      "Model answer: 1500.0\n",
      "Ground truth answer: 3000.0\n",
      "Correct: 76 out of 1319\n",
      "========================================\n",
      "task_id 622\n",
      "Model answer: None\n",
      "Ground truth answer: 7.0\n",
      "Correct: 76 out of 1319\n",
      "========================================\n",
      "task_id 623\n",
      "Model answer: 20.0\n",
      "Ground truth answer: 8.0\n",
      "Correct: 76 out of 1319\n",
      "========================================\n",
      "task_id 624\n",
      "Model answer: 89.0\n",
      "Ground truth answer: 85.0\n",
      "Correct: 76 out of 1319\n",
      "========================================\n",
      "task_id 625\n",
      "Model answer: 16.0\n",
      "Ground truth answer: 160.0\n",
      "Correct: 76 out of 1319\n",
      "========================================\n",
      "task_id 626\n",
      "Model answer: 7200000.0\n",
      "Ground truth answer: 72.0\n",
      "Correct: 76 out of 1319\n",
      "========================================\n",
      "task_id 627\n",
      "Model answer: 4.0\n",
      "Ground truth answer: 54.0\n",
      "Correct: 76 out of 1319\n",
      "========================================\n",
      "task_id 628\n",
      "Model answer: 2.0\n",
      "Ground truth answer: 4.0\n",
      "Correct: 76 out of 1319\n",
      "========================================\n",
      "task_id 629\n",
      "Model answer: 1.0\n",
      "Ground truth answer: 17500.0\n",
      "Correct: 76 out of 1319\n",
      "========================================\n",
      "task_id 630\n",
      "Model answer: 15.0\n",
      "Ground truth answer: 10.0\n",
      "Correct: 76 out of 1319\n",
      "========================================\n",
      "task_id 631\n",
      "Model answer: None\n",
      "Ground truth answer: 4800.0\n",
      "Correct: 76 out of 1319\n",
      "========================================\n",
      "task_id 632\n",
      "Model answer: 19.0\n",
      "Ground truth answer: 45.0\n",
      "Correct: 76 out of 1319\n",
      "========================================\n",
      "task_id 633\n",
      "Model answer: 5.0\n",
      "Ground truth answer: 5.0\n",
      "Correct: 77 out of 1319\n",
      "========================================\n",
      "task_id 634\n",
      "Model answer: 9.0\n",
      "Ground truth answer: 14.0\n",
      "Correct: 77 out of 1319\n",
      "========================================\n",
      "task_id 635\n",
      "Model answer: 10.0\n",
      "Ground truth answer: 4.0\n",
      "Correct: 77 out of 1319\n",
      "========================================\n",
      "task_id 636\n",
      "Model answer: 100.0\n",
      "Ground truth answer: 1050.0\n",
      "Correct: 77 out of 1319\n",
      "========================================\n",
      "task_id 637\n",
      "Model answer: 8.0\n",
      "Ground truth answer: 17.0\n",
      "Correct: 77 out of 1319\n",
      "========================================\n",
      "task_id 638\n",
      "Model answer: 8.5\n",
      "Ground truth answer: 12.0\n",
      "Correct: 77 out of 1319\n",
      "========================================\n",
      "task_id 639\n",
      "Model answer: 32.0\n",
      "Ground truth answer: 216.0\n",
      "Correct: 77 out of 1319\n",
      "========================================\n",
      "task_id 640\n",
      "Model answer: None\n",
      "Ground truth answer: 500.0\n",
      "Correct: 77 out of 1319\n",
      "========================================\n",
      "task_id 641\n",
      "Model answer: 21000.0\n",
      "Ground truth answer: 262500.0\n",
      "Correct: 77 out of 1319\n",
      "========================================\n",
      "task_id 642\n",
      "Model answer: 10500.0\n",
      "Ground truth answer: 800.0\n",
      "Correct: 77 out of 1319\n",
      "========================================\n",
      "task_id 643\n",
      "Model answer: 840.0\n",
      "Ground truth answer: 840.0\n",
      "Correct: 78 out of 1319\n",
      "========================================\n",
      "task_id 644\n",
      "Model answer: None\n",
      "Ground truth answer: 29.0\n",
      "Correct: 78 out of 1319\n",
      "========================================\n",
      "task_id 645\n",
      "Model answer: 5.66\n",
      "Ground truth answer: 48.0\n",
      "Correct: 78 out of 1319\n",
      "========================================\n",
      "task_id 646\n",
      "Model answer: 79.0\n",
      "Ground truth answer: 79.0\n",
      "Correct: 79 out of 1319\n",
      "========================================\n",
      "task_id 647\n",
      "Model answer: 10.0\n",
      "Ground truth answer: 10.0\n",
      "Correct: 80 out of 1319\n",
      "========================================\n",
      "task_id 648\n",
      "Model answer: 50.0\n",
      "Ground truth answer: 54.0\n",
      "Correct: 80 out of 1319\n",
      "========================================\n",
      "task_id 649\n",
      "Model answer: None\n",
      "Ground truth answer: 162000.0\n",
      "Correct: 80 out of 1319\n",
      "========================================\n",
      "task_id 650\n",
      "Model answer: None\n",
      "Ground truth answer: 142.0\n",
      "Correct: 80 out of 1319\n",
      "========================================\n",
      "task_id 651\n",
      "Model answer: None\n",
      "Ground truth answer: 2100.0\n",
      "Correct: 80 out of 1319\n",
      "========================================\n",
      "task_id 652\n",
      "Model answer: 120.0\n",
      "Ground truth answer: 75.0\n",
      "Correct: 80 out of 1319\n",
      "========================================\n",
      "task_id 653\n",
      "Model answer: -20.0\n",
      "Ground truth answer: 80.0\n",
      "Correct: 80 out of 1319\n",
      "========================================\n",
      "task_id 654\n",
      "Model answer: 48.0\n",
      "Ground truth answer: 2.0\n",
      "Correct: 80 out of 1319\n",
      "========================================\n",
      "task_id 655\n",
      "Model answer: 10.0\n",
      "Ground truth answer: 10.0\n",
      "Correct: 81 out of 1319\n",
      "========================================\n",
      "task_id 656\n",
      "Model answer: 66.6\n",
      "Ground truth answer: 10.0\n",
      "Correct: 81 out of 1319\n",
      "========================================\n",
      "task_id 657\n",
      "Model answer: 0.0\n",
      "Ground truth answer: 330000.0\n",
      "Correct: 81 out of 1319\n",
      "========================================\n",
      "task_id 658\n",
      "Model answer: None\n",
      "Ground truth answer: 120.0\n",
      "Correct: 81 out of 1319\n",
      "========================================\n",
      "task_id 659\n",
      "Model answer: None\n",
      "Ground truth answer: 3.0\n",
      "Correct: 81 out of 1319\n",
      "========================================\n",
      "task_id 660\n",
      "Model answer: 50.0\n",
      "Ground truth answer: 15.0\n",
      "Correct: 81 out of 1319\n",
      "========================================\n",
      "task_id 661\n",
      "Model answer: 37.0\n",
      "Ground truth answer: 44.0\n",
      "Correct: 81 out of 1319\n",
      "========================================\n",
      "task_id 662\n",
      "Model answer: None\n",
      "Ground truth answer: 7.0\n",
      "Correct: 81 out of 1319\n",
      "========================================\n",
      "task_id 663\n",
      "Model answer: 193.0\n",
      "Ground truth answer: 193.0\n",
      "Correct: 82 out of 1319\n",
      "========================================\n",
      "task_id 664\n",
      "Model answer: 36.0\n",
      "Ground truth answer: 32.0\n",
      "Correct: 82 out of 1319\n",
      "========================================\n",
      "task_id 665\n",
      "Model answer: 240.0\n",
      "Ground truth answer: 360.0\n",
      "Correct: 82 out of 1319\n",
      "========================================\n",
      "task_id 666\n",
      "Model answer: None\n",
      "Ground truth answer: 120.0\n",
      "Correct: 82 out of 1319\n",
      "========================================\n",
      "task_id 667\n",
      "Model answer: 60.0\n",
      "Ground truth answer: 53.0\n",
      "Correct: 82 out of 1319\n",
      "========================================\n",
      "task_id 668\n",
      "Model answer: 6.0\n",
      "Ground truth answer: 3.0\n",
      "Correct: 82 out of 1319\n",
      "========================================\n",
      "task_id 669\n",
      "Model answer: None\n",
      "Ground truth answer: 132.0\n",
      "Correct: 82 out of 1319\n",
      "========================================\n",
      "task_id 670\n",
      "Model answer: 4.0\n",
      "Ground truth answer: 4.0\n",
      "Correct: 83 out of 1319\n",
      "========================================\n",
      "task_id 671\n",
      "Model answer: 0.75\n",
      "Ground truth answer: 4.0\n",
      "Correct: 83 out of 1319\n",
      "========================================\n",
      "task_id 672\n",
      "Model answer: 4.0\n",
      "Ground truth answer: 2.0\n",
      "Correct: 83 out of 1319\n",
      "========================================\n",
      "task_id 673\n",
      "Model answer: 15.0\n",
      "Ground truth answer: 9.0\n",
      "Correct: 83 out of 1319\n",
      "========================================\n",
      "task_id 674\n",
      "Model answer: 600.0\n",
      "Ground truth answer: 12.0\n",
      "Correct: 83 out of 1319\n",
      "========================================\n",
      "task_id 675\n",
      "Model answer: None\n",
      "Ground truth answer: 33.0\n",
      "Correct: 83 out of 1319\n",
      "========================================\n",
      "task_id 676\n",
      "Model answer: 15.0\n",
      "Ground truth answer: 240.0\n",
      "Correct: 83 out of 1319\n",
      "========================================\n",
      "task_id 677\n",
      "Model answer: 36.0\n",
      "Ground truth answer: 36.0\n",
      "Correct: 84 out of 1319\n",
      "========================================\n",
      "task_id 678\n",
      "Model answer: 120.0\n",
      "Ground truth answer: 120.0\n",
      "Correct: 85 out of 1319\n",
      "========================================\n",
      "task_id 679\n",
      "Model answer: 3364.0\n",
      "Ground truth answer: 576.0\n",
      "Correct: 85 out of 1319\n",
      "========================================\n",
      "task_id 680\n",
      "Model answer: -60.0\n",
      "Ground truth answer: 20.0\n",
      "Correct: 85 out of 1319\n",
      "========================================\n",
      "task_id 681\n",
      "Model answer: 183.0\n",
      "Ground truth answer: 298.0\n",
      "Correct: 85 out of 1319\n",
      "========================================\n",
      "task_id 682\n",
      "Model answer: 70.0\n",
      "Ground truth answer: 80.0\n",
      "Correct: 85 out of 1319\n",
      "========================================\n",
      "task_id 683\n",
      "Model answer: None\n",
      "Ground truth answer: 50.0\n",
      "Correct: 85 out of 1319\n",
      "========================================\n",
      "task_id 684\n",
      "Model answer: 11.0\n",
      "Ground truth answer: 11.0\n",
      "Correct: 86 out of 1319\n",
      "========================================\n",
      "task_id 685\n",
      "Model answer: 11.0\n",
      "Ground truth answer: 14.0\n",
      "Correct: 86 out of 1319\n",
      "========================================\n",
      "task_id 686\n",
      "Model answer: 50.0\n",
      "Ground truth answer: 80.0\n",
      "Correct: 86 out of 1319\n",
      "========================================\n",
      "task_id 687\n",
      "Model answer: None\n",
      "Ground truth answer: 13.0\n",
      "Correct: 86 out of 1319\n",
      "========================================\n",
      "task_id 688\n",
      "Model answer: 26.0\n",
      "Ground truth answer: 100.0\n",
      "Correct: 86 out of 1319\n",
      "========================================\n",
      "task_id 689\n",
      "Model answer: None\n",
      "Ground truth answer: 7.0\n",
      "Correct: 86 out of 1319\n",
      "========================================\n",
      "task_id 690\n",
      "Model answer: None\n",
      "Ground truth answer: 5760.0\n",
      "Correct: 86 out of 1319\n",
      "========================================\n",
      "task_id 691\n",
      "Model answer: 5.0\n",
      "Ground truth answer: 25.0\n",
      "Correct: 86 out of 1319\n",
      "========================================\n",
      "task_id 692\n",
      "Model answer: None\n",
      "Ground truth answer: 32.0\n",
      "Correct: 86 out of 1319\n",
      "========================================\n",
      "task_id 693\n",
      "Model answer: None\n",
      "Ground truth answer: 68.0\n",
      "Correct: 86 out of 1319\n",
      "========================================\n",
      "task_id 694\n",
      "Model answer: 40.0\n",
      "Ground truth answer: 9.0\n",
      "Correct: 86 out of 1319\n",
      "========================================\n",
      "task_id 695\n",
      "Model answer: 5.0\n",
      "Ground truth answer: 5.0\n",
      "Correct: 87 out of 1319\n",
      "========================================\n",
      "task_id 696\n",
      "Model answer: 200.0\n",
      "Ground truth answer: 145.0\n",
      "Correct: 87 out of 1319\n",
      "========================================\n",
      "task_id 697\n",
      "Model answer: None\n",
      "Ground truth answer: 27.0\n",
      "Correct: 87 out of 1319\n",
      "========================================\n",
      "task_id 698\n",
      "Model answer: 240.0\n",
      "Ground truth answer: 720.0\n",
      "Correct: 87 out of 1319\n",
      "========================================\n",
      "task_id 699\n",
      "Model answer: None\n",
      "Ground truth answer: 8.0\n",
      "Correct: 87 out of 1319\n",
      "========================================\n",
      "task_id 700\n",
      "Model answer: None\n",
      "Ground truth answer: 135.0\n",
      "Correct: 87 out of 1319\n",
      "========================================\n",
      "task_id 701\n",
      "Model answer: 144.0\n",
      "Ground truth answer: 200.0\n",
      "Correct: 87 out of 1319\n",
      "========================================\n",
      "task_id 702\n",
      "Model answer: None\n",
      "Ground truth answer: 2800.0\n",
      "Correct: 87 out of 1319\n",
      "========================================\n",
      "task_id 703\n",
      "Model answer: None\n",
      "Ground truth answer: 50.0\n",
      "Correct: 87 out of 1319\n",
      "========================================\n",
      "task_id 704\n",
      "Model answer: 4.0\n",
      "Ground truth answer: 50.0\n",
      "Correct: 87 out of 1319\n",
      "========================================\n",
      "task_id 705\n",
      "Model answer: 45.0\n",
      "Ground truth answer: 120.0\n",
      "Correct: 87 out of 1319\n",
      "========================================\n",
      "task_id 706\n",
      "Model answer: 9.0\n",
      "Ground truth answer: 9.0\n",
      "Correct: 88 out of 1319\n",
      "========================================\n",
      "task_id 707\n",
      "Model answer: 40.0\n",
      "Ground truth answer: 8.0\n",
      "Correct: 88 out of 1319\n",
      "========================================\n",
      "task_id 708\n",
      "Model answer: 24.0\n",
      "Ground truth answer: 168.0\n",
      "Correct: 88 out of 1319\n",
      "========================================\n",
      "task_id 709\n",
      "Model answer: 7200.0\n",
      "Ground truth answer: 3000.0\n",
      "Correct: 88 out of 1319\n",
      "========================================\n",
      "task_id 710\n",
      "Model answer: None\n",
      "Ground truth answer: 45.0\n",
      "Correct: 88 out of 1319\n",
      "========================================\n",
      "task_id 711\n",
      "Model answer: None\n",
      "Ground truth answer: 6.0\n",
      "Correct: 88 out of 1319\n",
      "========================================\n",
      "task_id 712\n",
      "Model answer: 14.0\n",
      "Ground truth answer: 14.0\n",
      "Correct: 89 out of 1319\n",
      "========================================\n",
      "task_id 713\n",
      "Model answer: 864.0\n",
      "Ground truth answer: 576.0\n",
      "Correct: 89 out of 1319\n",
      "========================================\n",
      "task_id 714\n",
      "Model answer: 49.0\n",
      "Ground truth answer: 10.0\n",
      "Correct: 89 out of 1319\n",
      "========================================\n",
      "task_id 715\n",
      "Model answer: 385000.0\n",
      "Ground truth answer: 385000.0\n",
      "Correct: 90 out of 1319\n",
      "========================================\n",
      "task_id 716\n",
      "Model answer: 73.0\n",
      "Ground truth answer: 770.0\n",
      "Correct: 90 out of 1319\n",
      "========================================\n",
      "task_id 717\n",
      "Model answer: 5.0\n",
      "Ground truth answer: 5.0\n",
      "Correct: 91 out of 1319\n",
      "========================================\n",
      "task_id 718\n",
      "Model answer: 0.06\n",
      "Ground truth answer: 2.0\n",
      "Correct: 91 out of 1319\n",
      "========================================\n",
      "task_id 719\n",
      "Model answer: 175.0\n",
      "Ground truth answer: 175.0\n",
      "Correct: 92 out of 1319\n",
      "========================================\n",
      "task_id 720\n",
      "Model answer: 4.0\n",
      "Ground truth answer: 4.0\n",
      "Correct: 93 out of 1319\n",
      "========================================\n",
      "task_id 721\n",
      "Model answer: 1050.0\n",
      "Ground truth answer: 2450.0\n",
      "Correct: 93 out of 1319\n",
      "========================================\n",
      "task_id 722\n",
      "Model answer: 45.0\n",
      "Ground truth answer: 255.0\n",
      "Correct: 93 out of 1319\n",
      "========================================\n",
      "task_id 723\n",
      "Model answer: 127.0\n",
      "Ground truth answer: 160.0\n",
      "Correct: 93 out of 1319\n",
      "========================================\n",
      "task_id 724\n",
      "Model answer: None\n",
      "Ground truth answer: 18.0\n",
      "Correct: 93 out of 1319\n",
      "========================================\n",
      "task_id 725\n",
      "Model answer: 3.0\n",
      "Ground truth answer: 25.0\n",
      "Correct: 93 out of 1319\n",
      "========================================\n",
      "task_id 726\n",
      "Model answer: 90.0\n",
      "Ground truth answer: 10.0\n",
      "Correct: 93 out of 1319\n",
      "========================================\n",
      "task_id 727\n",
      "Model answer: 196.0\n",
      "Ground truth answer: 112.0\n",
      "Correct: 93 out of 1319\n",
      "========================================\n",
      "task_id 728\n",
      "Model answer: 100.0\n",
      "Ground truth answer: 40.0\n",
      "Correct: 93 out of 1319\n",
      "========================================\n",
      "task_id 729\n",
      "Model answer: None\n",
      "Ground truth answer: 1000.0\n",
      "Correct: 93 out of 1319\n",
      "========================================\n",
      "task_id 730\n",
      "Model answer: 1800.0\n",
      "Ground truth answer: 8.0\n",
      "Correct: 93 out of 1319\n",
      "========================================\n",
      "task_id 731\n",
      "Model answer: 1.0\n",
      "Ground truth answer: 1.0\n",
      "Correct: 94 out of 1319\n",
      "========================================\n",
      "task_id 732\n",
      "Model answer: None\n",
      "Ground truth answer: 87.0\n",
      "Correct: 94 out of 1319\n",
      "========================================\n",
      "task_id 733\n",
      "Model answer: 5.0\n",
      "Ground truth answer: 5.0\n",
      "Correct: 95 out of 1319\n",
      "========================================\n",
      "task_id 734\n",
      "Model answer: 11.0\n",
      "Ground truth answer: 17.0\n",
      "Correct: 95 out of 1319\n",
      "========================================\n",
      "task_id 735\n",
      "Model answer: 50.0\n",
      "Ground truth answer: 50.0\n",
      "Correct: 96 out of 1319\n",
      "========================================\n",
      "task_id 736\n",
      "Model answer: 67.0\n",
      "Ground truth answer: 3.0\n",
      "Correct: 96 out of 1319\n",
      "========================================\n",
      "task_id 737\n",
      "Model answer: None\n",
      "Ground truth answer: 2.0\n",
      "Correct: 96 out of 1319\n",
      "========================================\n",
      "task_id 738\n",
      "Model answer: 14.0\n",
      "Ground truth answer: 4.0\n",
      "Correct: 96 out of 1319\n",
      "========================================\n",
      "task_id 739\n",
      "Model answer: 82.0\n",
      "Ground truth answer: 98.0\n",
      "Correct: 96 out of 1319\n",
      "========================================\n",
      "task_id 740\n",
      "Model answer: 20.0\n",
      "Ground truth answer: 25.0\n",
      "Correct: 96 out of 1319\n",
      "========================================\n",
      "task_id 741\n",
      "Model answer: 24.0\n",
      "Ground truth answer: 28.0\n",
      "Correct: 96 out of 1319\n",
      "========================================\n",
      "task_id 742\n",
      "Model answer: 48.0\n",
      "Ground truth answer: 24.0\n",
      "Correct: 96 out of 1319\n",
      "========================================\n",
      "task_id 743\n",
      "Model answer: None\n",
      "Ground truth answer: 8.0\n",
      "Correct: 96 out of 1319\n",
      "========================================\n",
      "task_id 744\n",
      "Model answer: 30.0\n",
      "Ground truth answer: 4.0\n",
      "Correct: 96 out of 1319\n",
      "========================================\n",
      "task_id 745\n",
      "Model answer: None\n",
      "Ground truth answer: 1100.0\n",
      "Correct: 96 out of 1319\n",
      "========================================\n",
      "task_id 746\n",
      "Model answer: None\n",
      "Ground truth answer: 28.0\n",
      "Correct: 96 out of 1319\n",
      "========================================\n",
      "task_id 747\n",
      "Model answer: 50.0\n",
      "Ground truth answer: 350.0\n",
      "Correct: 96 out of 1319\n",
      "========================================\n",
      "task_id 748\n",
      "Model answer: 87.0\n",
      "Ground truth answer: 336.0\n",
      "Correct: 96 out of 1319\n",
      "========================================\n",
      "task_id 749\n",
      "Model answer: 5.0\n",
      "Ground truth answer: 3.0\n",
      "Correct: 96 out of 1319\n",
      "========================================\n",
      "task_id 750\n",
      "Model answer: None\n",
      "Ground truth answer: 4000.0\n",
      "Correct: 96 out of 1319\n",
      "========================================\n",
      "task_id 751\n",
      "Model answer: 73.0\n",
      "Ground truth answer: 43.0\n",
      "Correct: 96 out of 1319\n",
      "========================================\n",
      "task_id 752\n",
      "Model answer: 300.0\n",
      "Ground truth answer: 240.0\n",
      "Correct: 96 out of 1319\n",
      "========================================\n",
      "task_id 753\n",
      "Model answer: 42.0\n",
      "Ground truth answer: 128.0\n",
      "Correct: 96 out of 1319\n",
      "========================================\n",
      "task_id 754\n",
      "Model answer: None\n",
      "Ground truth answer: 89.0\n",
      "Correct: 96 out of 1319\n",
      "========================================\n",
      "task_id 755\n",
      "Model answer: 3.0\n",
      "Ground truth answer: 7.0\n",
      "Correct: 96 out of 1319\n",
      "========================================\n",
      "task_id 756\n",
      "Model answer: 17.0\n",
      "Ground truth answer: 22.0\n",
      "Correct: 96 out of 1319\n",
      "========================================\n",
      "task_id 757\n",
      "Model answer: 40.0\n",
      "Ground truth answer: 75.0\n",
      "Correct: 96 out of 1319\n",
      "========================================\n",
      "task_id 758\n",
      "Model answer: 136.0\n",
      "Ground truth answer: 133.0\n",
      "Correct: 96 out of 1319\n",
      "========================================\n",
      "task_id 759\n",
      "Model answer: None\n",
      "Ground truth answer: 60000.0\n",
      "Correct: 96 out of 1319\n",
      "========================================\n",
      "task_id 760\n",
      "Model answer: None\n",
      "Ground truth answer: 16.0\n",
      "Correct: 96 out of 1319\n",
      "========================================\n",
      "task_id 761\n",
      "Model answer: 6.0\n",
      "Ground truth answer: 27.0\n",
      "Correct: 96 out of 1319\n",
      "========================================\n",
      "task_id 762\n",
      "Model answer: 155.0\n",
      "Ground truth answer: 85.0\n",
      "Correct: 96 out of 1319\n",
      "========================================\n",
      "task_id 763\n",
      "Model answer: 500.0\n",
      "Ground truth answer: 100.0\n",
      "Correct: 96 out of 1319\n",
      "========================================\n",
      "task_id 764\n",
      "Model answer: 14.0\n",
      "Ground truth answer: 14.0\n",
      "Correct: 97 out of 1319\n",
      "========================================\n",
      "task_id 765\n",
      "Model answer: None\n",
      "Ground truth answer: 490.0\n",
      "Correct: 97 out of 1319\n",
      "========================================\n",
      "task_id 766\n",
      "Model answer: 60.0\n",
      "Ground truth answer: 12.0\n",
      "Correct: 97 out of 1319\n",
      "========================================\n",
      "task_id 767\n",
      "Model answer: 60.0\n",
      "Ground truth answer: 60.0\n",
      "Correct: 98 out of 1319\n",
      "========================================\n",
      "task_id 768\n",
      "Model answer: 450.0\n",
      "Ground truth answer: 675.0\n",
      "Correct: 98 out of 1319\n",
      "========================================\n",
      "task_id 769\n",
      "Model answer: 25.0\n",
      "Ground truth answer: 110.0\n",
      "Correct: 98 out of 1319\n",
      "========================================\n",
      "task_id 770\n",
      "Model answer: 4.0\n",
      "Ground truth answer: 4.0\n",
      "Correct: 99 out of 1319\n",
      "========================================\n",
      "task_id 771\n",
      "Model answer: 75.0\n",
      "Ground truth answer: 3.0\n",
      "Correct: 99 out of 1319\n",
      "========================================\n",
      "task_id 772\n",
      "Model answer: 71.0\n",
      "Ground truth answer: 50.0\n",
      "Correct: 99 out of 1319\n",
      "========================================\n",
      "task_id 773\n",
      "Model answer: 16.0\n",
      "Ground truth answer: 10.0\n",
      "Correct: 99 out of 1319\n",
      "========================================\n",
      "task_id 774\n",
      "Model answer: None\n",
      "Ground truth answer: 10.0\n",
      "Correct: 99 out of 1319\n",
      "========================================\n",
      "task_id 775\n",
      "Model answer: 374.0\n",
      "Ground truth answer: 276.0\n",
      "Correct: 99 out of 1319\n",
      "========================================\n",
      "task_id 776\n",
      "Model answer: 800.0\n",
      "Ground truth answer: 800.0\n",
      "Correct: 100 out of 1319\n",
      "========================================\n",
      "task_id 777\n",
      "Model answer: None\n",
      "Ground truth answer: 4400.0\n",
      "Correct: 100 out of 1319\n",
      "========================================\n",
      "task_id 778\n",
      "Model answer: 38.0\n",
      "Ground truth answer: 38.0\n",
      "Correct: 101 out of 1319\n",
      "========================================\n",
      "task_id 779\n",
      "Model answer: 77.5\n",
      "Ground truth answer: 255.0\n",
      "Correct: 101 out of 1319\n",
      "========================================\n",
      "task_id 780\n",
      "Model answer: None\n",
      "Ground truth answer: 25.0\n",
      "Correct: 101 out of 1319\n",
      "========================================\n",
      "task_id 781\n",
      "Model answer: 34.0\n",
      "Ground truth answer: 17.0\n",
      "Correct: 101 out of 1319\n",
      "========================================\n",
      "task_id 782\n",
      "Model answer: 18.0\n",
      "Ground truth answer: 54.0\n",
      "Correct: 101 out of 1319\n",
      "========================================\n",
      "task_id 783\n",
      "Model answer: 24.0\n",
      "Ground truth answer: 4.0\n",
      "Correct: 101 out of 1319\n",
      "========================================\n",
      "task_id 784\n",
      "Model answer: 150.0\n",
      "Ground truth answer: 15.0\n",
      "Correct: 101 out of 1319\n",
      "========================================\n",
      "task_id 785\n",
      "Model answer: None\n",
      "Ground truth answer: 155.0\n",
      "Correct: 101 out of 1319\n",
      "========================================\n",
      "task_id 786\n",
      "Model answer: 142.0\n",
      "Ground truth answer: 142.0\n",
      "Correct: 102 out of 1319\n",
      "========================================\n",
      "task_id 787\n",
      "Model answer: 2.0\n",
      "Ground truth answer: 25.0\n",
      "Correct: 102 out of 1319\n",
      "========================================\n",
      "task_id 788\n",
      "Model answer: 150.0\n",
      "Ground truth answer: 100.0\n",
      "Correct: 102 out of 1319\n",
      "========================================\n",
      "task_id 789\n",
      "Model answer: None\n",
      "Ground truth answer: 4.0\n",
      "Correct: 102 out of 1319\n",
      "========================================\n",
      "task_id 790\n",
      "Model answer: 36.0\n",
      "Ground truth answer: 108.0\n",
      "Correct: 102 out of 1319\n",
      "========================================\n",
      "task_id 791\n",
      "Model answer: 87.0\n",
      "Ground truth answer: 100.0\n",
      "Correct: 102 out of 1319\n",
      "========================================\n",
      "task_id 792\n",
      "Model answer: 75.0\n",
      "Ground truth answer: 75.0\n",
      "Correct: 103 out of 1319\n",
      "========================================\n",
      "task_id 793\n",
      "Model answer: 240.0\n",
      "Ground truth answer: 250.0\n",
      "Correct: 103 out of 1319\n",
      "========================================\n",
      "task_id 794\n",
      "Model answer: 32.0\n",
      "Ground truth answer: 32.0\n",
      "Correct: 104 out of 1319\n",
      "========================================\n",
      "task_id 795\n",
      "Model answer: 20.0\n",
      "Ground truth answer: 20.0\n",
      "Correct: 105 out of 1319\n",
      "========================================\n",
      "task_id 796\n",
      "Model answer: 600000.0\n",
      "Ground truth answer: 2880000.0\n",
      "Correct: 105 out of 1319\n",
      "========================================\n",
      "task_id 797\n",
      "Model answer: 490.0\n",
      "Ground truth answer: 540.0\n",
      "Correct: 105 out of 1319\n",
      "========================================\n",
      "task_id 798\n",
      "Model answer: None\n",
      "Ground truth answer: 20.0\n",
      "Correct: 105 out of 1319\n",
      "========================================\n",
      "task_id 799\n",
      "Model answer: 4.0\n",
      "Ground truth answer: 4.0\n",
      "Correct: 106 out of 1319\n",
      "========================================\n",
      "task_id 800\n",
      "Model answer: 289.0\n",
      "Ground truth answer: 428.0\n",
      "Correct: 106 out of 1319\n",
      "========================================\n",
      "task_id 801\n",
      "Model answer: None\n",
      "Ground truth answer: 1240.0\n",
      "Correct: 106 out of 1319\n",
      "========================================\n",
      "task_id 802\n",
      "Model answer: None\n",
      "Ground truth answer: 6.0\n",
      "Correct: 106 out of 1319\n",
      "========================================\n",
      "task_id 803\n",
      "Model answer: 44.0\n",
      "Ground truth answer: 9.0\n",
      "Correct: 106 out of 1319\n",
      "========================================\n",
      "task_id 804\n",
      "Model answer: None\n",
      "Ground truth answer: 20.0\n",
      "Correct: 106 out of 1319\n",
      "========================================\n",
      "task_id 805\n",
      "Model answer: 780.0\n",
      "Ground truth answer: 1170.0\n",
      "Correct: 106 out of 1319\n",
      "========================================\n",
      "task_id 806\n",
      "Model answer: 40.0\n",
      "Ground truth answer: 70.0\n",
      "Correct: 106 out of 1319\n",
      "========================================\n",
      "task_id 807\n",
      "Model answer: 6.0\n",
      "Ground truth answer: 4.0\n",
      "Correct: 106 out of 1319\n",
      "========================================\n",
      "task_id 808\n",
      "Model answer: 32.0\n",
      "Ground truth answer: 12.0\n",
      "Correct: 106 out of 1319\n",
      "========================================\n",
      "task_id 809\n",
      "Model answer: 50.0\n",
      "Ground truth answer: 50.0\n",
      "Correct: 107 out of 1319\n",
      "========================================\n",
      "task_id 810\n",
      "Model answer: None\n",
      "Ground truth answer: 310.0\n",
      "Correct: 107 out of 1319\n",
      "========================================\n",
      "task_id 811\n",
      "Model answer: 15.0\n",
      "Ground truth answer: 60.0\n",
      "Correct: 107 out of 1319\n",
      "========================================\n",
      "task_id 812\n",
      "Model answer: None\n",
      "Ground truth answer: 79.0\n",
      "Correct: 107 out of 1319\n",
      "========================================\n",
      "task_id 813\n",
      "Model answer: 11.5\n",
      "Ground truth answer: 7.0\n",
      "Correct: 107 out of 1319\n",
      "========================================\n",
      "task_id 814\n",
      "Model answer: None\n",
      "Ground truth answer: 11.0\n",
      "Correct: 107 out of 1319\n",
      "========================================\n",
      "task_id 815\n",
      "Model answer: 20.0\n",
      "Ground truth answer: 4.0\n",
      "Correct: 107 out of 1319\n",
      "========================================\n",
      "task_id 816\n",
      "Model answer: 1500.0\n",
      "Ground truth answer: 4500.0\n",
      "Correct: 107 out of 1319\n",
      "========================================\n",
      "task_id 817\n",
      "Model answer: 15.0\n",
      "Ground truth answer: 15.0\n",
      "Correct: 108 out of 1319\n",
      "========================================\n",
      "task_id 818\n",
      "Model answer: None\n",
      "Ground truth answer: 16.0\n",
      "Correct: 108 out of 1319\n",
      "========================================\n",
      "task_id 819\n",
      "Model answer: 250.0\n",
      "Ground truth answer: 250.0\n",
      "Correct: 109 out of 1319\n",
      "========================================\n",
      "task_id 820\n",
      "Model answer: 12.0\n",
      "Ground truth answer: 720.0\n",
      "Correct: 109 out of 1319\n",
      "========================================\n",
      "task_id 821\n",
      "Model answer: 35.0\n",
      "Ground truth answer: 35.0\n",
      "Correct: 110 out of 1319\n",
      "========================================\n",
      "task_id 822\n",
      "Model answer: 9.0\n",
      "Ground truth answer: 1260.0\n",
      "Correct: 110 out of 1319\n",
      "========================================\n",
      "task_id 823\n",
      "Model answer: 20.0\n",
      "Ground truth answer: 14.0\n",
      "Correct: 110 out of 1319\n",
      "========================================\n",
      "task_id 824\n",
      "Model answer: 59.0\n",
      "Ground truth answer: 52.0\n",
      "Correct: 110 out of 1319\n",
      "========================================\n",
      "task_id 825\n",
      "Model answer: None\n",
      "Ground truth answer: 153.0\n",
      "Correct: 110 out of 1319\n",
      "========================================\n",
      "task_id 826\n",
      "Model answer: 17.0\n",
      "Ground truth answer: 27.0\n",
      "Correct: 110 out of 1319\n",
      "========================================\n",
      "task_id 827\n",
      "Model answer: None\n",
      "Ground truth answer: 11.0\n",
      "Correct: 110 out of 1319\n",
      "========================================\n",
      "task_id 828\n",
      "Model answer: 160.0\n",
      "Ground truth answer: 60.0\n",
      "Correct: 110 out of 1319\n",
      "========================================\n",
      "task_id 829\n",
      "Model answer: None\n",
      "Ground truth answer: 0.0\n",
      "Correct: 110 out of 1319\n",
      "========================================\n",
      "task_id 830\n",
      "Model answer: 140.0\n",
      "Ground truth answer: 1128.0\n",
      "Correct: 110 out of 1319\n",
      "========================================\n",
      "task_id 831\n",
      "Model answer: 15.0\n",
      "Ground truth answer: 324.0\n",
      "Correct: 110 out of 1319\n",
      "========================================\n",
      "task_id 832\n",
      "Model answer: None\n",
      "Ground truth answer: 42.0\n",
      "Correct: 110 out of 1319\n",
      "========================================\n",
      "task_id 833\n",
      "Model answer: 480.0\n",
      "Ground truth answer: 40.0\n",
      "Correct: 110 out of 1319\n",
      "========================================\n",
      "task_id 834\n",
      "Model answer: None\n",
      "Ground truth answer: 80.0\n",
      "Correct: 110 out of 1319\n",
      "========================================\n",
      "task_id 835\n",
      "Model answer: None\n",
      "Ground truth answer: 48.0\n",
      "Correct: 110 out of 1319\n",
      "========================================\n",
      "task_id 836\n",
      "Model answer: 80.0\n",
      "Ground truth answer: 140.0\n",
      "Correct: 110 out of 1319\n",
      "========================================\n",
      "task_id 837\n",
      "Model answer: 200.0\n",
      "Ground truth answer: 120.0\n",
      "Correct: 110 out of 1319\n",
      "========================================\n",
      "task_id 838\n",
      "Model answer: None\n",
      "Ground truth answer: 15.0\n",
      "Correct: 110 out of 1319\n",
      "========================================\n",
      "task_id 839\n",
      "Model answer: 10.0\n",
      "Ground truth answer: 2.0\n",
      "Correct: 110 out of 1319\n",
      "========================================\n",
      "task_id 840\n",
      "Model answer: 18.0\n",
      "Ground truth answer: 16.0\n",
      "Correct: 110 out of 1319\n",
      "========================================\n",
      "task_id 841\n",
      "Model answer: 4800.0\n",
      "Ground truth answer: 5600.0\n",
      "Correct: 110 out of 1319\n",
      "========================================\n",
      "task_id 842\n",
      "Model answer: 10.0\n",
      "Ground truth answer: 10.0\n",
      "Correct: 111 out of 1319\n",
      "========================================\n",
      "task_id 843\n",
      "Model answer: 1.0\n",
      "Ground truth answer: 19.0\n",
      "Correct: 111 out of 1319\n",
      "========================================\n",
      "task_id 844\n",
      "Model answer: 240.0\n",
      "Ground truth answer: 180.0\n",
      "Correct: 111 out of 1319\n",
      "========================================\n",
      "task_id 845\n",
      "Model answer: 28.0\n",
      "Ground truth answer: 12.0\n",
      "Correct: 111 out of 1319\n",
      "========================================\n",
      "task_id 846\n",
      "Model answer: 23.0\n",
      "Ground truth answer: 11.0\n",
      "Correct: 111 out of 1319\n",
      "========================================\n",
      "task_id 847\n",
      "Model answer: 225.0\n",
      "Ground truth answer: 975.0\n",
      "Correct: 111 out of 1319\n",
      "========================================\n",
      "task_id 848\n",
      "Model answer: 10.0\n",
      "Ground truth answer: 10.0\n",
      "Correct: 112 out of 1319\n",
      "========================================\n",
      "task_id 849\n",
      "Model answer: 75.0\n",
      "Ground truth answer: 75.0\n",
      "Correct: 113 out of 1319\n",
      "========================================\n",
      "task_id 850\n",
      "Model answer: 86.0\n",
      "Ground truth answer: 70.0\n",
      "Correct: 113 out of 1319\n",
      "========================================\n",
      "task_id 851\n",
      "Model answer: 2640.0\n",
      "Ground truth answer: 110.0\n",
      "Correct: 113 out of 1319\n",
      "========================================\n",
      "task_id 852\n",
      "Model answer: None\n",
      "Ground truth answer: 123.0\n",
      "Correct: 113 out of 1319\n",
      "========================================\n",
      "task_id 853\n",
      "Model answer: 900.0\n",
      "Ground truth answer: 15.0\n",
      "Correct: 113 out of 1319\n",
      "========================================\n",
      "task_id 854\n",
      "Model answer: 84.0\n",
      "Ground truth answer: 144.0\n",
      "Correct: 113 out of 1319\n",
      "========================================\n",
      "task_id 855\n",
      "Model answer: None\n",
      "Ground truth answer: 13.0\n",
      "Correct: 113 out of 1319\n",
      "========================================\n",
      "task_id 856\n",
      "Model answer: 54.0\n",
      "Ground truth answer: 7.0\n",
      "Correct: 113 out of 1319\n",
      "========================================\n",
      "task_id 857\n",
      "Model answer: 2400.0\n",
      "Ground truth answer: 14000.0\n",
      "Correct: 113 out of 1319\n",
      "========================================\n",
      "task_id 858\n",
      "Model answer: 180.0\n",
      "Ground truth answer: 3430.0\n",
      "Correct: 113 out of 1319\n",
      "========================================\n",
      "task_id 859\n",
      "Model answer: 3800.0\n",
      "Ground truth answer: 1520.0\n",
      "Correct: 113 out of 1319\n",
      "========================================\n",
      "task_id 860\n",
      "Model answer: 4.0\n",
      "Ground truth answer: 3.0\n",
      "Correct: 113 out of 1319\n",
      "========================================\n",
      "task_id 861\n",
      "Model answer: 12.0\n",
      "Ground truth answer: 30.0\n",
      "Correct: 113 out of 1319\n",
      "========================================\n",
      "task_id 862\n",
      "Model answer: 2000.0\n",
      "Ground truth answer: 40.0\n",
      "Correct: 113 out of 1319\n",
      "========================================\n",
      "task_id 863\n",
      "Model answer: 40.0\n",
      "Ground truth answer: 110.0\n",
      "Correct: 113 out of 1319\n",
      "========================================\n",
      "task_id 864\n",
      "Model answer: 300.0\n",
      "Ground truth answer: 80.0\n",
      "Correct: 113 out of 1319\n",
      "========================================\n",
      "task_id 865\n",
      "Model answer: 18.0\n",
      "Ground truth answer: 23.0\n",
      "Correct: 113 out of 1319\n",
      "========================================\n",
      "task_id 866\n",
      "Model answer: 13.0\n",
      "Ground truth answer: 28.0\n",
      "Correct: 113 out of 1319\n",
      "========================================\n",
      "task_id 867\n",
      "Model answer: None\n",
      "Ground truth answer: 7.0\n",
      "Correct: 113 out of 1319\n",
      "========================================\n",
      "task_id 868\n",
      "Model answer: 15.0\n",
      "Ground truth answer: 15.0\n",
      "Correct: 114 out of 1319\n",
      "========================================\n",
      "task_id 869\n",
      "Model answer: 500.0\n",
      "Ground truth answer: 500.0\n",
      "Correct: 115 out of 1319\n",
      "========================================\n",
      "task_id 870\n",
      "Model answer: 40.0\n",
      "Ground truth answer: 40.0\n",
      "Correct: 116 out of 1319\n",
      "========================================\n",
      "task_id 871\n",
      "Model answer: None\n",
      "Ground truth answer: 48.0\n",
      "Correct: 116 out of 1319\n",
      "========================================\n",
      "task_id 872\n",
      "Model answer: 89.0\n",
      "Ground truth answer: 13.0\n",
      "Correct: 116 out of 1319\n",
      "========================================\n",
      "task_id 873\n",
      "Model answer: 7.68\n",
      "Ground truth answer: 12.0\n",
      "Correct: 116 out of 1319\n",
      "========================================\n",
      "task_id 874\n",
      "Model answer: 132.0\n",
      "Ground truth answer: 132.0\n",
      "Correct: 117 out of 1319\n",
      "========================================\n",
      "task_id 875\n",
      "Model answer: -24.0\n",
      "Ground truth answer: 60.0\n",
      "Correct: 117 out of 1319\n",
      "========================================\n",
      "task_id 876\n",
      "Model answer: 11.0\n",
      "Ground truth answer: 41.0\n",
      "Correct: 117 out of 1319\n",
      "========================================\n",
      "task_id 877\n",
      "Model answer: 9000.0\n",
      "Ground truth answer: 7000.0\n",
      "Correct: 117 out of 1319\n",
      "========================================\n",
      "task_id 878\n",
      "Model answer: 14.0\n",
      "Ground truth answer: 5.0\n",
      "Correct: 117 out of 1319\n",
      "========================================\n",
      "task_id 879\n",
      "Model answer: None\n",
      "Ground truth answer: 575.0\n",
      "Correct: 117 out of 1319\n",
      "========================================\n",
      "task_id 880\n",
      "Model answer: 1.0\n",
      "Ground truth answer: 10.0\n",
      "Correct: 117 out of 1319\n",
      "========================================\n",
      "task_id 881\n",
      "Model answer: 30.0\n",
      "Ground truth answer: 16.0\n",
      "Correct: 117 out of 1319\n",
      "========================================\n",
      "task_id 882\n",
      "Model answer: None\n",
      "Ground truth answer: 5.0\n",
      "Correct: 117 out of 1319\n",
      "========================================\n",
      "task_id 883\n",
      "Model answer: 130.0\n",
      "Ground truth answer: 25.0\n",
      "Correct: 117 out of 1319\n",
      "========================================\n",
      "task_id 884\n",
      "Model answer: 50.0\n",
      "Ground truth answer: 50.0\n",
      "Correct: 118 out of 1319\n",
      "========================================\n",
      "task_id 885\n",
      "Model answer: 500.0\n",
      "Ground truth answer: 500.0\n",
      "Correct: 119 out of 1319\n",
      "========================================\n",
      "task_id 886\n",
      "Model answer: 40.0\n",
      "Ground truth answer: 20.0\n",
      "Correct: 119 out of 1319\n",
      "========================================\n",
      "task_id 887\n",
      "Model answer: 34.0\n",
      "Ground truth answer: 34.0\n",
      "Correct: 120 out of 1319\n",
      "========================================\n",
      "task_id 888\n",
      "Model answer: 10.0\n",
      "Ground truth answer: 10.0\n",
      "Correct: 121 out of 1319\n",
      "========================================\n",
      "task_id 889\n",
      "Model answer: 6.0\n",
      "Ground truth answer: 15.0\n",
      "Correct: 121 out of 1319\n",
      "========================================\n",
      "task_id 890\n",
      "Model answer: None\n",
      "Ground truth answer: 25.0\n",
      "Correct: 121 out of 1319\n",
      "========================================\n",
      "task_id 891\n",
      "Model answer: 605.0\n",
      "Ground truth answer: 55.0\n",
      "Correct: 121 out of 1319\n",
      "========================================\n",
      "task_id 892\n",
      "Model answer: 2.5\n",
      "Ground truth answer: 1.0\n",
      "Correct: 121 out of 1319\n",
      "========================================\n",
      "task_id 893\n",
      "Model answer: 410.0\n",
      "Ground truth answer: 480.0\n",
      "Correct: 121 out of 1319\n",
      "========================================\n",
      "task_id 894\n",
      "Model answer: 74.0\n",
      "Ground truth answer: 26.0\n",
      "Correct: 121 out of 1319\n",
      "========================================\n",
      "task_id 895\n",
      "Model answer: None\n",
      "Ground truth answer: 74.0\n",
      "Correct: 121 out of 1319\n",
      "========================================\n",
      "task_id 896\n",
      "Model answer: 250.0\n",
      "Ground truth answer: 250.0\n",
      "Correct: 122 out of 1319\n",
      "========================================\n",
      "task_id 897\n",
      "Model answer: 4.0\n",
      "Ground truth answer: 1.0\n",
      "Correct: 122 out of 1319\n",
      "========================================\n",
      "task_id 898\n",
      "Model answer: None\n",
      "Ground truth answer: 110.0\n",
      "Correct: 122 out of 1319\n",
      "========================================\n",
      "task_id 899\n",
      "Model answer: 16.0\n",
      "Ground truth answer: 16.0\n",
      "Correct: 123 out of 1319\n",
      "========================================\n",
      "task_id 900\n",
      "Model answer: None\n",
      "Ground truth answer: 15.0\n",
      "Correct: 123 out of 1319\n",
      "========================================\n",
      "task_id 901\n",
      "Model answer: 2.0\n",
      "Ground truth answer: 1.0\n",
      "Correct: 123 out of 1319\n",
      "========================================\n",
      "task_id 902\n",
      "Model answer: 3.0\n",
      "Ground truth answer: 8.0\n",
      "Correct: 123 out of 1319\n",
      "========================================\n",
      "task_id 903\n",
      "Model answer: None\n",
      "Ground truth answer: 16.0\n",
      "Correct: 123 out of 1319\n",
      "========================================\n",
      "task_id 904\n",
      "Model answer: 216.0\n",
      "Ground truth answer: 8.0\n",
      "Correct: 123 out of 1319\n",
      "========================================\n",
      "task_id 905\n",
      "Model answer: 7.0\n",
      "Ground truth answer: 5.0\n",
      "Correct: 123 out of 1319\n",
      "========================================\n",
      "task_id 906\n",
      "Model answer: 81.0\n",
      "Ground truth answer: 10.0\n",
      "Correct: 123 out of 1319\n",
      "========================================\n",
      "task_id 907\n",
      "Model answer: 16.0\n",
      "Ground truth answer: 16.0\n",
      "Correct: 124 out of 1319\n",
      "========================================\n",
      "task_id 908\n",
      "Model answer: 14.0\n",
      "Ground truth answer: 14.0\n",
      "Correct: 125 out of 1319\n",
      "========================================\n",
      "task_id 909\n",
      "Model answer: 56.0\n",
      "Ground truth answer: 38.0\n",
      "Correct: 125 out of 1319\n",
      "========================================\n",
      "task_id 910\n",
      "Model answer: 600.0\n",
      "Ground truth answer: 700.0\n",
      "Correct: 125 out of 1319\n",
      "========================================\n",
      "task_id 911\n",
      "Model answer: 64.0\n",
      "Ground truth answer: 64.0\n",
      "Correct: 126 out of 1319\n",
      "========================================\n",
      "task_id 912\n",
      "Model answer: 4.0\n",
      "Ground truth answer: 6.0\n",
      "Correct: 126 out of 1319\n",
      "========================================\n",
      "task_id 913\n",
      "Model answer: 38.0\n",
      "Ground truth answer: 6.0\n",
      "Correct: 126 out of 1319\n",
      "========================================\n",
      "task_id 914\n",
      "Model answer: 30.0\n",
      "Ground truth answer: 3.0\n",
      "Correct: 126 out of 1319\n",
      "========================================\n",
      "task_id 915\n",
      "Model answer: 23.0\n",
      "Ground truth answer: 23.0\n",
      "Correct: 127 out of 1319\n",
      "========================================\n",
      "task_id 916\n",
      "Model answer: None\n",
      "Ground truth answer: 14.0\n",
      "Correct: 127 out of 1319\n",
      "========================================\n",
      "task_id 917\n",
      "Model answer: 12.0\n",
      "Ground truth answer: 12.0\n",
      "Correct: 128 out of 1319\n",
      "========================================\n",
      "task_id 918\n",
      "Model answer: 56.0\n",
      "Ground truth answer: 56.0\n",
      "Correct: 129 out of 1319\n",
      "========================================\n",
      "task_id 919\n",
      "Model answer: 150.0\n",
      "Ground truth answer: 90.0\n",
      "Correct: 129 out of 1319\n",
      "========================================\n",
      "task_id 920\n",
      "Model answer: None\n",
      "Ground truth answer: 47.0\n",
      "Correct: 129 out of 1319\n",
      "========================================\n",
      "task_id 921\n",
      "Model answer: 4.0\n",
      "Ground truth answer: 4.0\n",
      "Correct: 130 out of 1319\n",
      "========================================\n",
      "task_id 922\n",
      "Model answer: 60.0\n",
      "Ground truth answer: 60.0\n",
      "Correct: 131 out of 1319\n",
      "========================================\n",
      "task_id 923\n",
      "Model answer: None\n",
      "Ground truth answer: 2.0\n",
      "Correct: 131 out of 1319\n",
      "========================================\n",
      "task_id 924\n",
      "Model answer: None\n",
      "Ground truth answer: 12.0\n",
      "Correct: 131 out of 1319\n",
      "========================================\n",
      "task_id 925\n",
      "Model answer: 0.0\n",
      "Ground truth answer: 2000.0\n",
      "Correct: 131 out of 1319\n",
      "========================================\n",
      "task_id 926\n",
      "Model answer: None\n",
      "Ground truth answer: 1.0\n",
      "Correct: 131 out of 1319\n",
      "========================================\n",
      "task_id 927\n",
      "Model answer: 350.0\n",
      "Ground truth answer: 85000.0\n",
      "Correct: 131 out of 1319\n",
      "========================================\n",
      "task_id 928\n",
      "Model answer: 73.0\n",
      "Ground truth answer: 60.0\n",
      "Correct: 131 out of 1319\n",
      "========================================\n",
      "task_id 929\n",
      "Model answer: 60.0\n",
      "Ground truth answer: 60.0\n",
      "Correct: 132 out of 1319\n",
      "========================================\n",
      "task_id 930\n",
      "Model answer: 14.0\n",
      "Ground truth answer: 14.0\n",
      "Correct: 133 out of 1319\n",
      "========================================\n",
      "task_id 931\n",
      "Model answer: 100.0\n",
      "Ground truth answer: 50.0\n",
      "Correct: 133 out of 1319\n",
      "========================================\n",
      "task_id 932\n",
      "Model answer: 6.0\n",
      "Ground truth answer: 24.0\n",
      "Correct: 133 out of 1319\n",
      "========================================\n",
      "task_id 933\n",
      "Model answer: 32.5\n",
      "Ground truth answer: 15.0\n",
      "Correct: 133 out of 1319\n",
      "========================================\n",
      "task_id 934\n",
      "Model answer: 820.0\n",
      "Ground truth answer: 410.0\n",
      "Correct: 133 out of 1319\n",
      "========================================\n",
      "task_id 935\n",
      "Model answer: 0.0\n",
      "Ground truth answer: 64800.0\n",
      "Correct: 133 out of 1319\n",
      "========================================\n",
      "task_id 936\n",
      "Model answer: None\n",
      "Ground truth answer: 250.0\n",
      "Correct: 133 out of 1319\n",
      "========================================\n",
      "task_id 937\n",
      "Model answer: 229.0\n",
      "Ground truth answer: 159.0\n",
      "Correct: 133 out of 1319\n",
      "========================================\n",
      "task_id 938\n",
      "Model answer: 25.0\n",
      "Ground truth answer: 4.0\n",
      "Correct: 133 out of 1319\n",
      "========================================\n",
      "task_id 939\n",
      "Model answer: None\n",
      "Ground truth answer: 650.0\n",
      "Correct: 133 out of 1319\n",
      "========================================\n",
      "task_id 940\n",
      "Model answer: 168.0\n",
      "Ground truth answer: 280.0\n",
      "Correct: 133 out of 1319\n",
      "========================================\n",
      "task_id 941\n",
      "Model answer: None\n",
      "Ground truth answer: 842.0\n",
      "Correct: 133 out of 1319\n",
      "========================================\n",
      "task_id 942\n",
      "Model answer: 91.0\n",
      "Ground truth answer: 205.0\n",
      "Correct: 133 out of 1319\n",
      "========================================\n",
      "task_id 943\n",
      "Model answer: None\n",
      "Ground truth answer: 50.0\n",
      "Correct: 133 out of 1319\n",
      "========================================\n",
      "task_id 944\n",
      "Model answer: 34.0\n",
      "Ground truth answer: 34.0\n",
      "Correct: 134 out of 1319\n",
      "========================================\n",
      "task_id 945\n",
      "Model answer: None\n",
      "Ground truth answer: 17.0\n",
      "Correct: 134 out of 1319\n",
      "========================================\n",
      "task_id 946\n",
      "Model answer: 21.0\n",
      "Ground truth answer: 450.0\n",
      "Correct: 134 out of 1319\n",
      "========================================\n",
      "task_id 947\n",
      "Model answer: 5.0\n",
      "Ground truth answer: 13.0\n",
      "Correct: 134 out of 1319\n",
      "========================================\n",
      "task_id 948\n",
      "Model answer: None\n",
      "Ground truth answer: 15.0\n",
      "Correct: 134 out of 1319\n",
      "========================================\n",
      "task_id 949\n",
      "Model answer: 8.0\n",
      "Ground truth answer: 42.0\n",
      "Correct: 134 out of 1319\n",
      "========================================\n",
      "task_id 950\n",
      "Model answer: 0.0\n",
      "Ground truth answer: 5.0\n",
      "Correct: 134 out of 1319\n",
      "========================================\n",
      "task_id 951\n",
      "Model answer: 200.0\n",
      "Ground truth answer: 300.0\n",
      "Correct: 134 out of 1319\n",
      "========================================\n",
      "task_id 952\n",
      "Model answer: 450.0\n",
      "Ground truth answer: 360.0\n",
      "Correct: 134 out of 1319\n",
      "========================================\n",
      "task_id 953\n",
      "Model answer: None\n",
      "Ground truth answer: 452.0\n",
      "Correct: 134 out of 1319\n",
      "========================================\n",
      "task_id 954\n",
      "Model answer: None\n",
      "Ground truth answer: 34.0\n",
      "Correct: 134 out of 1319\n",
      "========================================\n",
      "task_id 955\n",
      "Model answer: None\n",
      "Ground truth answer: 100.0\n",
      "Correct: 134 out of 1319\n",
      "========================================\n",
      "task_id 956\n",
      "Model answer: 8.0\n",
      "Ground truth answer: 1.0\n",
      "Correct: 134 out of 1319\n",
      "========================================\n",
      "task_id 957\n",
      "Model answer: 45.0\n",
      "Ground truth answer: 45.0\n",
      "Correct: 135 out of 1319\n",
      "========================================\n",
      "task_id 958\n",
      "Model answer: 28.0\n",
      "Ground truth answer: 40.0\n",
      "Correct: 135 out of 1319\n",
      "========================================\n",
      "task_id 959\n",
      "Model answer: None\n",
      "Ground truth answer: 7.0\n",
      "Correct: 135 out of 1319\n",
      "========================================\n",
      "task_id 960\n",
      "Model answer: None\n",
      "Ground truth answer: 11.0\n",
      "Correct: 135 out of 1319\n",
      "========================================\n",
      "task_id 961\n",
      "Model answer: 85.0\n",
      "Ground truth answer: 225.0\n",
      "Correct: 135 out of 1319\n",
      "========================================\n",
      "task_id 962\n",
      "Model answer: 200.0\n",
      "Ground truth answer: 1000.0\n",
      "Correct: 135 out of 1319\n",
      "========================================\n",
      "task_id 963\n",
      "Model answer: 36.0\n",
      "Ground truth answer: 147.0\n",
      "Correct: 135 out of 1319\n",
      "========================================\n",
      "task_id 964\n",
      "Model answer: 1.0\n",
      "Ground truth answer: 200.0\n",
      "Correct: 135 out of 1319\n",
      "========================================\n",
      "task_id 965\n",
      "Model answer: 510.0\n",
      "Ground truth answer: 374.0\n",
      "Correct: 135 out of 1319\n",
      "========================================\n",
      "task_id 966\n",
      "Model answer: 7.0\n",
      "Ground truth answer: 48.0\n",
      "Correct: 135 out of 1319\n",
      "========================================\n",
      "task_id 967\n",
      "Model answer: 28.0\n",
      "Ground truth answer: 30.0\n",
      "Correct: 135 out of 1319\n",
      "========================================\n",
      "task_id 968\n",
      "Model answer: None\n",
      "Ground truth answer: 227.0\n",
      "Correct: 135 out of 1319\n",
      "========================================\n",
      "task_id 969\n",
      "Model answer: 750.0\n",
      "Ground truth answer: 1800.0\n",
      "Correct: 135 out of 1319\n",
      "========================================\n",
      "task_id 970\n",
      "Model answer: 20.0\n",
      "Ground truth answer: 33.0\n",
      "Correct: 135 out of 1319\n",
      "========================================\n",
      "task_id 971\n",
      "Model answer: 300.0\n",
      "Ground truth answer: 100.0\n",
      "Correct: 135 out of 1319\n",
      "========================================\n",
      "task_id 972\n",
      "Model answer: 18.0\n",
      "Ground truth answer: 120.0\n",
      "Correct: 135 out of 1319\n",
      "========================================\n",
      "task_id 973\n",
      "Model answer: None\n",
      "Ground truth answer: 79.0\n",
      "Correct: 135 out of 1319\n",
      "========================================\n",
      "task_id 974\n",
      "Model answer: 26.0\n",
      "Ground truth answer: 5.0\n",
      "Correct: 135 out of 1319\n",
      "========================================\n",
      "task_id 975\n",
      "Model answer: 20.0\n",
      "Ground truth answer: 20.0\n",
      "Correct: 136 out of 1319\n",
      "========================================\n",
      "task_id 976\n",
      "Model answer: None\n",
      "Ground truth answer: 540.0\n",
      "Correct: 136 out of 1319\n",
      "========================================\n",
      "task_id 977\n",
      "Model answer: 4.0\n",
      "Ground truth answer: 4.0\n",
      "Correct: 137 out of 1319\n",
      "========================================\n",
      "task_id 978\n",
      "Model answer: 40.0\n",
      "Ground truth answer: 160.0\n",
      "Correct: 137 out of 1319\n",
      "========================================\n",
      "task_id 979\n",
      "Model answer: None\n",
      "Ground truth answer: 50.0\n",
      "Correct: 137 out of 1319\n",
      "========================================\n",
      "task_id 980\n",
      "Model answer: 52.0\n",
      "Ground truth answer: 90.0\n",
      "Correct: 137 out of 1319\n",
      "========================================\n",
      "task_id 981\n",
      "Model answer: 9.0\n",
      "Ground truth answer: 7.0\n",
      "Correct: 137 out of 1319\n",
      "========================================\n",
      "task_id 982\n",
      "Model answer: 7.5\n",
      "Ground truth answer: 12.0\n",
      "Correct: 137 out of 1319\n",
      "========================================\n",
      "task_id 983\n",
      "Model answer: 25.0\n",
      "Ground truth answer: 15.0\n",
      "Correct: 137 out of 1319\n",
      "========================================\n",
      "task_id 984\n",
      "Model answer: None\n",
      "Ground truth answer: 342.0\n",
      "Correct: 137 out of 1319\n",
      "========================================\n",
      "task_id 985\n",
      "Model answer: 63.0\n",
      "Ground truth answer: 63.0\n",
      "Correct: 138 out of 1319\n",
      "========================================\n",
      "task_id 986\n",
      "Model answer: None\n",
      "Ground truth answer: 70.0\n",
      "Correct: 138 out of 1319\n",
      "========================================\n",
      "task_id 987\n",
      "Model answer: None\n",
      "Ground truth answer: 3.0\n",
      "Correct: 138 out of 1319\n",
      "========================================\n",
      "task_id 988\n",
      "Model answer: 5.0\n",
      "Ground truth answer: 6.0\n",
      "Correct: 138 out of 1319\n",
      "========================================\n",
      "task_id 989\n",
      "Model answer: 90.0\n",
      "Ground truth answer: 45.0\n",
      "Correct: 138 out of 1319\n",
      "========================================\n",
      "task_id 990\n",
      "Model answer: None\n",
      "Ground truth answer: 14.0\n",
      "Correct: 138 out of 1319\n",
      "========================================\n",
      "task_id 991\n",
      "Model answer: 90.0\n",
      "Ground truth answer: 15.0\n",
      "Correct: 138 out of 1319\n",
      "========================================\n",
      "task_id 992\n",
      "Model answer: None\n",
      "Ground truth answer: 52.0\n",
      "Correct: 138 out of 1319\n",
      "========================================\n",
      "task_id 993\n",
      "Model answer: 7.0\n",
      "Ground truth answer: 11.0\n",
      "Correct: 138 out of 1319\n",
      "========================================\n",
      "task_id 994\n",
      "Model answer: 60.0\n",
      "Ground truth answer: 2.0\n",
      "Correct: 138 out of 1319\n",
      "========================================\n",
      "task_id 995\n",
      "Model answer: 6.0\n",
      "Ground truth answer: 12.0\n",
      "Correct: 138 out of 1319\n",
      "========================================\n",
      "task_id 996\n",
      "Model answer: 3.0\n",
      "Ground truth answer: 3.0\n",
      "Correct: 139 out of 1319\n",
      "========================================\n",
      "task_id 997\n",
      "Model answer: 4500.0\n",
      "Ground truth answer: 600.0\n",
      "Correct: 139 out of 1319\n",
      "========================================\n",
      "task_id 998\n",
      "Model answer: 150.0\n",
      "Ground truth answer: 50.0\n",
      "Correct: 139 out of 1319\n",
      "========================================\n",
      "task_id 999\n",
      "Model answer: None\n",
      "Ground truth answer: 25.0\n",
      "Correct: 139 out of 1319\n",
      "========================================\n",
      "task_id 1000\n",
      "Model answer: 120.0\n",
      "Ground truth answer: 1.0\n",
      "Correct: 139 out of 1319\n",
      "========================================\n",
      "task_id 1001\n",
      "Model answer: 0.0\n",
      "Ground truth answer: 2.0\n",
      "Correct: 139 out of 1319\n",
      "========================================\n",
      "task_id 1002\n",
      "Model answer: 16.0\n",
      "Ground truth answer: 8.0\n",
      "Correct: 139 out of 1319\n",
      "========================================\n",
      "task_id 1003\n",
      "Model answer: 7.5\n",
      "Ground truth answer: 480.0\n",
      "Correct: 139 out of 1319\n",
      "========================================\n",
      "task_id 1004\n",
      "Model answer: 16.0\n",
      "Ground truth answer: 8.0\n",
      "Correct: 139 out of 1319\n",
      "========================================\n",
      "task_id 1005\n",
      "Model answer: None\n",
      "Ground truth answer: 1490.0\n",
      "Correct: 139 out of 1319\n",
      "========================================\n",
      "task_id 1006\n",
      "Model answer: 5900.0\n",
      "Ground truth answer: 826.0\n",
      "Correct: 139 out of 1319\n",
      "========================================\n",
      "task_id 1007\n",
      "Model answer: 11.0\n",
      "Ground truth answer: 34.0\n",
      "Correct: 139 out of 1319\n",
      "========================================\n",
      "task_id 1008\n",
      "Model answer: 230.0\n",
      "Ground truth answer: 230.0\n",
      "Correct: 140 out of 1319\n",
      "========================================\n",
      "task_id 1009\n",
      "Model answer: None\n",
      "Ground truth answer: 875.0\n",
      "Correct: 140 out of 1319\n",
      "========================================\n",
      "task_id 1010\n",
      "Model answer: 4.0\n",
      "Ground truth answer: 5.0\n",
      "Correct: 140 out of 1319\n",
      "========================================\n",
      "task_id 1011\n",
      "Model answer: None\n",
      "Ground truth answer: 6000.0\n",
      "Correct: 140 out of 1319\n",
      "========================================\n",
      "task_id 1012\n",
      "Model answer: None\n",
      "Ground truth answer: 94.0\n",
      "Correct: 140 out of 1319\n",
      "========================================\n",
      "task_id 1013\n",
      "Model answer: 20.0\n",
      "Ground truth answer: 2.0\n",
      "Correct: 140 out of 1319\n",
      "========================================\n",
      "task_id 1014\n",
      "Model answer: None\n",
      "Ground truth answer: 3.0\n",
      "Correct: 140 out of 1319\n",
      "========================================\n",
      "task_id 1015\n",
      "Model answer: 90.0\n",
      "Ground truth answer: 78.0\n",
      "Correct: 140 out of 1319\n",
      "========================================\n",
      "task_id 1016\n",
      "Model answer: None\n",
      "Ground truth answer: 138.0\n",
      "Correct: 140 out of 1319\n",
      "========================================\n",
      "task_id 1017\n",
      "Model answer: 67.0\n",
      "Ground truth answer: 45.0\n",
      "Correct: 140 out of 1319\n",
      "========================================\n",
      "task_id 1018\n",
      "Model answer: 54.0\n",
      "Ground truth answer: 60.0\n",
      "Correct: 140 out of 1319\n",
      "========================================\n",
      "task_id 1019\n",
      "Model answer: None\n",
      "Ground truth answer: 98.0\n",
      "Correct: 140 out of 1319\n",
      "========================================\n",
      "task_id 1020\n",
      "Model answer: 21.0\n",
      "Ground truth answer: 22.0\n",
      "Correct: 140 out of 1319\n",
      "========================================\n",
      "task_id 1021\n",
      "Model answer: 5.5\n",
      "Ground truth answer: 36.0\n",
      "Correct: 140 out of 1319\n",
      "========================================\n",
      "task_id 1022\n",
      "Model answer: 5.0\n",
      "Ground truth answer: 12.0\n",
      "Correct: 140 out of 1319\n",
      "========================================\n",
      "task_id 1023\n",
      "Model answer: 11.0\n",
      "Ground truth answer: 77.0\n",
      "Correct: 140 out of 1319\n",
      "========================================\n",
      "task_id 1024\n",
      "Model answer: 340.0\n",
      "Ground truth answer: 300.0\n",
      "Correct: 140 out of 1319\n",
      "========================================\n",
      "task_id 1025\n",
      "Model answer: 60.0\n",
      "Ground truth answer: 30.0\n",
      "Correct: 140 out of 1319\n",
      "========================================\n",
      "task_id 1026\n",
      "Model answer: 400.0\n",
      "Ground truth answer: 43200.0\n",
      "Correct: 140 out of 1319\n",
      "========================================\n",
      "task_id 1027\n",
      "Model answer: 6.0\n",
      "Ground truth answer: 12.0\n",
      "Correct: 140 out of 1319\n",
      "========================================\n",
      "task_id 1028\n",
      "Model answer: 300.0\n",
      "Ground truth answer: 200.0\n",
      "Correct: 140 out of 1319\n",
      "========================================\n",
      "task_id 1029\n",
      "Model answer: None\n",
      "Ground truth answer: 34.0\n",
      "Correct: 140 out of 1319\n",
      "========================================\n",
      "task_id 1030\n",
      "Model answer: 110.0\n",
      "Ground truth answer: 24.0\n",
      "Correct: 140 out of 1319\n",
      "========================================\n",
      "task_id 1031\n",
      "Model answer: None\n",
      "Ground truth answer: 5.0\n",
      "Correct: 140 out of 1319\n",
      "========================================\n",
      "task_id 1032\n",
      "Model answer: 450.0\n",
      "Ground truth answer: 450.0\n",
      "Correct: 141 out of 1319\n",
      "========================================\n",
      "task_id 1033\n",
      "Model answer: 98.0\n",
      "Ground truth answer: 2.0\n",
      "Correct: 141 out of 1319\n",
      "========================================\n",
      "task_id 1034\n",
      "Model answer: 66.0\n",
      "Ground truth answer: 66.0\n",
      "Correct: 142 out of 1319\n",
      "========================================\n",
      "task_id 1035\n",
      "Model answer: None\n",
      "Ground truth answer: 35.0\n",
      "Correct: 142 out of 1319\n",
      "========================================\n",
      "task_id 1036\n",
      "Model answer: 10.0\n",
      "Ground truth answer: 10.0\n",
      "Correct: 143 out of 1319\n",
      "========================================\n",
      "task_id 1037\n",
      "Model answer: 10.0\n",
      "Ground truth answer: 10.0\n",
      "Correct: 144 out of 1319\n",
      "========================================\n",
      "task_id 1038\n",
      "Model answer: 100000.0\n",
      "Ground truth answer: 4.0\n",
      "Correct: 144 out of 1319\n",
      "========================================\n",
      "task_id 1039\n",
      "Model answer: 192.0\n",
      "Ground truth answer: 160.0\n",
      "Correct: 144 out of 1319\n",
      "========================================\n",
      "task_id 1040\n",
      "Model answer: None\n",
      "Ground truth answer: 736.0\n",
      "Correct: 144 out of 1319\n",
      "========================================\n",
      "task_id 1041\n",
      "Model answer: 101.0\n",
      "Ground truth answer: 101.0\n",
      "Correct: 145 out of 1319\n",
      "========================================\n",
      "task_id 1042\n",
      "Model answer: None\n",
      "Ground truth answer: 3.0\n",
      "Correct: 145 out of 1319\n",
      "========================================\n",
      "task_id 1043\n",
      "Model answer: 130000.0\n",
      "Ground truth answer: 130000.0\n",
      "Correct: 146 out of 1319\n",
      "========================================\n",
      "task_id 1044\n",
      "Model answer: 45.0\n",
      "Ground truth answer: 1.0\n",
      "Correct: 146 out of 1319\n",
      "========================================\n",
      "task_id 1045\n",
      "Model answer: 1760.0\n",
      "Ground truth answer: 420.0\n",
      "Correct: 146 out of 1319\n",
      "========================================\n",
      "task_id 1046\n",
      "Model answer: 37.5\n",
      "Ground truth answer: 189.0\n",
      "Correct: 146 out of 1319\n",
      "========================================\n",
      "task_id 1047\n",
      "Model answer: 25.0\n",
      "Ground truth answer: 10.0\n",
      "Correct: 146 out of 1319\n",
      "========================================\n",
      "task_id 1048\n",
      "Model answer: 16800.0\n",
      "Ground truth answer: 7400.0\n",
      "Correct: 146 out of 1319\n",
      "========================================\n",
      "task_id 1049\n",
      "Model answer: 10.0\n",
      "Ground truth answer: 20.0\n",
      "Correct: 146 out of 1319\n",
      "========================================\n",
      "task_id 1050\n",
      "Model answer: 1630.0\n",
      "Ground truth answer: 655.0\n",
      "Correct: 146 out of 1319\n",
      "========================================\n",
      "task_id 1051\n",
      "Model answer: 128.0\n",
      "Ground truth answer: 15.0\n",
      "Correct: 146 out of 1319\n",
      "========================================\n",
      "task_id 1052\n",
      "Model answer: 50.0\n",
      "Ground truth answer: 110.0\n",
      "Correct: 146 out of 1319\n",
      "========================================\n",
      "task_id 1053\n",
      "Model answer: 45.0\n",
      "Ground truth answer: 55.0\n",
      "Correct: 146 out of 1319\n",
      "========================================\n",
      "task_id 1054\n",
      "Model answer: 2400.0\n",
      "Ground truth answer: 2400.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1055\n",
      "Model answer: 192.0\n",
      "Ground truth answer: 2304.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1056\n",
      "Model answer: 432.0\n",
      "Ground truth answer: 156.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1057\n",
      "Model answer: 8.0\n",
      "Ground truth answer: 24.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1058\n",
      "Model answer: 200.0\n",
      "Ground truth answer: 250.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1059\n",
      "Model answer: 6.0\n",
      "Ground truth answer: 2.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1060\n",
      "Model answer: 21.0\n",
      "Ground truth answer: 31.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1061\n",
      "Model answer: 80.0\n",
      "Ground truth answer: 58.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1062\n",
      "Model answer: None\n",
      "Ground truth answer: 482.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1063\n",
      "Model answer: 64.0\n",
      "Ground truth answer: 320.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1064\n",
      "Model answer: 36.0\n",
      "Ground truth answer: 247.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1065\n",
      "Model answer: 90.0\n",
      "Ground truth answer: 95.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1066\n",
      "Model answer: 32.0\n",
      "Ground truth answer: 14.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1067\n",
      "Model answer: None\n",
      "Ground truth answer: 245.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1068\n",
      "Model answer: 7.0\n",
      "Ground truth answer: 24.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1069\n",
      "Model answer: None\n",
      "Ground truth answer: 300.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1070\n",
      "Model answer: None\n",
      "Ground truth answer: 18.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1071\n",
      "Model answer: 246.0\n",
      "Ground truth answer: 251.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1072\n",
      "Model answer: 25.0\n",
      "Ground truth answer: 85.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1073\n",
      "Model answer: None\n",
      "Ground truth answer: 21.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1074\n",
      "Model answer: 1000.0\n",
      "Ground truth answer: 750.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1075\n",
      "Model answer: 15.0\n",
      "Ground truth answer: 16.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1076\n",
      "Model answer: None\n",
      "Ground truth answer: 162.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1077\n",
      "Model answer: None\n",
      "Ground truth answer: 145.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1078\n",
      "Model answer: 12.0\n",
      "Ground truth answer: 8.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1079\n",
      "Model answer: 300.0\n",
      "Ground truth answer: 10.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1080\n",
      "Model answer: 1200.0\n",
      "Ground truth answer: 72000.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1081\n",
      "Model answer: 1350.0\n",
      "Ground truth answer: 195.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1082\n",
      "Model answer: 4.0\n",
      "Ground truth answer: 2.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1083\n",
      "Model answer: 2.2\n",
      "Ground truth answer: 2.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1084\n",
      "Model answer: 60.0\n",
      "Ground truth answer: 20.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1085\n",
      "Model answer: None\n",
      "Ground truth answer: 26.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1086\n",
      "Model answer: None\n",
      "Ground truth answer: 131250.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1087\n",
      "Model answer: 48.0\n",
      "Ground truth answer: 12.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1088\n",
      "Model answer: None\n",
      "Ground truth answer: 30.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1089\n",
      "Model answer: 8.0\n",
      "Ground truth answer: 32.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1090\n",
      "Model answer: 10.0\n",
      "Ground truth answer: 72.0\n",
      "Correct: 147 out of 1319\n",
      "========================================\n",
      "task_id 1091\n",
      "Model answer: 1000.0\n",
      "Ground truth answer: 1000.0\n",
      "Correct: 148 out of 1319\n",
      "========================================\n",
      "task_id 1092\n",
      "Model answer: None\n",
      "Ground truth answer: 1080.0\n",
      "Correct: 148 out of 1319\n",
      "========================================\n",
      "task_id 1093\n",
      "Model answer: None\n",
      "Ground truth answer: 144.0\n",
      "Correct: 148 out of 1319\n",
      "========================================\n",
      "task_id 1094\n",
      "Model answer: 3.0\n",
      "Ground truth answer: 25.0\n",
      "Correct: 148 out of 1319\n",
      "========================================\n",
      "task_id 1095\n",
      "Model answer: None\n",
      "Ground truth answer: 270.0\n",
      "Correct: 148 out of 1319\n",
      "========================================\n",
      "task_id 1096\n",
      "Model answer: 29.0\n",
      "Ground truth answer: 240.0\n",
      "Correct: 148 out of 1319\n",
      "========================================\n",
      "task_id 1097\n",
      "Model answer: 480.0\n",
      "Ground truth answer: 480.0\n",
      "Correct: 149 out of 1319\n",
      "========================================\n",
      "task_id 1098\n",
      "Model answer: 10.0\n",
      "Ground truth answer: 30.0\n",
      "Correct: 149 out of 1319\n",
      "========================================\n",
      "task_id 1099\n",
      "Model answer: 20.0\n",
      "Ground truth answer: 2.0\n",
      "Correct: 149 out of 1319\n",
      "========================================\n",
      "task_id 1100\n",
      "Model answer: 60.0\n",
      "Ground truth answer: 5.0\n",
      "Correct: 149 out of 1319\n",
      "========================================\n",
      "task_id 1101\n",
      "Model answer: 24.0\n",
      "Ground truth answer: 16.0\n",
      "Correct: 149 out of 1319\n",
      "========================================\n",
      "task_id 1102\n",
      "Model answer: None\n",
      "Ground truth answer: 113.0\n",
      "Correct: 149 out of 1319\n",
      "========================================\n",
      "task_id 1103\n",
      "Model answer: None\n",
      "Ground truth answer: 90.0\n",
      "Correct: 149 out of 1319\n",
      "========================================\n",
      "task_id 1104\n",
      "Model answer: 24.0\n",
      "Ground truth answer: 24.0\n",
      "Correct: 150 out of 1319\n",
      "========================================\n",
      "task_id 1105\n",
      "Model answer: 0.0\n",
      "Ground truth answer: 40.0\n",
      "Correct: 150 out of 1319\n",
      "========================================\n",
      "task_id 1106\n",
      "Model answer: 5.0\n",
      "Ground truth answer: 5.0\n",
      "Correct: 151 out of 1319\n",
      "========================================\n",
      "task_id 1107\n",
      "Model answer: 4.0\n",
      "Ground truth answer: 360.0\n",
      "Correct: 151 out of 1319\n",
      "========================================\n",
      "task_id 1108\n",
      "Model answer: 28.0\n",
      "Ground truth answer: 38.0\n",
      "Correct: 151 out of 1319\n",
      "========================================\n",
      "task_id 1109\n",
      "Model answer: 3.0\n",
      "Ground truth answer: 3.0\n",
      "Correct: 152 out of 1319\n",
      "========================================\n",
      "task_id 1110\n",
      "Model answer: 250.0\n",
      "Ground truth answer: 60.0\n",
      "Correct: 152 out of 1319\n",
      "========================================\n",
      "task_id 1111\n",
      "Model answer: 427.0\n",
      "Ground truth answer: 157.0\n",
      "Correct: 152 out of 1319\n",
      "========================================\n",
      "task_id 1112\n",
      "Model answer: 1.5\n",
      "Ground truth answer: 5.0\n",
      "Correct: 152 out of 1319\n",
      "========================================\n",
      "task_id 1113\n",
      "Model answer: 5.0\n",
      "Ground truth answer: -3.0\n",
      "Correct: 152 out of 1319\n",
      "========================================\n",
      "task_id 1114\n",
      "Model answer: -14.0\n",
      "Ground truth answer: 8.0\n",
      "Correct: 152 out of 1319\n",
      "========================================\n",
      "task_id 1115\n",
      "Model answer: 2.0\n",
      "Ground truth answer: 5.0\n",
      "Correct: 152 out of 1319\n",
      "========================================\n",
      "task_id 1116\n",
      "Model answer: 60.0\n",
      "Ground truth answer: 60.0\n",
      "Correct: 153 out of 1319\n",
      "========================================\n",
      "task_id 1117\n",
      "Model answer: 9.0\n",
      "Ground truth answer: 9.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1118\n",
      "Model answer: None\n",
      "Ground truth answer: 5.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1119\n",
      "Model answer: 6.0\n",
      "Ground truth answer: 18.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1120\n",
      "Model answer: 140.0\n",
      "Ground truth answer: 560.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1121\n",
      "Model answer: 70.0\n",
      "Ground truth answer: 35.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1122\n",
      "Model answer: 80.0\n",
      "Ground truth answer: 18.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1123\n",
      "Model answer: 45.0\n",
      "Ground truth answer: 105.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1124\n",
      "Model answer: 25.0\n",
      "Ground truth answer: 64.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1125\n",
      "Model answer: 3.0\n",
      "Ground truth answer: 90.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1126\n",
      "Model answer: None\n",
      "Ground truth answer: 50.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1127\n",
      "Model answer: 600.0\n",
      "Ground truth answer: 750.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1128\n",
      "Model answer: 14.0\n",
      "Ground truth answer: 9.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1129\n",
      "Model answer: 14.0\n",
      "Ground truth answer: 8.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1130\n",
      "Model answer: None\n",
      "Ground truth answer: 25.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1131\n",
      "Model answer: None\n",
      "Ground truth answer: 96.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1132\n",
      "Model answer: 15500.0\n",
      "Ground truth answer: 45000.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1133\n",
      "Model answer: None\n",
      "Ground truth answer: 50.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1134\n",
      "Model answer: 4.0\n",
      "Ground truth answer: 7.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1135\n",
      "Model answer: 21.0\n",
      "Ground truth answer: 32.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1136\n",
      "Model answer: 54.0\n",
      "Ground truth answer: 26.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1137\n",
      "Model answer: None\n",
      "Ground truth answer: 68.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1138\n",
      "Model answer: 120.0\n",
      "Ground truth answer: 700.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1139\n",
      "Model answer: 0.25\n",
      "Ground truth answer: 1.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1140\n",
      "Model answer: 3.0\n",
      "Ground truth answer: 27.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1141\n",
      "Model answer: 240.0\n",
      "Ground truth answer: 20.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1142\n",
      "Model answer: 13.0\n",
      "Ground truth answer: 9.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1143\n",
      "Model answer: 30.0\n",
      "Ground truth answer: 300.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1144\n",
      "Model answer: 64.0\n",
      "Ground truth answer: 34.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1145\n",
      "Model answer: 36.0\n",
      "Ground truth answer: 291.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1146\n",
      "Model answer: 40.0\n",
      "Ground truth answer: 16.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1147\n",
      "Model answer: None\n",
      "Ground truth answer: 22.0\n",
      "Correct: 154 out of 1319\n",
      "========================================\n",
      "task_id 1148\n",
      "Model answer: 9.0\n",
      "Ground truth answer: 9.0\n",
      "Correct: 155 out of 1319\n",
      "========================================\n",
      "task_id 1149\n",
      "Model answer: 97.0\n",
      "Ground truth answer: 93.0\n",
      "Correct: 155 out of 1319\n",
      "========================================\n",
      "task_id 1150\n",
      "Model answer: 31.0\n",
      "Ground truth answer: 21.0\n",
      "Correct: 155 out of 1319\n",
      "========================================\n",
      "task_id 1151\n",
      "Model answer: 46.6\n",
      "Ground truth answer: 50.0\n",
      "Correct: 155 out of 1319\n",
      "========================================\n",
      "task_id 1152\n",
      "Model answer: 60.0\n",
      "Ground truth answer: 12.0\n",
      "Correct: 155 out of 1319\n",
      "========================================\n",
      "task_id 1153\n",
      "Model answer: 61.0\n",
      "Ground truth answer: 20.0\n",
      "Correct: 155 out of 1319\n",
      "========================================\n",
      "task_id 1154\n",
      "Model answer: 20.0\n",
      "Ground truth answer: 30.0\n",
      "Correct: 155 out of 1319\n",
      "========================================\n",
      "task_id 1155\n",
      "Model answer: 15.0\n",
      "Ground truth answer: 13.0\n",
      "Correct: 155 out of 1319\n",
      "========================================\n",
      "task_id 1156\n",
      "Model answer: 120.0\n",
      "Ground truth answer: 120.0\n",
      "Correct: 156 out of 1319\n",
      "========================================\n",
      "task_id 1157\n",
      "Model answer: None\n",
      "Ground truth answer: 3.0\n",
      "Correct: 156 out of 1319\n",
      "========================================\n",
      "task_id 1158\n",
      "Model answer: 230.0\n",
      "Ground truth answer: 7300.0\n",
      "Correct: 156 out of 1319\n",
      "========================================\n",
      "task_id 1159\n",
      "Model answer: 12.0\n",
      "Ground truth answer: 50.0\n",
      "Correct: 156 out of 1319\n",
      "========================================\n",
      "task_id 1160\n",
      "Model answer: -348.0\n",
      "Ground truth answer: 1125.0\n",
      "Correct: 156 out of 1319\n",
      "========================================\n",
      "task_id 1161\n",
      "Model answer: 240.0\n",
      "Ground truth answer: 170.0\n",
      "Correct: 156 out of 1319\n",
      "========================================\n",
      "task_id 1162\n",
      "Model answer: 5.0\n",
      "Ground truth answer: 3.0\n",
      "Correct: 156 out of 1319\n",
      "========================================\n",
      "task_id 1163\n",
      "Model answer: 12.0\n",
      "Ground truth answer: 12.0\n",
      "Correct: 157 out of 1319\n",
      "========================================\n",
      "task_id 1164\n",
      "Model answer: 15.0\n",
      "Ground truth answer: 9.0\n",
      "Correct: 157 out of 1319\n",
      "========================================\n",
      "task_id 1165\n",
      "Model answer: None\n",
      "Ground truth answer: 1248.0\n",
      "Correct: 157 out of 1319\n",
      "========================================\n",
      "task_id 1166\n",
      "Model answer: None\n",
      "Ground truth answer: 2350.0\n",
      "Correct: 157 out of 1319\n",
      "========================================\n",
      "task_id 1167\n",
      "Model answer: 80.0\n",
      "Ground truth answer: 120.0\n",
      "Correct: 157 out of 1319\n",
      "========================================\n",
      "task_id 1168\n",
      "Model answer: None\n",
      "Ground truth answer: 20.0\n",
      "Correct: 157 out of 1319\n",
      "========================================\n",
      "task_id 1169\n",
      "Model answer: 5.0\n",
      "Ground truth answer: 2.0\n",
      "Correct: 157 out of 1319\n",
      "========================================\n",
      "task_id 1170\n",
      "Model answer: 16.0\n",
      "Ground truth answer: 2.0\n",
      "Correct: 157 out of 1319\n",
      "========================================\n",
      "task_id 1171\n",
      "Model answer: 10800.0\n",
      "Ground truth answer: 3160.0\n",
      "Correct: 157 out of 1319\n",
      "========================================\n",
      "task_id 1172\n",
      "Model answer: None\n",
      "Ground truth answer: 93.0\n",
      "Correct: 157 out of 1319\n",
      "========================================\n",
      "task_id 1173\n",
      "Model answer: 120.0\n",
      "Ground truth answer: 10.0\n",
      "Correct: 157 out of 1319\n",
      "========================================\n",
      "task_id 1174\n",
      "Model answer: 294.0\n",
      "Ground truth answer: 240.0\n",
      "Correct: 157 out of 1319\n",
      "========================================\n",
      "task_id 1175\n",
      "Model answer: None\n",
      "Ground truth answer: 16.0\n",
      "Correct: 157 out of 1319\n",
      "========================================\n",
      "task_id 1176\n",
      "Model answer: 9.0\n",
      "Ground truth answer: 2.0\n",
      "Correct: 157 out of 1319\n",
      "========================================\n",
      "task_id 1177\n",
      "Model answer: 0.0\n",
      "Ground truth answer: 17.0\n",
      "Correct: 157 out of 1319\n",
      "========================================\n",
      "task_id 1178\n",
      "Model answer: 15.0\n",
      "Ground truth answer: 17.0\n",
      "Correct: 157 out of 1319\n",
      "========================================\n",
      "task_id 1179\n",
      "Model answer: None\n",
      "Ground truth answer: 50.0\n",
      "Correct: 157 out of 1319\n",
      "========================================\n",
      "task_id 1180\n",
      "Model answer: 2800.0\n",
      "Ground truth answer: 5600.0\n",
      "Correct: 157 out of 1319\n",
      "========================================\n",
      "task_id 1181\n",
      "Model answer: None\n",
      "Ground truth answer: 20.0\n",
      "Correct: 157 out of 1319\n",
      "========================================\n",
      "task_id 1182\n",
      "Model answer: 1.5\n",
      "Ground truth answer: 1800.0\n",
      "Correct: 157 out of 1319\n",
      "========================================\n",
      "task_id 1183\n",
      "Model answer: None\n",
      "Ground truth answer: 11.0\n",
      "Correct: 157 out of 1319\n",
      "========================================\n",
      "task_id 1184\n",
      "Model answer: 302.0\n",
      "Ground truth answer: 306.0\n",
      "Correct: 157 out of 1319\n",
      "========================================\n",
      "task_id 1185\n",
      "Model answer: 52.0\n",
      "Ground truth answer: 6.0\n",
      "Correct: 157 out of 1319\n",
      "========================================\n",
      "task_id 1186\n",
      "Model answer: 18.0\n",
      "Ground truth answer: 19.0\n",
      "Correct: 157 out of 1319\n",
      "========================================\n",
      "task_id 1187\n",
      "Model answer: 4.0\n",
      "Ground truth answer: 5.0\n",
      "Correct: 157 out of 1319\n",
      "========================================\n",
      "task_id 1188\n",
      "Model answer: 12.0\n",
      "Ground truth answer: 24.0\n",
      "Correct: 157 out of 1319\n",
      "========================================\n",
      "task_id 1189\n",
      "Model answer: 6.0\n",
      "Ground truth answer: 6.0\n",
      "Correct: 158 out of 1319\n",
      "========================================\n",
      "task_id 1190\n",
      "Model answer: 28.0\n",
      "Ground truth answer: 19.0\n",
      "Correct: 158 out of 1319\n",
      "========================================\n",
      "task_id 1191\n",
      "Model answer: 70.0\n",
      "Ground truth answer: 100.0\n",
      "Correct: 158 out of 1319\n",
      "========================================\n",
      "task_id 1192\n",
      "Model answer: 77.5\n",
      "Ground truth answer: 280.0\n",
      "Correct: 158 out of 1319\n",
      "========================================\n",
      "task_id 1193\n",
      "Model answer: None\n",
      "Ground truth answer: 9.0\n",
      "Correct: 158 out of 1319\n",
      "========================================\n",
      "task_id 1194\n",
      "Model answer: 1200.0\n",
      "Ground truth answer: 1200.0\n",
      "Correct: 159 out of 1319\n",
      "========================================\n",
      "task_id 1195\n",
      "Model answer: None\n",
      "Ground truth answer: 320.0\n",
      "Correct: 159 out of 1319\n",
      "========================================\n",
      "task_id 1196\n",
      "Model answer: 35.0\n",
      "Ground truth answer: 75.0\n",
      "Correct: 159 out of 1319\n",
      "========================================\n",
      "task_id 1197\n",
      "Model answer: 1500.0\n",
      "Ground truth answer: 2400.0\n",
      "Correct: 159 out of 1319\n",
      "========================================\n",
      "task_id 1198\n",
      "Model answer: None\n",
      "Ground truth answer: 140.0\n",
      "Correct: 159 out of 1319\n",
      "========================================\n",
      "task_id 1199\n",
      "Model answer: None\n",
      "Ground truth answer: 2.0\n",
      "Correct: 159 out of 1319\n",
      "========================================\n",
      "task_id 1200\n",
      "Model answer: 168.0\n",
      "Ground truth answer: 8.0\n",
      "Correct: 159 out of 1319\n",
      "========================================\n",
      "task_id 1201\n",
      "Model answer: 55.0\n",
      "Ground truth answer: 42.0\n",
      "Correct: 159 out of 1319\n",
      "========================================\n",
      "task_id 1202\n",
      "Model answer: 4.0\n",
      "Ground truth answer: 19.0\n",
      "Correct: 159 out of 1319\n",
      "========================================\n",
      "task_id 1203\n",
      "Model answer: 12.0\n",
      "Ground truth answer: 240.0\n",
      "Correct: 159 out of 1319\n",
      "========================================\n",
      "task_id 1204\n",
      "Model answer: 140.0\n",
      "Ground truth answer: 168.0\n",
      "Correct: 159 out of 1319\n",
      "========================================\n",
      "task_id 1205\n",
      "Model answer: 2.0\n",
      "Ground truth answer: 4.0\n",
      "Correct: 159 out of 1319\n",
      "========================================\n",
      "task_id 1206\n",
      "Model answer: None\n",
      "Ground truth answer: 0.0\n",
      "Correct: 159 out of 1319\n",
      "========================================\n",
      "task_id 1207\n",
      "Model answer: None\n",
      "Ground truth answer: 64.0\n",
      "Correct: 159 out of 1319\n",
      "========================================\n",
      "task_id 1208\n",
      "Model answer: 39.0\n",
      "Ground truth answer: 27.0\n",
      "Correct: 159 out of 1319\n",
      "========================================\n",
      "task_id 1209\n",
      "Model answer: None\n",
      "Ground truth answer: 29.0\n",
      "Correct: 159 out of 1319\n",
      "========================================\n",
      "task_id 1210\n",
      "Model answer: 288.0\n",
      "Ground truth answer: 288.0\n",
      "Correct: 160 out of 1319\n",
      "========================================\n",
      "task_id 1211\n",
      "Model answer: 32.0\n",
      "Ground truth answer: 448.0\n",
      "Correct: 160 out of 1319\n",
      "========================================\n",
      "task_id 1212\n",
      "Model answer: 1800.0\n",
      "Ground truth answer: 150.0\n",
      "Correct: 160 out of 1319\n",
      "========================================\n",
      "task_id 1213\n",
      "Model answer: None\n",
      "Ground truth answer: 31.0\n",
      "Correct: 160 out of 1319\n",
      "========================================\n",
      "task_id 1214\n",
      "Model answer: 10.0\n",
      "Ground truth answer: 5.0\n",
      "Correct: 160 out of 1319\n",
      "========================================\n",
      "task_id 1215\n",
      "Model answer: None\n",
      "Ground truth answer: 36.0\n",
      "Correct: 160 out of 1319\n",
      "========================================\n",
      "task_id 1216\n",
      "Model answer: 20.0\n",
      "Ground truth answer: 20.0\n",
      "Correct: 161 out of 1319\n",
      "========================================\n",
      "task_id 1217\n",
      "Model answer: 27.0\n",
      "Ground truth answer: 75.0\n",
      "Correct: 161 out of 1319\n",
      "========================================\n",
      "task_id 1218\n",
      "Model answer: 6.0\n",
      "Ground truth answer: 225.0\n",
      "Correct: 161 out of 1319\n",
      "========================================\n",
      "task_id 1219\n",
      "Model answer: 90.0\n",
      "Ground truth answer: 100.0\n",
      "Correct: 161 out of 1319\n",
      "========================================\n",
      "task_id 1220\n",
      "Model answer: 160.0\n",
      "Ground truth answer: 32.0\n",
      "Correct: 161 out of 1319\n",
      "========================================\n",
      "task_id 1221\n",
      "Model answer: 2560.0\n",
      "Ground truth answer: 10.0\n",
      "Correct: 161 out of 1319\n",
      "========================================\n",
      "task_id 1222\n",
      "Model answer: 70.0\n",
      "Ground truth answer: 350.0\n",
      "Correct: 161 out of 1319\n",
      "========================================\n",
      "task_id 1223\n",
      "Model answer: None\n",
      "Ground truth answer: 8.0\n",
      "Correct: 161 out of 1319\n",
      "========================================\n",
      "task_id 1224\n",
      "Model answer: None\n",
      "Ground truth answer: 5.0\n",
      "Correct: 161 out of 1319\n",
      "========================================\n",
      "task_id 1225\n",
      "Model answer: 20.0\n",
      "Ground truth answer: 3.0\n",
      "Correct: 161 out of 1319\n",
      "========================================\n",
      "task_id 1226\n",
      "Model answer: None\n",
      "Ground truth answer: 90.0\n",
      "Correct: 161 out of 1319\n",
      "========================================\n",
      "task_id 1227\n",
      "Model answer: 43.0\n",
      "Ground truth answer: 66.0\n",
      "Correct: 161 out of 1319\n",
      "========================================\n",
      "task_id 1228\n",
      "Model answer: 3.0\n",
      "Ground truth answer: 31.0\n",
      "Correct: 161 out of 1319\n",
      "========================================\n",
      "task_id 1229\n",
      "Model answer: 36.0\n",
      "Ground truth answer: 36.0\n",
      "Correct: 162 out of 1319\n",
      "========================================\n",
      "task_id 1230\n",
      "Model answer: 480.0\n",
      "Ground truth answer: 440.0\n",
      "Correct: 162 out of 1319\n",
      "========================================\n",
      "task_id 1231\n",
      "Model answer: None\n",
      "Ground truth answer: 70.0\n",
      "Correct: 162 out of 1319\n",
      "========================================\n",
      "task_id 1232\n",
      "Model answer: 5.0\n",
      "Ground truth answer: 15.0\n",
      "Correct: 162 out of 1319\n",
      "========================================\n",
      "task_id 1233\n",
      "Model answer: 135.0\n",
      "Ground truth answer: 81.0\n",
      "Correct: 162 out of 1319\n",
      "========================================\n",
      "task_id 1234\n",
      "Model answer: 27.0\n",
      "Ground truth answer: 12.0\n",
      "Correct: 162 out of 1319\n",
      "========================================\n",
      "task_id 1235\n",
      "Model answer: 81.875\n",
      "Ground truth answer: 60.0\n",
      "Correct: 162 out of 1319\n",
      "========================================\n",
      "task_id 1236\n",
      "Model answer: 48.0\n",
      "Ground truth answer: 84.0\n",
      "Correct: 162 out of 1319\n",
      "========================================\n",
      "task_id 1237\n",
      "Model answer: 22.0\n",
      "Ground truth answer: 78.0\n",
      "Correct: 162 out of 1319\n",
      "========================================\n",
      "task_id 1238\n",
      "Model answer: 208.0\n",
      "Ground truth answer: 520.0\n",
      "Correct: 162 out of 1319\n",
      "========================================\n",
      "task_id 1239\n",
      "Model answer: 11.0\n",
      "Ground truth answer: 50.0\n",
      "Correct: 162 out of 1319\n",
      "========================================\n",
      "task_id 1240\n",
      "Model answer: 2.0\n",
      "Ground truth answer: 2.0\n",
      "Correct: 163 out of 1319\n",
      "========================================\n",
      "task_id 1241\n",
      "Model answer: 15.0\n",
      "Ground truth answer: 8.0\n",
      "Correct: 163 out of 1319\n",
      "========================================\n",
      "task_id 1242\n",
      "Model answer: None\n",
      "Ground truth answer: 20.0\n",
      "Correct: 163 out of 1319\n",
      "========================================\n",
      "task_id 1243\n",
      "Model answer: 0.6\n",
      "Ground truth answer: 50.0\n",
      "Correct: 163 out of 1319\n",
      "========================================\n",
      "task_id 1244\n",
      "Model answer: 28.0\n",
      "Ground truth answer: 35.0\n",
      "Correct: 163 out of 1319\n",
      "========================================\n",
      "task_id 1245\n",
      "Model answer: 560.0\n",
      "Ground truth answer: 96.0\n",
      "Correct: 163 out of 1319\n",
      "========================================\n",
      "task_id 1246\n",
      "Model answer: 840.0\n",
      "Ground truth answer: 3360.0\n",
      "Correct: 163 out of 1319\n",
      "========================================\n",
      "task_id 1247\n",
      "Model answer: 3.0\n",
      "Ground truth answer: 7.0\n",
      "Correct: 163 out of 1319\n",
      "========================================\n",
      "task_id 1248\n",
      "Model answer: None\n",
      "Ground truth answer: 750.0\n",
      "Correct: 163 out of 1319\n",
      "========================================\n",
      "task_id 1249\n",
      "Model answer: None\n",
      "Ground truth answer: 56.0\n",
      "Correct: 163 out of 1319\n",
      "========================================\n",
      "task_id 1250\n",
      "Model answer: 11.0\n",
      "Ground truth answer: 22.0\n",
      "Correct: 163 out of 1319\n",
      "========================================\n",
      "task_id 1251\n",
      "Model answer: 30.0\n",
      "Ground truth answer: 30.0\n",
      "Correct: 164 out of 1319\n",
      "========================================\n",
      "task_id 1252\n",
      "Model answer: 10.0\n",
      "Ground truth answer: 70.0\n",
      "Correct: 164 out of 1319\n",
      "========================================\n",
      "task_id 1253\n",
      "Model answer: 10.0\n",
      "Ground truth answer: 120.0\n",
      "Correct: 164 out of 1319\n",
      "========================================\n",
      "task_id 1254\n",
      "Model answer: 20.0\n",
      "Ground truth answer: 30.0\n",
      "Correct: 164 out of 1319\n",
      "========================================\n",
      "task_id 1255\n",
      "Model answer: 5.0\n",
      "Ground truth answer: 12.0\n",
      "Correct: 164 out of 1319\n",
      "========================================\n",
      "task_id 1256\n",
      "Model answer: None\n",
      "Ground truth answer: 15.0\n",
      "Correct: 164 out of 1319\n",
      "========================================\n",
      "task_id 1257\n",
      "Model answer: 112.0\n",
      "Ground truth answer: 14.0\n",
      "Correct: 164 out of 1319\n",
      "========================================\n",
      "task_id 1258\n",
      "Model answer: 100.0\n",
      "Ground truth answer: 60.0\n",
      "Correct: 164 out of 1319\n",
      "========================================\n",
      "task_id 1259\n",
      "Model answer: 600.0\n",
      "Ground truth answer: 7200.0\n",
      "Correct: 164 out of 1319\n",
      "========================================\n",
      "task_id 1260\n",
      "Model answer: 210.0\n",
      "Ground truth answer: 5.0\n",
      "Correct: 164 out of 1319\n",
      "========================================\n",
      "task_id 1261\n",
      "Model answer: 39.0\n",
      "Ground truth answer: 235.0\n",
      "Correct: 164 out of 1319\n",
      "========================================\n",
      "task_id 1262\n",
      "Model answer: 12.0\n",
      "Ground truth answer: 12.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1263\n",
      "Model answer: None\n",
      "Ground truth answer: 500.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1264\n",
      "Model answer: None\n",
      "Ground truth answer: 210.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1265\n",
      "Model answer: 24.0\n",
      "Ground truth answer: 36.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1266\n",
      "Model answer: 35.0\n",
      "Ground truth answer: 147.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1267\n",
      "Model answer: 20.0\n",
      "Ground truth answer: 40.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1268\n",
      "Model answer: 14.0\n",
      "Ground truth answer: 20.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1269\n",
      "Model answer: 244.0\n",
      "Ground truth answer: 54.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1270\n",
      "Model answer: 92.0\n",
      "Ground truth answer: 3528.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1271\n",
      "Model answer: None\n",
      "Ground truth answer: 43.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1272\n",
      "Model answer: 104.0\n",
      "Ground truth answer: 296.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1273\n",
      "Model answer: 17.0\n",
      "Ground truth answer: 27.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1274\n",
      "Model answer: 41.0\n",
      "Ground truth answer: 38.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1275\n",
      "Model answer: 12.0\n",
      "Ground truth answer: 16.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1276\n",
      "Model answer: 300.0\n",
      "Ground truth answer: 70.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1277\n",
      "Model answer: 52.0\n",
      "Ground truth answer: 48.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1278\n",
      "Model answer: 0.0\n",
      "Ground truth answer: 665.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1279\n",
      "Model answer: 216.0\n",
      "Ground truth answer: 180.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1280\n",
      "Model answer: 12.0\n",
      "Ground truth answer: 7.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1281\n",
      "Model answer: 260.0\n",
      "Ground truth answer: 20.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1282\n",
      "Model answer: 72.0\n",
      "Ground truth answer: 12.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1283\n",
      "Model answer: 0.0\n",
      "Ground truth answer: 60.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1284\n",
      "Model answer: 8.0\n",
      "Ground truth answer: 25.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1285\n",
      "Model answer: -612.0\n",
      "Ground truth answer: 1218.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1286\n",
      "Model answer: 65.0\n",
      "Ground truth answer: 105.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1287\n",
      "Model answer: 28.0\n",
      "Ground truth answer: 84.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1288\n",
      "Model answer: 35.0\n",
      "Ground truth answer: 34.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1289\n",
      "Model answer: 81.0\n",
      "Ground truth answer: 101.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1290\n",
      "Model answer: 4.5\n",
      "Ground truth answer: 90.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1291\n",
      "Model answer: 3.0\n",
      "Ground truth answer: 27.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1292\n",
      "Model answer: 39.0\n",
      "Ground truth answer: 67.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1293\n",
      "Model answer: 20000.0\n",
      "Ground truth answer: 140000.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1294\n",
      "Model answer: 32.0\n",
      "Ground truth answer: 36.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1295\n",
      "Model answer: None\n",
      "Ground truth answer: 2.0\n",
      "Correct: 165 out of 1319\n",
      "========================================\n",
      "task_id 1296\n",
      "Model answer: 335.0\n",
      "Ground truth answer: 335.0\n",
      "Correct: 166 out of 1319\n",
      "========================================\n",
      "task_id 1297\n",
      "Model answer: None\n",
      "Ground truth answer: 60.0\n",
      "Correct: 166 out of 1319\n",
      "========================================\n",
      "task_id 1298\n",
      "Model answer: None\n",
      "Ground truth answer: 31.0\n",
      "Correct: 166 out of 1319\n",
      "========================================\n",
      "task_id 1299\n",
      "Model answer: None\n",
      "Ground truth answer: 13.0\n",
      "Correct: 166 out of 1319\n",
      "========================================\n",
      "task_id 1300\n",
      "Model answer: 168.0\n",
      "Ground truth answer: 120.0\n",
      "Correct: 166 out of 1319\n",
      "========================================\n",
      "task_id 1301\n",
      "Model answer: None\n",
      "Ground truth answer: 23.0\n",
      "Correct: 166 out of 1319\n",
      "========================================\n",
      "task_id 1302\n",
      "Model answer: None\n",
      "Ground truth answer: 72.0\n",
      "Correct: 166 out of 1319\n",
      "========================================\n",
      "task_id 1303\n",
      "Model answer: None\n",
      "Ground truth answer: 4.0\n",
      "Correct: 166 out of 1319\n",
      "========================================\n",
      "task_id 1304\n",
      "Model answer: 1000.0\n",
      "Ground truth answer: 1000.0\n",
      "Correct: 167 out of 1319\n",
      "========================================\n",
      "task_id 1305\n",
      "Model answer: 2425.0\n",
      "Ground truth answer: 2325.0\n",
      "Correct: 167 out of 1319\n",
      "========================================\n",
      "task_id 1306\n",
      "Model answer: 18.0\n",
      "Ground truth answer: 2.0\n",
      "Correct: 167 out of 1319\n",
      "========================================\n",
      "task_id 1307\n",
      "Model answer: 16.0\n",
      "Ground truth answer: 8.0\n",
      "Correct: 167 out of 1319\n",
      "========================================\n",
      "task_id 1308\n",
      "Model answer: 30.0\n",
      "Ground truth answer: 30.0\n",
      "Correct: 168 out of 1319\n",
      "========================================\n",
      "task_id 1309\n",
      "Model answer: 1450.0\n",
      "Ground truth answer: 2280.0\n",
      "Correct: 168 out of 1319\n",
      "========================================\n",
      "task_id 1310\n",
      "Model answer: 8.0\n",
      "Ground truth answer: 64.0\n",
      "Correct: 168 out of 1319\n",
      "========================================\n",
      "task_id 1311\n",
      "Model answer: 594.0\n",
      "Ground truth answer: 594.0\n",
      "Correct: 169 out of 1319\n",
      "========================================\n",
      "task_id 1312\n",
      "Model answer: 120.0\n",
      "Ground truth answer: 180.0\n",
      "Correct: 169 out of 1319\n",
      "========================================\n",
      "task_id 1313\n",
      "Model answer: 5.0\n",
      "Ground truth answer: 2.0\n",
      "Correct: 169 out of 1319\n",
      "========================================\n",
      "task_id 1314\n",
      "Model answer: None\n",
      "Ground truth answer: 8.0\n",
      "Correct: 169 out of 1319\n",
      "========================================\n",
      "task_id 1315\n",
      "Model answer: None\n",
      "Ground truth answer: 5.0\n",
      "Correct: 169 out of 1319\n",
      "========================================\n",
      "task_id 1316\n",
      "Model answer: 370.0\n",
      "Ground truth answer: 230.0\n",
      "Correct: 169 out of 1319\n",
      "========================================\n",
      "task_id 1317\n",
      "Model answer: 3.5\n",
      "Ground truth answer: 5.0\n",
      "Correct: 169 out of 1319\n",
      "========================================\n",
      "task_id 1318\n",
      "Model answer: 14.0\n",
      "Ground truth answer: 14.0\n",
      "Correct: 170 out of 1319\n",
      "========================================\n",
      "Final Accuracy: 0.13\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "TEMPLATE = \"\"\"\n",
    "Q: {}\n",
    "A:\"\"\"\n",
    "\n",
    "# Load GSM8K dataset\n",
    "gsm8k_test = load_dataset(\"gsm8k\",\"main\", split=\"test\")\n",
    "\n",
    "# Assuming model and tokenizer are already initialized\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Helper function to encode inputs\n",
    "def prepare_input(p):\n",
    "    # print(question)\n",
    "    prompt = (PREAMBLE +'\\n\\n' + PROMPT + '\\n' +\n",
    "                 TEMPLATE.format(p))\n",
    "    return tokenizer(prompt, return_tensors='pt').input_ids\n",
    "\n",
    "# Function to decode model output\n",
    "def decode_output(output_ids):\n",
    "    return tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "# Manual testing loop\n",
    "all_correct = 0\n",
    "all_responses = {}\n",
    "idx = 0\n",
    "total = len(gsm8k_test)\n",
    "# total = 100\n",
    "\n",
    "for task_id, problem in enumerate(gsm8k_test):\n",
    "    if idx == total:\n",
    "        break\n",
    "    \n",
    "    print(f\"task_id {task_id}\")\n",
    "\n",
    "    # Prepare the input for the model\n",
    "    input_ids = prepare_input(problem['question'])\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(input_ids, max_new_tokens = 120)  # Adjust max_length as needed\n",
    "\n",
    "    response = decode_output(output_ids[0])\n",
    "    all_responses[task_id] = response\n",
    "    \n",
    "    answer_line = extract_response_after_question(response, problem['question'])\n",
    "\n",
    "    # Compare model output to the ground truth\n",
    "    model_number = extract_number_from_text(answer_line, \"The answer is\")\n",
    "    ground_truth_number = extract_number_from_text(problem['answer'], \"####\")\n",
    "    \n",
    "    # print(model_number)\n",
    "    # print(ground_truth_number)\n",
    "    \n",
    "    if model_number == ground_truth_number:\n",
    "        all_correct += 1\n",
    "    \n",
    "\n",
    "    print(f\"Model answer: {model_number}\")\n",
    "    print(f\"Ground truth answer: {ground_truth_number}\")\n",
    "    print(f\"Correct: {all_correct} out of {total}\")\n",
    "    print(\"=\"*40)\n",
    "    idx += 1\n",
    "    \n",
    "\n",
    "# Final accuracy\n",
    "accuracy = all_correct / len(gsm8k_test)\n",
    "print(f\"Final Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy Llama2 base : 12.89%\n"
     ]
    }
   ],
   "source": [
    "accuracy = all_correct / total* 100\n",
    "print(f\"Final Accuracy Llama2 base : {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s> \\n### Input:\\n198 + 789\\n\\n### Response:\\n2777\\n\\n### Explanation:\\n\\nYou can use the fact that the sum of the first two digits of any number is 7. So, the sum of the first two digits of 198 + 789 is 7 + 8 = 15.\\n\\n### Example 1:\\n\\n```\\nInput:\\n198 + 789\\n\\nOutput: 2777\\n```\\n\\n### Example 2:\\n\\n```\\nInput:\\n198 + 789\\n\\nOutput: 2777\\n```\\n\\n### Example 3:\\n\\n```\\nInput:\\n198 + 789\\n\\nOutput: 2777\\n```\\n\\n### Example 4:\\n\\n```\\nInput:\\n198 + 789\\n\\nOutput: 2777\\n```']\n"
     ]
    }
   ],
   "source": [
    "alpaca_prompt = \"\"\"\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "inputs = tokenizer([\n",
    "    alpaca_prompt.format(\n",
    "            \"198 + 789\"\n",
    "            , \"\")\n",
    "], return_tensors = \"pt\").to('cuda')\n",
    "outputs = model.generate(**inputs, max_new_tokens = 200, use_cache = True)\n",
    "print(tokenizer.batch_decode(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['<s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWrite down all of the state changes that take place after the code snippet is executed.\\n\\n### Input:\\n1981 + 1789\\n\\n### Response:\\nAdd 1981 and 1789 step by step:\\nAdding the ones: 1 + 9 + 0 = 10 (carry 1 to the next pair, and we write down 0 at the ones place)\\nAdding the tens: 8 + 8 + 1 = 17 (carry 1 to the next pair, and we write down 7 at the tens place)\\nAdding the hundreds: 9 + 7 + 1 = 17 (carry 1 to the next pair, and we write down 7 at the hundreds place)\\nAdding the thousands: 1 + 1 + 1 = 3 (carry 0 to the next pair, and we write down 3 at the thousands place)\\nThe final answer is 3770']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
